{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ae52f44-f54e-4d4d-9be7-0d62b14c0769",
   "metadata": {},
   "source": [
    "# Text Analytics - Assignment 2\n",
    "# (Text Classification With Multi-Layer Perceptrons)\n",
    "\n",
    "---\n",
    "> Kostis Konstantinos (p3352311) <br>\n",
    "> MSc Data-Science (Part-Time) <br>\n",
    "> Athens University Of Economics and Business"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54238c92-0466-4fea-954f-a2bac52d109a",
   "metadata": {},
   "source": [
    "## Exercice 10 (POS Tagger)\n",
    "\n",
    "In this exercise we implement a Part-Of-Speech tagger. The POS tagger is implemented as a classifier of words to part-of-speech tags.\\\n",
    "The main objective is to create a tagger using a Multi-Layer Perceptron with the maximum possible correctness (classification power).\\\n",
    "To do that we will firstly create a baseline classifier which for a word that was present in the training set always responds with its most frequent tag \\\n",
    "and if it was not encountered in the training set always responds with the most frequent tag (over all words) of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f2674e5-bf9c-46dd-9053-05be7bb1b907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries (via pip) for Google Colab\n",
    "\n",
    "#!pip install -U conllu gensim pandas requests tensorflow keras-tuner scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "859bf84a-346e-48c4-a5cc-1d6a8d2e8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "\n",
    "# INFO, WARNING and ERROR messages are not printed\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  \n",
    "\n",
    "from io import open\n",
    "from collections import Counter\n",
    "\n",
    "from conllu import parse_incr\n",
    "import requests\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from sklearn.metrics import (f1_score, recall_score, precision_score, classification_report, \n",
    "auc, precision_recall_curve, roc_auc_score)\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd662a3-2764-4042-aa90-c2c3856c0eed",
   "metadata": {},
   "source": [
    "### Setting a random seed (for reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f156464-eb4e-4860-a3c4-c67c77418768",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2024\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7956e7-6e85-4a83-a7c8-9c3d9e215b36",
   "metadata": {},
   "source": [
    "### Dataset (Description & Helper classes)\n",
    "\n",
    "The dataset used, refers to the english language of the Universal Dependencies tree banks and more specifically GUM from Georgetown University.\\\n",
    "It contains 10761 sentences from different genres: academic, blog, fiction, government, news, nonfiction, social, spoken, web, wiki. \\\n",
    "The dataset is downloaded from Github and parsed using the `conllu` package, via a custom class named `DatasetHandler`.\n",
    "\n",
    "Treebank index page can be found here [https://universaldependencies.org/treebanks/en_gum/index.html](https://universaldependencies.org/treebanks/en_gum/index.html) \\\n",
    "The actual data (train, dev, test) files can be found at [https://github.com/UniversalDependencies/UD_English-GUM/tree/master](https://github.com/UniversalDependencies/UD_English-GUM/tree/master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b323d5ad-3a29-445b-9063-ccfb012e39ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and parse train, dev and test splits (download from github)\n",
    "\n",
    "class DatasetHandler:\n",
    "    \"\"\" DatasetHandler\n",
    "    \n",
    "    Downloads and parses the universal-dependencies/en-gmu data files.\n",
    "    \"\"\"\n",
    "    def __init__(self, url, mode):\n",
    "        self.url = url\n",
    "        self.mode = mode\n",
    "\n",
    "        self.sentences = []\n",
    "        \n",
    "        self.data_directory = 'data'\n",
    "        self.data_file = os.path.join(self.data_directory, \"{}.conllu\".format(self.mode))\n",
    "\n",
    "    def fetch(self):\n",
    "        if not os.path.exists(self.data_directory):\n",
    "            os.makedirs(self.data_directory)\n",
    "\n",
    "        if not os.path.exists(self.data_file):\n",
    "            self.download()\n",
    "\n",
    "        handle = open(self.data_file, \"r\", encoding=\"utf-8\")\n",
    "        for tokenlist in parse_incr(handle):\n",
    "            sentence = []\n",
    "\n",
    "            for token in tokenlist:\n",
    "                if not token['form']:\n",
    "                    continue\n",
    "                sentence.append((token['form'].lower(), token['upos']))\n",
    "\n",
    "            self.sentences.append(sentence)\n",
    "\n",
    "    def basic_stats(self):\n",
    "        n_sentences = len(self.sentences)\n",
    "\n",
    "        words = []\n",
    "        average_sentence_length = 0\n",
    "        \n",
    "        for sentence in self.sentences:\n",
    "            average_sentence_length += len(sentence)\n",
    "\n",
    "            for item in sentence:\n",
    "                words.append(item[0])\n",
    "\n",
    "        average_sentence_length /= n_sentences \n",
    "\n",
    "        n_words = len(words)\n",
    "        n_unique_words = len(set(words))\n",
    "\n",
    "        stats = [[self.mode, n_sentences, round(average_sentence_length,1), n_words, n_unique_words]]\n",
    "        df = pd.DataFrame(stats, columns=['Dataset', 'Sentences', 'Average Sentence Length', 'Words', 'Unique Words'])\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def download(self):\n",
    "        response = requests.get(self.url)\n",
    "        with open(self.data_file, mode=\"wb\") as file:\n",
    "            file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef36210a-fd6d-444d-a160-98b428b25e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceUtils:\n",
    "    \"\"\"Sentence utility methods.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def tokens_of(tagged_sentence):\n",
    "        return [token for (token, tag) in tagged_sentence]\n",
    "\n",
    "    @staticmethod\n",
    "    def pos_of(tagged_sentence):\n",
    "        return [tag for (token, tag) in tagged_sentence]\n",
    "\n",
    "    @staticmethod\n",
    "    def texts(sentences):\n",
    "        return [ __class__.tokens_of(sentence) for sentence in sentences]\n",
    "\n",
    "    @staticmethod\n",
    "    def tags(sentences):\n",
    "        return [ __class__.pos_of(sentence) for sentence in sentences]\n",
    "\n",
    "    @staticmethod\n",
    "    def flatten_texts(sentences):\n",
    "        return [token\n",
    "                for tokenList in __class__.texts(sentences)\n",
    "                for token in tokenList]\n",
    "\n",
    "    @staticmethod\n",
    "    def flatten_tags(sentences):\n",
    "        return [tag \n",
    "                for tagList in __class__.tags(sentences)\n",
    "                for tag in tagList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "506f6e81-b670-4d65-9c8a-e7e07e934382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch/Parse the data\n",
    "\n",
    "train_url = 'https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/master/en_gum-ud-train.conllu'\n",
    "dev_url = 'https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/master/en_gum-ud-dev.conllu'\n",
    "test_url = 'https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/master/en_gum-ud-test.conllu'\n",
    "\n",
    "train_ds_handler = DatasetHandler(train_url, 'train')\n",
    "train_ds_handler.fetch()\n",
    "\n",
    "dev_ds_handler = DatasetHandler(dev_url, 'dev')\n",
    "dev_ds_handler.fetch()\n",
    "\n",
    "test_ds_handler = DatasetHandler(test_url, 'test')\n",
    "test_ds_handler.fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c99b8-6a9e-4110-9f84-f4dc595ae35c",
   "metadata": {},
   "source": [
    "### Basic statistics\n",
    "Below you can find some basic statistics regarding the train, dev and test sets.\n",
    "Reported statistics are:\n",
    "\n",
    "- Dataset split\n",
    "- Number of sentences\n",
    "- Average sentence length\n",
    "- Number of words\n",
    "- Number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "218dd07e-3fcc-42db-a3af-85282d8d305e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Words</th>\n",
       "      <th>Unique Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>9521</td>\n",
       "      <td>17.5</td>\n",
       "      <td>166918</td>\n",
       "      <td>15555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev</td>\n",
       "      <td>1341</td>\n",
       "      <td>18.2</td>\n",
       "      <td>24375</td>\n",
       "      <td>4302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>1285</td>\n",
       "      <td>18.9</td>\n",
       "      <td>24330</td>\n",
       "      <td>4819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Sentences  Average Sentence Length   Words  Unique Words\n",
       "0   train       9521                     17.5  166918         15555\n",
       "1     dev       1341                     18.2   24375          4302\n",
       "2    test       1285                     18.9   24330          4819"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats = train_ds_handler.basic_stats()\n",
    "dev_stats = dev_ds_handler.basic_stats()\n",
    "test_stats = test_ds_handler.basic_stats()\n",
    "\n",
    "stats = pd.concat([train_stats, dev_stats, test_stats], ignore_index=True)\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1416a35f-9e8f-4595-8f92-cb24aa0a5c46",
   "metadata": {},
   "source": [
    "### Helper method for generating a classification report\n",
    "\n",
    "This section refers to an implementation of a method that produces a classification report\n",
    "for a given dataset. The dimensions of this report include:\n",
    "\n",
    "- Precision (For each POS tag)\n",
    "- Recall (For each POS tag)\n",
    "- F1 (For each POS tag)\n",
    "- Precision-Recall AUC (For each POS Tag)\n",
    "- Macro avegerages for the above metrics\n",
    "\n",
    "The report is given as pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0560663-74ca-4bfb-b9a5-3f6bfceb7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report implementation\n",
    "class EvaluationMetrics:\n",
    "\n",
    "    @staticmethod\n",
    "    def classification_report(y_true, y_probabilities, y_predicted, class_ids, class_labels):\n",
    "        \"\"\" Creates a classification report for a multi-class classsification problem.\n",
    "\n",
    "        Note: Scikit-Learn's precision_recall_curve has its output reversed. See:\n",
    "        https://github.com/scikit-learn/scikit-learn/issues/2097\n",
    "        \n",
    "        Args:\n",
    "            y_true: A one dimensional array(n_samples), containing the actual class id per sample.\n",
    "            y_probabilities: A 2D array (n_samples, n_classes) containing the predicted probabilities\n",
    "                per sample.\n",
    "            y_predicted: A one dimensional array(n_samples) containing the predicted class id per sample.\n",
    "            class_ids: A one dimensional array (n_classes) containing the ids of classes.\n",
    "            class_labels: A one dimensional array (n_classes) containing the names of the classes.\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute precision (per class)\n",
    "        precision = precision_score(y_true, y_predicted, average=None)\n",
    "\n",
    "        # Compute recall (per class)\n",
    "        recall = recall_score(y_true, y_predicted, average=None)\n",
    "\n",
    "        # Compute F1 (per class)\n",
    "        f1 = f1_score(y_true, y_predicted, average=None)\n",
    "\n",
    "        # Compute Precision-Recall AUC score (per class)\n",
    "        auc_scores = []\n",
    "        for class_id in class_ids:\n",
    "            class_indices = (y_true == class_id)\n",
    "            if any(class_indices):\n",
    "                class_precision, class_recall, thresholds = precision_recall_curve(\n",
    "                    class_indices.astype(int), y_probabilities[:, class_id])\n",
    "                class_precision_recall_auc = auc(class_recall, class_precision)\n",
    "                auc_scores.append(class_precision_recall_auc)\n",
    "\n",
    "        classification_report_df = pd.DataFrame()\n",
    "        classification_report_df['Class Id'] = class_ids\n",
    "        classification_report_df['Class Name'] = class_labels\n",
    "        classification_report_df['Precision'] = precision\n",
    "        classification_report_df['Recall'] = recall\n",
    "        classification_report_df['F1'] = f1\n",
    "        classification_report_df['Precision-Recall AUC'] = auc_scores\n",
    "    \n",
    "        macro_average_df = pd.DataFrame()\n",
    "        macro_average_df['Macro Average Precision'] = [np.mean(precision)]\n",
    "        macro_average_df['Macro Average Recall'] = [np.mean(recall)]\n",
    "        macro_average_df['Macro Average F1'] = [np.mean(f1)]\n",
    "        macro_average_df['Macro Average Precision Recall AUC'] = [np.mean(auc_scores)]\n",
    "    \n",
    "        return (classification_report_df, macro_average_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422ebe16",
   "metadata": {},
   "source": [
    "## POS Tagger: Baseline Classifier (most frequent tag)\n",
    "\n",
    "This section implements a baseline classifier, that utilizes the most frequent tag (POS tag) given a word.\\\n",
    "Essentially, fitting the baseline simply means counting the occurencies of (word, tag) pairs.\\\n",
    "Consequently, during inference when a word is given the most frequent tag of the word is selected.\\\n",
    "In case the given word was not seen in the training set, then the most frequent tag over all tags is selected.\\\n",
    "This is a custom implementation with a Scikit-Learn compatible interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a0b2526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline (Most frequent tag) implementation\n",
    "class MostFrequentTagClassifier:\n",
    "    def __init__(self):\n",
    "        self.word2tag = {}\n",
    "        self.most_frequent_tag = None\n",
    "        self.tag2id = {}\n",
    "\n",
    "    def fit(self, X):\n",
    "        pair_frequencies = {}\n",
    "        tag_frequencies = Counter()\n",
    "\n",
    "        # Collect counts for tags and pairs of word/tag\n",
    "        for sentence in X:\n",
    "            for (word, tag) in sentence:\n",
    "                if word not in pair_frequencies:\n",
    "                    pair_frequencies[word] = Counter()\n",
    "                pair_frequencies[word][tag] += 1\n",
    "                tag_frequencies[tag] += 1\n",
    "\n",
    "        # Persist the overall most frequent tag and the most frequent tag per word\n",
    "        self.most_frequent_tag = tag_frequencies.most_common()[0][0]\n",
    "        for word in pair_frequencies.keys():\n",
    "            self.word2tag[word] = pair_frequencies[word].most_common()[0][0]\n",
    "\n",
    "        tags = list(tag_frequencies.keys())\n",
    "        self.tag2id = {tag: idx for (idx, tag) in enumerate(tags)}\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, word):\n",
    "        prediction = None\n",
    "\n",
    "        if word not in self.word2tag:\n",
    "            prediction = self.most_frequent_tag\n",
    "        else:\n",
    "            prediction = self.word2tag[word]\n",
    "\n",
    "        return self.tag2id[prediction]\n",
    "\n",
    "    def predict_proba(self, word):\n",
    "        prediction = self.predict(word)\n",
    "\n",
    "        return to_categorical([prediction], num_classes=len(self.tag2id))\n",
    "\n",
    "    def evaluate(self, dataset):\n",
    "        tokens = SentenceUtils.flatten_texts(dataset)\n",
    "        tags = SentenceUtils.flatten_tags(dataset)\n",
    "\n",
    "        y_true = np.array([self.tag2id[tag] for tag in tags])\n",
    "        y_predicted = np.array([self.predict(token) for token in tokens])\n",
    "\n",
    "        y_probabilities = []\n",
    "        for token in tokens:\n",
    "            y_probabilities.append(self.predict_proba(token))\n",
    "        y_probabilities = np.array(y_probabilities).reshape((len(tokens), len(self.tag2id)))\n",
    "\n",
    "        class_ids = list(self.tag2id.values())\n",
    "        class_labels = list(self.tag2id.keys())\n",
    "\n",
    "        return EvaluationMetrics.classification_report(\n",
    "            y_true, y_probabilities, y_predicted, class_ids, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2c32a5d-8a10-423a-ad9b-efdfcd1ff066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit the MostFrequentTagClassifier\n",
    "most_frequent_tag_classifier = MostFrequentTagClassifier().fit(train_ds_handler.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97532786-260a-4656-8cb4-15ba8c7742a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline evaluation (train set)\n",
    "train_set = train_ds_handler.sentences\n",
    "train_classification_report_df, train_macro_average_df = most_frequent_tag_classifier.evaluate(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54af1992-8a29-4625-9455-9636adddb529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Id</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision-Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0.905493</td>\n",
       "      <td>0.932019</td>\n",
       "      <td>0.918565</td>\n",
       "      <td>0.920946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.923814</td>\n",
       "      <td>0.939181</td>\n",
       "      <td>0.931434</td>\n",
       "      <td>0.936470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>0.990724</td>\n",
       "      <td>0.992565</td>\n",
       "      <td>0.992718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>0.995007</td>\n",
       "      <td>0.998593</td>\n",
       "      <td>0.996797</td>\n",
       "      <td>0.996896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0.905744</td>\n",
       "      <td>0.888595</td>\n",
       "      <td>0.897087</td>\n",
       "      <td>0.902333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0.924751</td>\n",
       "      <td>0.828910</td>\n",
       "      <td>0.874212</td>\n",
       "      <td>0.881716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0.923371</td>\n",
       "      <td>0.898068</td>\n",
       "      <td>0.910544</td>\n",
       "      <td>0.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>ADV</td>\n",
       "      <td>0.915924</td>\n",
       "      <td>0.824751</td>\n",
       "      <td>0.867950</td>\n",
       "      <td>0.874456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>AUX</td>\n",
       "      <td>0.870135</td>\n",
       "      <td>0.947965</td>\n",
       "      <td>0.907384</td>\n",
       "      <td>0.910425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>DET</td>\n",
       "      <td>0.946340</td>\n",
       "      <td>0.977793</td>\n",
       "      <td>0.961810</td>\n",
       "      <td>0.962953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>PRON</td>\n",
       "      <td>0.920814</td>\n",
       "      <td>0.957455</td>\n",
       "      <td>0.938777</td>\n",
       "      <td>0.940893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>0.804577</td>\n",
       "      <td>0.345166</td>\n",
       "      <td>0.483087</td>\n",
       "      <td>0.580066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>X</td>\n",
       "      <td>0.954918</td>\n",
       "      <td>0.732704</td>\n",
       "      <td>0.829181</td>\n",
       "      <td>0.844066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>SYM</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.721805</td>\n",
       "      <td>0.817021</td>\n",
       "      <td>0.831712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>PART</td>\n",
       "      <td>0.698403</td>\n",
       "      <td>0.900381</td>\n",
       "      <td>0.786634</td>\n",
       "      <td>0.800566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>_</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.999294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>NUM</td>\n",
       "      <td>0.953790</td>\n",
       "      <td>0.996843</td>\n",
       "      <td>0.974842</td>\n",
       "      <td>0.975347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.858573</td>\n",
       "      <td>0.787600</td>\n",
       "      <td>0.793696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class Id Class Name  Precision    Recall        F1  Precision-Recall AUC\n",
       "0          0        ADJ   0.905493  0.932019  0.918565              0.920946\n",
       "1          1       NOUN   0.923814  0.939181  0.931434              0.936470\n",
       "2          2      CCONJ   0.994413  0.990724  0.992565              0.992718\n",
       "3          3      PUNCT   0.995007  0.998593  0.996797              0.996896\n",
       "4          4        ADP   0.905744  0.888595  0.897087              0.902333\n",
       "5          5      PROPN   0.924751  0.828910  0.874212              0.881716\n",
       "6          6       VERB   0.923371  0.898068  0.910544              0.915968\n",
       "7          7        ADV   0.915924  0.824751  0.867950              0.874456\n",
       "8          8        AUX   0.870135  0.947965  0.907384              0.910425\n",
       "9          9        DET   0.946340  0.977793  0.961810              0.962953\n",
       "10        10       PRON   0.920814  0.957455  0.938777              0.940893\n",
       "11        11      SCONJ   0.804577  0.345166  0.483087              0.580066\n",
       "12        12          X   0.954918  0.732704  0.829181              0.844066\n",
       "13        13        SYM   0.941176  0.721805  0.817021              0.831712\n",
       "14        14       PART   0.698403  0.900381  0.786634              0.800566\n",
       "15        15          _   0.999288  0.999288  0.999288              0.999294\n",
       "16        16        NUM   0.953790  0.996843  0.974842              0.975347\n",
       "17        17       INTJ   0.727466  0.858573  0.787600              0.793696"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classification_report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5669792c-a701-4582-8b46-d815eb702533",
   "metadata": {},
   "source": [
    "## Building a Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6d1c64-9d7c-462b-8ae3-e288073af554",
   "metadata": {},
   "source": [
    "### Loading pretrained word embeddingns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c28483a-9ed0-4c0e-8ff6-94e306500285",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_100 = api.load(\"glove-wiki-gigaword-100\")\n",
    "# word2vec = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286c271-5b80-47dd-996c-2e670107faf0",
   "metadata": {},
   "source": [
    "### Encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f6a85c5-c9e8-46e0-bd88-a26adff13328",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = SentenceUtils.tags(train_ds_handler.sentences)\n",
    "pos_tags = set()\n",
    "\n",
    "for sentence_tags in tags:\n",
    "    for tag in sentence_tags:\n",
    "        pos_tags.add(tag)\n",
    "\n",
    "tag2id = {tag: idx for (idx, tag) in enumerate(pos_tags)}\n",
    "pos_tags_encoder = LabelBinarizer()\n",
    "tags_encoded = pos_tags_encoder.fit_transform(list(tag2id.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f22e6-9ed6-4cc1-9e42-c56d7f89b94c",
   "metadata": {},
   "source": [
    "### Feature engineering (using the pretrained embeddings)\n",
    "\n",
    "In this section a class named `Featurizer` is created. This class is responsible to encode, the given center word and its context/window words, as a single vector.\\\n",
    "The `window_size` and the `embeddings_model` are parameterizable in order to facilitate experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dab0b08a-ed2d-41ca-b767-f01b19ee0d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Featurizer:\n",
    "    def __init__(self, embeddings_model, tag2id, tags_encoded):\n",
    "        self.embeddings_model = embeddings_model\n",
    "        self.dimensionality = embeddings_model.vectors.shape[-1]\n",
    "        # padding for start/end of sentence\n",
    "        self.pad_vector = np.zeros(self.dimensionality)\n",
    "        # oov vector signifies a given word that was not present in the embeddings model\n",
    "        min_value = np.min(embeddings_model.vectors)\n",
    "        self.oov_vector = np.array([min_value - 10.0] * self.dimensionality)\n",
    "        self.tag2id = tag2id\n",
    "        self.tags_encoded = tags_encoded\n",
    "\n",
    "    def process(self, sentence, position, window_size=1):\n",
    "        \"\"\" Convert a word and its context into a vector.\n",
    "\n",
    "        The method used, is concatenation (not the summation)\n",
    "        \n",
    "        Args:\n",
    "            sentence: A list of string words\n",
    "            position: Integer position of the center word\n",
    "            window_size: The size of window/words before and after the center word\n",
    "        \"\"\"\n",
    "        featurized = np.array([])\n",
    "        \n",
    "        for idx in range(position - window_size, position + window_size + 1):\n",
    "            if idx < 0:\n",
    "                featurized = np.append(featurized, self.pad_vector)\n",
    "                continue\n",
    "            if idx > len(sentence) - 1:\n",
    "                featurized = np.append(featurized, self.pad_vector)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                featurized = np.append(featurized, self.embeddings_model[sentence[idx]])\n",
    "            except KeyError:\n",
    "                featurized = np.append(featurized, self.oov_vector)\n",
    "\n",
    "        return featurized\n",
    "\n",
    "    def process_dataset(self, dataset, window_size=1):\n",
    "        \"\"\"\n",
    "            Process a dataset (train/val/test) by featurizing\n",
    "            the words of its sentences.\n",
    "\n",
    "            Args:\n",
    "                dataset: A list of sentences. Each sentence is represented\n",
    "                    as a list of tuples, where a tuple contains a word as\n",
    "                    the first element and the POS tag as a second element.\n",
    "                window_size: The size of window/words before and after the center word\n",
    "        \"\"\"\n",
    "        X, y = [], []\n",
    "\n",
    "        for doc_index, tagged_sentence in enumerate(dataset):\n",
    "            sentence_words = SentenceUtils.tokens_of(tagged_sentence)\n",
    "            sentence_tags = SentenceUtils.pos_of(tagged_sentence)\n",
    "            \n",
    "            for word_index in range(len(tagged_sentence)):\n",
    "                featurized = self.process(sentence_words, word_index, window_size)\n",
    "                tag_id = self.tag2id[sentence_tags[word_index]]\n",
    "                tag_encoded = self.tags_encoded[tag_id]\n",
    "\n",
    "                X.append(featurized)\n",
    "                y.append(tag_encoded)\n",
    "\n",
    "        return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cbdf1ed-f2c9-4d79-a5e7-ccff9c45cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example to check the correctness of the output shape of featurizer.process\n",
    "featurizer = Featurizer(glove_100, tag2id, tags_encoded)\n",
    "example = SentenceUtils.tokens_of(train_ds_handler.sentences[100])\n",
    "\n",
    "featurized_example_1 = featurizer.process(example, 5, window_size=1)\n",
    "assert featurized_example_1.shape[0] == featurizer.dimensionality * 3\n",
    "\n",
    "featurized_example_2 = featurizer.process(example, 5, window_size=2)\n",
    "assert featurized_example_2.shape[0] == featurizer.dimensionality * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce9ca5d-5fcd-4242-a6b4-c33599c50f42",
   "metadata": {},
   "source": [
    "### MLP tuning\n",
    "\n",
    "In this section a class named `MLPTaggerTuner` is responsible for tuning hyper-parameters, given a window_size.\\\n",
    "The values of window_size tested are: 0, 1, 3, 5. \\\n",
    "The hyperparameters tuned include:\n",
    "\n",
    "- number of layers (with possible values: 1, 2, 3)\n",
    "- number of hidden units for a layer (min: 128, max: 512, step=64)\n",
    "- dropout probability (with possible values: 0.1, 0.2, 0.3, 0.4, 0.5)\n",
    "- learning rate (with possible values: 0.01, 0.001, 0.0001)\n",
    "\n",
    "Tuning is achieved using `keras-tuner`, with 10 maximum trials, 30 epochs and batch size of 128.\n",
    "The objective of the tuner is to maximize the validation categorical accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "322c99f5-8f09-4a0a-bff3-7e0853833db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPTaggerTuner:\n",
    "    def __init__(self, train_sentences, dev_sentences, featurizer, window_size, train_size=0.5, seed=seed):\n",
    "        self.window_size = window_size\n",
    "        self.seed = seed\n",
    "\n",
    "        train_X, train_y = featurizer.process_dataset(train_sentences, window_size)\n",
    "        sample_size = int(len(train_X) * train_size)\n",
    "        \n",
    "        self.train_X = train_X[0:sample_size+1]\n",
    "        self.train_y = train_y[0:sample_size+1]\n",
    "\n",
    "        self.dev_X, self.dev_y = featurizer.process_dataset(dev_sentences, window_size)\n",
    "\n",
    "    def tune(self):\n",
    "        tuner = kt.RandomSearch(self.build_model, \n",
    "                                objective=kt.Objective(\"val_categorical_accuracy\", direction=\"max\"),\n",
    "                                max_trials = 10,\n",
    "                                seed=self.seed,\n",
    "                                directory='KT_dir',\n",
    "                                project_name=\"KT_pos_tuning_window_{}\".format(self.window_size))\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "        tuner.search(self.train_X, self.train_y,\n",
    "                     validation_data=(self.dev_X, self.dev_y),\n",
    "                     epochs=30, batch_size = 128,\n",
    "                     callbacks=[early_stopping])\n",
    "\n",
    "        return tuner\n",
    "\n",
    "    def build_model(self, hp):\n",
    "        model = Sequential()\n",
    "\n",
    "        layer_index = 0\n",
    "\n",
    "        for i in range(hp.Int(name='num_layers',min_value=1,max_value=3)):\n",
    "            if layer_index == 0:\n",
    "                model.add(Dense(hp.Int(name='hidden_units_'+str(i),min_value=128,max_value=512,step=64),\n",
    "                                activation=hp.Choice(name='activation_layer'+str(i),values=['relu','tanh']),\n",
    "                                input_dim=self.train_X.shape[1]\n",
    "                               ))\n",
    "                model.add(Dropout(hp.Choice(name='dropout_layer_'+str(i),values=[0.1,0.2,0.3,0.4,0.5])))\n",
    "            else:\n",
    "                model.add(Dense(hp.Int(name='hidden_units_'+str(i),min_value=128,max_value=512,step=64),\n",
    "                                activation=hp.Choice(name='activation_layer'+str(i),values=['relu','tanh'])))\n",
    "                model.add(Dropout(hp.Choice(name='dropout_layer_'+str(i),values=[0.1,0.2,0.3,0.4,0.5])))\n",
    "    \n",
    "            layer_index += 1\n",
    "\n",
    "        # Add last layer that produces the logits\n",
    "        model.add(Dense(self.train_y.shape[1],  activation='softmax'))\n",
    "    \n",
    "        # Tune the learning rate for the optimizer\n",
    "        # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "        hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "        model.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "                      metrics=[CategoricalAccuracy()])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea05caee-549a-4b18-acbc-dc836b763a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform tuning for window_size = 0\n",
    "# # Run this on Colab using GPU mode\n",
    "# mlp_tuner_window_0 = MLPTaggerTuner(train_ds_handler.sentences, dev_ds_handler.sentences, featurizer, 0, train_size=0.7)\n",
    "# tuner_0 = mlp_tuner_window_0.tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5bb9e2d-665d-43bc-8a53-be1da212e8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 02m 11s]\n",
      "val_categorical_accuracy: 0.9156102538108826\n",
      "\n",
      "Best val_categorical_accuracy So Far: 0.9376410245895386\n",
      "Total elapsed time: 00h 22m 24s\n"
     ]
    }
   ],
   "source": [
    "# Perform tuning for window_size = 1\n",
    "# Run this on Colab using GPU mode\n",
    "mlp_tuner_window_1 = MLPTaggerTuner(train_ds_handler.sentences, dev_ds_handler.sentences, featurizer, 1, train_size=0.7)\n",
    "tuner_1 = mlp_tuner_window_1.tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03e4b643-8245-44ac-b240-3c511d82a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform tuning for window_size = 3\n",
    "# # Run this on Colab using GPU mode\n",
    "# mlp_tuner_window_3 = MLPTaggerTuner(train_ds_handler.sentences, dev_ds_handler.sentences, featurizer, 3, train_size=0.7)\n",
    "# tuner_3 = mlp_tuner_window_3.tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d87f515-97fa-445b-8c97-b02de07798cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform tuning for window_size = 5\n",
    "# # Run this on Colab using GPU mode\n",
    "# mlp_tuner_window_5 = MLPTaggerTuner(train_ds_handler.sentences, dev_ds_handler.sentences, featurizer, 5, train_size=0.7)\n",
    "# tuner_5 = mlp_tuner_window_5.tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4354eb0c-1f64-4127-b271-32b486560724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 3,\n",
       " 'hidden_units_0': 192,\n",
       " 'activation_layer0': 'relu',\n",
       " 'dropout_layer_0': 0.2,\n",
       " 'learning_rate': 0.0001,\n",
       " 'hidden_units_1': 448,\n",
       " 'activation_layer1': 'relu',\n",
       " 'dropout_layer_1': 0.1,\n",
       " 'hidden_units_2': 256,\n",
       " 'activation_layer2': 'relu',\n",
       " 'dropout_layer_2': 0.1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the hyperparameters of the best tuner\n",
    "best_hyperparams = tuner_1.get_best_hyperparameters()[0].values\n",
    "\n",
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7076e534-52c2-4f7a-a168-2e9abaccc58f",
   "metadata": {},
   "source": [
    "### Evaluation Metrics Helper Class\n",
    "\n",
    "In this section a class named `EvaluationMetrics` is created that encapsulates a classification report given a dataset\n",
    "for a multi-class classification problem. It is used to report metrics on train, dev and test subsets.\n",
    "\n",
    "It reports (in the form of pandas dataframes) on:\n",
    "\n",
    "  - Precision\n",
    "  - Recall\n",
    "  - F1\n",
    "  - Precision-Recall AUC score\n",
    "  - Their Macro Averages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ca09007-f589-4810-b2a0-946be06518b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationMetrics:\n",
    "\n",
    "    @staticmethod\n",
    "    def classification_report(y_true, y_probabilities, y_predicted, class_ids, class_labels):\n",
    "        \"\"\" Creates a classification report for a multi-class classsification problem.\n",
    "\n",
    "        Note: Scikit-Learn's precision_recall_curve has its output reversed. See:\n",
    "        https://github.com/scikit-learn/scikit-learn/issues/2097\n",
    "        \n",
    "        Args:\n",
    "            y_true: A one dimensional array(n_samples), containing the actual class id per sample.\n",
    "            y_probabilities: A 2D array (n_samples, n_classes) containing the predicted probabilities\n",
    "                per sample.\n",
    "            y_predicted: A one dimensional array(n_samples) containing the predicted class id per sample.\n",
    "            class_ids: A one dimensional array (n_classes) containing the ids of classes.\n",
    "            class_labels: A one dimensional array (n_classes) containing the names of the classes.\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute precision (per class)\n",
    "        precision = precision_score(y_true, y_predicted, average=None)\n",
    "\n",
    "        # Compute recall (per class)\n",
    "        recall = recall_score(y_true, y_predicted, average=None)\n",
    "\n",
    "        # Compute F1 (per class)\n",
    "        f1 = f1_score(y_true, y_predicted, average=None)\n",
    "\n",
    "        # Compute Precision-Recall AUC score (per class)\n",
    "        auc_scores = []\n",
    "        for class_id in class_ids:\n",
    "            class_indices = (y_true == class_id)\n",
    "            if any(class_indices):\n",
    "                class_precision, class_recall, thresholds = precision_recall_curve(\n",
    "                    class_indices.astype(int), y_probabilities[:, class_id])\n",
    "                class_precision_recall_auc = auc(class_recall, class_precision)\n",
    "                auc_scores.append(class_precision_recall_auc)\n",
    "\n",
    "        classification_report_df = pd.DataFrame()\n",
    "        classification_report_df['Class Id'] = class_ids\n",
    "        classification_report_df['Class Name'] = class_labels\n",
    "        classification_report_df['Precision'] = precision\n",
    "        classification_report_df['Recall'] = recall\n",
    "        classification_report_df['F1'] = f1\n",
    "        classification_report_df['Precision-Recall AUC'] = auc_scores\n",
    "    \n",
    "        macro_average_df = pd.DataFrame()\n",
    "        macro_average_df['Macro Average Precision'] = [np.mean(precision)]\n",
    "        macro_average_df['Macro Average Recall'] = [np.mean(recall)]\n",
    "        macro_average_df['Macro Average F1'] = [np.mean(f1)]\n",
    "        macro_average_df['Macro Average Precision Recall AUC'] = [np.mean(auc_scores)]\n",
    "    \n",
    "        return (classification_report_df, macro_average_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ad69e3-f3ea-40f6-8ce2-5f34ddeb9fb2",
   "metadata": {},
   "source": [
    "### MLP modeling\n",
    "\n",
    "In this section the class `MLPTagger` is introduced. This class contains methods for:\n",
    "- fitting a model (constructing first the next architecture from a dictionary)\n",
    "- predicting pos tags, given a set of sentences\n",
    "- plotting curves (train/dev loss and train/dev accuracy vs epochs)\n",
    "- generating a classification report (for the predictions)\n",
    "\n",
    "During training we monitor categorical accuracy, loss and f1.\\\n",
    "A `Metrics` class (taken from the course labs) is responsible for recording\n",
    "f1, precision and recall in the dev (validation) set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ea8cf36-56ee-4ec3-aa3d-cb3435c63edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics class (taken from course labs)\n",
    "# is added as a callback during training\n",
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, valid_data):\n",
    "        super(Metrics, self).__init__()\n",
    "        self.validation_data = valid_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val_predict = np.argmax(self.model.predict(self.validation_data[0]), -1)\n",
    "        val_targ = self.validation_data[1]\n",
    "        val_targ = tf.cast(val_targ,dtype=tf.float32)\n",
    "        # If val_targ is 1-hot\n",
    "        if len(val_targ.shape) == 2 and val_targ.shape[1] != 1:\n",
    "          val_targ = np.argmax(val_targ, -1)\n",
    "\n",
    "        _val_f1 = f1_score(val_targ, val_predict,average=\"weighted\")\n",
    "        _val_recall = recall_score(val_targ, val_predict,average=\"weighted\")\n",
    "        _val_precision = precision_score(val_targ, val_predict,average=\"weighted\")\n",
    "\n",
    "        logs['val_f1'] = _val_f1\n",
    "        logs['val_recall'] = _val_recall\n",
    "        logs['val_precision'] = _val_precision\n",
    "        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" % (_val_f1, _val_precision, _val_recall))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89603bef-abc0-4dd7-816e-295ea77beaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPTagger:\n",
    "    def __init__(self, featurizer, window_size):\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.featurizer = featurizer\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def fit(self, train_set, dev_set, hyperparams):\n",
    "        train_X, train_y = featurizer.process_dataset(train_set, self.window_size)\n",
    "        dev_X, dev_y = featurizer.process_dataset(dev_set, self.window_size)\n",
    "\n",
    "        self.build_model(hyperparams, train_X.shape[-1], train_y.shape[-1])\n",
    "\n",
    "        if not os.path.exists('./checkpoints'):\n",
    "            os.makedirs('./checkpoints')\n",
    "\n",
    "        checkpoint = ModelCheckpoint('checkpoints/mlp_pos_tagger.weights.h5',\n",
    "                                     monitor='val_f1',\n",
    "                                     mode='max', verbose=2,\n",
    "                                     save_best_only=True,\n",
    "                                     save_weights_only=True)\n",
    "\n",
    "        early_stopping = EarlyStopping(patience=10, verbose=2,\n",
    "                                       restore_best_weights=True,\n",
    "                                       monitor='val_f1', mode='max')\n",
    "\n",
    "        self.history = self.model.fit(train_X, train_y,\n",
    "                            validation_data=(dev_X, dev_y),\n",
    "                            batch_size=128, epochs=100, shuffle=True,\n",
    "                            callbacks=[Metrics(valid_data=(dev_X, dev_y)),\n",
    "                                       checkpoint, early_stopping])\n",
    "\n",
    "    def classification_report(self, dataset):\n",
    "        \"\"\" Create a classification report for a given dataset.\"\"\"\n",
    "        data_X, data_y = self.featurizer.process_dataset(dataset, self.window_size)\n",
    "        y_true = np.argmax(data_y, -1)\n",
    "        y_probabilities = self.model.predict(data_X)\n",
    "        y_predicted = np.argmax(y_probabilities.copy(), -1)\n",
    "        class_ids = list(self.featurizer.tag2id.values())\n",
    "        class_labels = list(self.featurizer.tag2id.keys())\n",
    "\n",
    "        return EvaluationMetrics.classification_report(y_true, y_probabilities, y_predicted, \n",
    "                                                       class_ids, class_labels)\n",
    "\n",
    "    def plot_curves(self):\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "        # summarize history for accuracy\n",
    "        axs[0].plot(self.history.history['categorical_accuracy'])\n",
    "        axs[0].plot(self.history.history['val_categorical_accuracy'])\n",
    "        axs[0].set_title('model accuracy')\n",
    "        axs[0].set_ylabel('accuracy')\n",
    "        axs[0].set_xlabel('epoch')\n",
    "        axs[0].legend(['train', 'dev'], loc='upper left')\n",
    "        axs[0].set_xticks(range(1,len(self.history.history['categorical_accuracy'])+1,4))\n",
    "    \n",
    "        # summarize history for loss\n",
    "        axs[1].plot(self.history.history['loss'])\n",
    "        axs[1].plot(self.history.history['val_loss'])\n",
    "        axs[1].set_title('model loss')\n",
    "        axs[1].set_ylabel('loss')\n",
    "        axs[1].set_xlabel('epoch')\n",
    "        axs[1].legend(['train', 'dev'], loc='upper right')\n",
    "        axs[1].set_xticks(range(1,len(self.history.history['loss'])+1,4))\n",
    "    \n",
    "        # # space between the plots\n",
    "        plt.tight_layout()\n",
    "     \n",
    "        # show plot\n",
    "        plt.show()\n",
    "\n",
    "    def build_model(self, hyperparams, input_dim, output_dim):\n",
    "        self.model = Sequential()\n",
    "\n",
    "        layer_index = 0\n",
    "\n",
    "        num_layers = hyperparams.get('num_layers')\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            hidden_units = hyperparams.get('hidden_units_'+str(i))\n",
    "            activation = hyperparams.get('activation_layer'+str(i))\n",
    "            dropout_proba = hyperparams.get('dropout_layer_'+str(i))\n",
    "\n",
    "            if layer_index == 0:\n",
    "                self.model.add(Dense(hidden_units, input_dim=input_dim,\n",
    "                                name='hidden_units_'+str(i),\n",
    "                                activation=activation))\n",
    "                self.model.add(Dropout(dropout_proba, name='dropout_layer_'+str(i)))\n",
    "            else:\n",
    "                self.model.add(Dense(hidden_units,\n",
    "                                name='hidden_units_'+str(i),\n",
    "                                activation=activation))\n",
    "                self.model.add(Dropout(dropout_proba, name='dropout_layer_'+str(i)))\n",
    "    \n",
    "            layer_index += 1\n",
    "\n",
    "        # Add last layer that produces the logits\n",
    "        self.model.add(Dense(output_dim, activation='softmax'))\n",
    "    \n",
    "        # Tune the learning rate for the optimizer\n",
    "        learning_rate = hyperparams.get('learning_rate')\n",
    "        self.model.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=learning_rate),\n",
    "                      metrics=[CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c145c25-4ec4-4121-b105-cee37d375710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the MLP tagger\n",
    "mlp_tagger = MLPTagger(featurizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0af2758-6e8d-4870-bfa8-428a5f96a125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.798759 — val_precision: 0.806424 — val_recall: 0.812185\n",
      "\n",
      "Epoch 1: val_f1 improved from -inf to 0.79876, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 14s 11ms/step - loss: 1.2665 - categorical_accuracy: 0.6147 - val_loss: 0.6011 - val_categorical_accuracy: 0.8122 - val_f1: 0.7988 - val_recall: 0.8122 - val_precision: 0.8064\n",
      "Epoch 2/100\n",
      "  17/1305 [..............................] - ETA: 8s - loss: 0.7335 - categorical_accuracy: 0.7574"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konstantinos/miniconda3/envs/ds-aueb/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762/762 [==============================] - 1s 1ms/step loss\n",
      " — val_f1: 0.860360 — val_precision: 0.860404 — val_recall: 0.864328\n",
      "\n",
      "Epoch 2: val_f1 improved from 0.79876 to 0.86036, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 14s 11ms/step - loss: 0.6316 - categorical_accuracy: 0.7980 - val_loss: 0.4343 - val_categorical_accuracy: 0.8643 - val_f1: 0.8604 - val_recall: 0.8643 - val_precision: 0.8604\n",
      "Epoch 3/100\n",
      "  16/1305 [..............................] - ETA: 8s - loss: 0.5773 - categorical_accuracy: 0.8179"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konstantinos/miniconda3/envs/ds-aueb/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.884323 — val_precision: 0.884736 — val_recall: 0.887015\n",
      "\n",
      "Epoch 3: val_f1 improved from 0.86036 to 0.88432, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 16s 12ms/step - loss: 0.5087 - categorical_accuracy: 0.8366 - val_loss: 0.3615 - val_categorical_accuracy: 0.8870 - val_f1: 0.8843 - val_recall: 0.8870 - val_precision: 0.8847\n",
      "Epoch 4/100\n",
      "  15/1305 [..............................] - ETA: 9s - loss: 0.4728 - categorical_accuracy: 0.8495"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konstantinos/miniconda3/envs/ds-aueb/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762/762 [==============================] - 2s 2ms/step\n",
      " — val_f1: 0.891418 — val_precision: 0.892240 — val_recall: 0.893005\n",
      "\n",
      "Epoch 4: val_f1 improved from 0.88432 to 0.89142, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 14s 11ms/step - loss: 0.4391 - categorical_accuracy: 0.8595 - val_loss: 0.3399 - val_categorical_accuracy: 0.8930 - val_f1: 0.8914 - val_recall: 0.8930 - val_precision: 0.8922\n",
      "Epoch 5/100\n",
      "  16/1305 [..............................] - ETA: 8s - loss: 0.3978 - categorical_accuracy: 0.8711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konstantinos/miniconda3/envs/ds-aueb/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.903411 — val_precision: 0.904085 — val_recall: 0.905682\n",
      "\n",
      "Epoch 5: val_f1 improved from 0.89142 to 0.90341, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.3938 - categorical_accuracy: 0.8739 - val_loss: 0.2972 - val_categorical_accuracy: 0.9057 - val_f1: 0.9034 - val_recall: 0.9057 - val_precision: 0.9041\n",
      "Epoch 6/100\n",
      "   9/1305 [..............................] - ETA: 17s - loss: 0.3777 - categorical_accuracy: 0.8819"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konstantinos/miniconda3/envs/ds-aueb/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.910840 — val_precision: 0.911196 — val_recall: 0.912246\n",
      "\n",
      "Epoch 6: val_f1 improved from 0.90341 to 0.91084, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 15s 11ms/step - loss: 0.3589 - categorical_accuracy: 0.8851 - val_loss: 0.2763 - val_categorical_accuracy: 0.9122 - val_f1: 0.9108 - val_recall: 0.9122 - val_precision: 0.9112\n",
      "Epoch 7/100\n",
      "762/762 [==============================] - 1s 1ms/step \n",
      " — val_f1: 0.913765 — val_precision: 0.913998 — val_recall: 0.914708\n",
      "\n",
      "Epoch 7: val_f1 improved from 0.91084 to 0.91377, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 14s 11ms/step - loss: 0.3369 - categorical_accuracy: 0.8918 - val_loss: 0.2629 - val_categorical_accuracy: 0.9147 - val_f1: 0.9138 - val_recall: 0.9147 - val_precision: 0.9140\n",
      "Epoch 8/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.920410 — val_precision: 0.920785 — val_recall: 0.921231\n",
      "\n",
      "Epoch 8: val_f1 improved from 0.91377 to 0.92041, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 16s 12ms/step - loss: 0.3166 - categorical_accuracy: 0.8985 - val_loss: 0.2462 - val_categorical_accuracy: 0.9212 - val_f1: 0.9204 - val_recall: 0.9212 - val_precision: 0.9208\n",
      "Epoch 9/100\n",
      "762/762 [==============================] - 2s 2ms/step\n",
      " — val_f1: 0.921737 — val_precision: 0.922016 — val_recall: 0.922913\n",
      "\n",
      "Epoch 9: val_f1 improved from 0.92041 to 0.92174, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 17s 13ms/step - loss: 0.2975 - categorical_accuracy: 0.9039 - val_loss: 0.2387 - val_categorical_accuracy: 0.9229 - val_f1: 0.9217 - val_recall: 0.9229 - val_precision: 0.9220\n",
      "Epoch 10/100\n",
      "762/762 [==============================] - 1s 1ms/step\n",
      " — val_f1: 0.926722 — val_precision: 0.927272 — val_recall: 0.927877\n",
      "\n",
      "Epoch 10: val_f1 improved from 0.92174 to 0.92672, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 14s 11ms/step - loss: 0.2849 - categorical_accuracy: 0.9072 - val_loss: 0.2262 - val_categorical_accuracy: 0.9279 - val_f1: 0.9267 - val_recall: 0.9279 - val_precision: 0.9273\n",
      "Epoch 11/100\n",
      "762/762 [==============================] - 1s 1ms/step lo\n",
      " — val_f1: 0.928171 — val_precision: 0.928283 — val_recall: 0.928779\n",
      "\n",
      "Epoch 11: val_f1 improved from 0.92672 to 0.92817, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 15s 11ms/step - loss: 0.2724 - categorical_accuracy: 0.9122 - val_loss: 0.2184 - val_categorical_accuracy: 0.9288 - val_f1: 0.9282 - val_recall: 0.9288 - val_precision: 0.9283\n",
      "Epoch 12/100\n",
      "762/762 [==============================] - 1s 1ms/step \n",
      " — val_f1: 0.930133 — val_precision: 0.930330 — val_recall: 0.930913\n",
      "\n",
      "Epoch 12: val_f1 improved from 0.92817 to 0.93013, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 16s 12ms/step - loss: 0.2613 - categorical_accuracy: 0.9158 - val_loss: 0.2132 - val_categorical_accuracy: 0.9309 - val_f1: 0.9301 - val_recall: 0.9309 - val_precision: 0.9303\n",
      "Epoch 13/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.932344 — val_precision: 0.932658 — val_recall: 0.933005\n",
      "\n",
      "Epoch 13: val_f1 improved from 0.93013 to 0.93234, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 14s 11ms/step - loss: 0.2507 - categorical_accuracy: 0.9188 - val_loss: 0.2068 - val_categorical_accuracy: 0.9330 - val_f1: 0.9323 - val_recall: 0.9330 - val_precision: 0.9327\n",
      "Epoch 14/100\n",
      "762/762 [==============================] - 2s 2ms/step\n",
      " — val_f1: 0.931848 — val_precision: 0.931837 — val_recall: 0.932431\n",
      "\n",
      "Epoch 14: val_f1 did not improve from 0.93234\n",
      "1305/1305 [==============================] - 16s 12ms/step - loss: 0.2426 - categorical_accuracy: 0.9212 - val_loss: 0.2035 - val_categorical_accuracy: 0.9324 - val_f1: 0.9318 - val_recall: 0.9324 - val_precision: 0.9318\n",
      "Epoch 15/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.932580 — val_precision: 0.932442 — val_recall: 0.933251\n",
      "\n",
      "Epoch 15: val_f1 improved from 0.93234 to 0.93258, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 15s 11ms/step - loss: 0.2355 - categorical_accuracy: 0.9237 - val_loss: 0.2033 - val_categorical_accuracy: 0.9333 - val_f1: 0.9326 - val_recall: 0.9333 - val_precision: 0.9324\n",
      "Epoch 16/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.936076 — val_precision: 0.936565 — val_recall: 0.936985\n",
      "\n",
      "Epoch 16: val_f1 improved from 0.93258 to 0.93608, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 17s 13ms/step - loss: 0.2279 - categorical_accuracy: 0.9251 - val_loss: 0.1957 - val_categorical_accuracy: 0.9370 - val_f1: 0.9361 - val_recall: 0.9370 - val_precision: 0.9366\n",
      "Epoch 17/100\n",
      "762/762 [==============================] - 1s 1ms/step \n",
      " — val_f1: 0.936897 — val_precision: 0.937251 — val_recall: 0.937395\n",
      "\n",
      "Epoch 17: val_f1 improved from 0.93608 to 0.93690, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 15s 11ms/step - loss: 0.2199 - categorical_accuracy: 0.9287 - val_loss: 0.1910 - val_categorical_accuracy: 0.9374 - val_f1: 0.9369 - val_recall: 0.9374 - val_precision: 0.9373\n",
      "Epoch 18/100\n",
      "762/762 [==============================] - 1s 1ms/step \n",
      " — val_f1: 0.938304 — val_precision: 0.938595 — val_recall: 0.938667\n",
      "\n",
      "Epoch 18: val_f1 improved from 0.93690 to 0.93830, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.2145 - categorical_accuracy: 0.9298 - val_loss: 0.1907 - val_categorical_accuracy: 0.9387 - val_f1: 0.9383 - val_recall: 0.9387 - val_precision: 0.9386\n",
      "Epoch 19/100\n",
      "762/762 [==============================] - 1s 1ms/step loss: \n",
      " — val_f1: 0.937994 — val_precision: 0.938288 — val_recall: 0.938667\n",
      "\n",
      "Epoch 19: val_f1 did not improve from 0.93830\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.2083 - categorical_accuracy: 0.9322 - val_loss: 0.1873 - val_categorical_accuracy: 0.9387 - val_f1: 0.9380 - val_recall: 0.9387 - val_precision: 0.9383\n",
      "Epoch 20/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.936774 — val_precision: 0.937287 — val_recall: 0.937641\n",
      "\n",
      "Epoch 20: val_f1 did not improve from 0.93830\n",
      "1305/1305 [==============================] - 16s 12ms/step - loss: 0.2050 - categorical_accuracy: 0.9327 - val_loss: 0.1888 - val_categorical_accuracy: 0.9376 - val_f1: 0.9368 - val_recall: 0.9376 - val_precision: 0.9373\n",
      "Epoch 21/100\n",
      "762/762 [==============================] - 1s 1ms/step loss\n",
      " — val_f1: 0.940848 — val_precision: 0.940890 — val_recall: 0.941333\n",
      "\n",
      "Epoch 21: val_f1 improved from 0.93830 to 0.94085, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 14s 11ms/step - loss: 0.1996 - categorical_accuracy: 0.9345 - val_loss: 0.1823 - val_categorical_accuracy: 0.9413 - val_f1: 0.9408 - val_recall: 0.9413 - val_precision: 0.9409\n",
      "Epoch 22/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.938752 — val_precision: 0.938615 — val_recall: 0.939323\n",
      "\n",
      "Epoch 22: val_f1 did not improve from 0.94085\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1957 - categorical_accuracy: 0.9360 - val_loss: 0.1820 - val_categorical_accuracy: 0.9393 - val_f1: 0.9388 - val_recall: 0.9393 - val_precision: 0.9386\n",
      "Epoch 23/100\n",
      "762/762 [==============================] - 1s 1ms/step \n",
      " — val_f1: 0.941030 — val_precision: 0.941016 — val_recall: 0.941497\n",
      "\n",
      "Epoch 23: val_f1 improved from 0.94085 to 0.94103, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 15s 11ms/step - loss: 0.1903 - categorical_accuracy: 0.9375 - val_loss: 0.1787 - val_categorical_accuracy: 0.9415 - val_f1: 0.9410 - val_recall: 0.9415 - val_precision: 0.9410\n",
      "Epoch 24/100\n",
      "762/762 [==============================] - 1s 1ms/step lo\n",
      " — val_f1: 0.940681 — val_precision: 0.940820 — val_recall: 0.941169\n",
      "\n",
      "Epoch 24: val_f1 did not improve from 0.94103\n",
      "1305/1305 [==============================] - 14s 11ms/step - loss: 0.1873 - categorical_accuracy: 0.9387 - val_loss: 0.1779 - val_categorical_accuracy: 0.9412 - val_f1: 0.9407 - val_recall: 0.9412 - val_precision: 0.9408\n",
      "Epoch 25/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.941387 — val_precision: 0.941400 — val_recall: 0.941826\n",
      "\n",
      "Epoch 25: val_f1 improved from 0.94103 to 0.94139, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1878 - categorical_accuracy: 0.9382 - val_loss: 0.1773 - val_categorical_accuracy: 0.9418 - val_f1: 0.9414 - val_recall: 0.9418 - val_precision: 0.9414\n",
      "Epoch 26/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.941821 — val_precision: 0.942230 — val_recall: 0.942564\n",
      "\n",
      "Epoch 26: val_f1 improved from 0.94139 to 0.94182, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 15s 12ms/step - loss: 0.1816 - categorical_accuracy: 0.9399 - val_loss: 0.1765 - val_categorical_accuracy: 0.9426 - val_f1: 0.9418 - val_recall: 0.9426 - val_precision: 0.9422\n",
      "Epoch 27/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.944217 — val_precision: 0.944348 — val_recall: 0.944862\n",
      "\n",
      "Epoch 27: val_f1 improved from 0.94182 to 0.94422, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 17s 13ms/step - loss: 0.1785 - categorical_accuracy: 0.9405 - val_loss: 0.1712 - val_categorical_accuracy: 0.9449 - val_f1: 0.9442 - val_recall: 0.9449 - val_precision: 0.9443\n",
      "Epoch 28/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.944336 — val_precision: 0.944451 — val_recall: 0.944944\n",
      "\n",
      "Epoch 28: val_f1 improved from 0.94422 to 0.94434, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 14s 11ms/step - loss: 0.1774 - categorical_accuracy: 0.9412 - val_loss: 0.1712 - val_categorical_accuracy: 0.9449 - val_f1: 0.9443 - val_recall: 0.9449 - val_precision: 0.9445\n",
      "Epoch 29/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.943417 — val_precision: 0.943534 — val_recall: 0.943959\n",
      "\n",
      "Epoch 29: val_f1 did not improve from 0.94434\n",
      "1305/1305 [==============================] - 16s 12ms/step - loss: 0.1715 - categorical_accuracy: 0.9431 - val_loss: 0.1698 - val_categorical_accuracy: 0.9440 - val_f1: 0.9434 - val_recall: 0.9440 - val_precision: 0.9435\n",
      "Epoch 30/100\n",
      "762/762 [==============================] - 1s 1ms/step loss: 0.\n",
      " — val_f1: 0.943905 — val_precision: 0.943865 — val_recall: 0.944164\n",
      "\n",
      "Epoch 30: val_f1 did not improve from 0.94434\n",
      "1305/1305 [==============================] - 15s 11ms/step - loss: 0.1684 - categorical_accuracy: 0.9445 - val_loss: 0.1698 - val_categorical_accuracy: 0.9442 - val_f1: 0.9439 - val_recall: 0.9442 - val_precision: 0.9439\n",
      "Epoch 31/100\n",
      "762/762 [==============================] - 1s 1ms/step lo\n",
      " — val_f1: 0.943476 — val_precision: 0.943841 — val_recall: 0.944123\n",
      "\n",
      "Epoch 31: val_f1 did not improve from 0.94434\n",
      "1305/1305 [==============================] - 14s 10ms/step - loss: 0.1650 - categorical_accuracy: 0.9453 - val_loss: 0.1697 - val_categorical_accuracy: 0.9441 - val_f1: 0.9435 - val_recall: 0.9441 - val_precision: 0.9438\n",
      "Epoch 32/100\n",
      "762/762 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.942989 — val_precision: 0.943072 — val_recall: 0.943467\n",
      "\n",
      "Epoch 32: val_f1 did not improve from 0.94434\n",
      "1305/1305 [==============================] - 17s 13ms/step - loss: 0.1639 - categorical_accuracy: 0.9460 - val_loss: 0.1717 - val_categorical_accuracy: 0.9435 - val_f1: 0.9430 - val_recall: 0.9435 - val_precision: 0.9431\n",
      "Epoch 33/100\n",
      "762/762 [==============================] - 1s 1ms/step lo\n",
      " — val_f1: 0.943921 — val_precision: 0.943854 — val_recall: 0.944533\n",
      "\n",
      "Epoch 33: val_f1 did not improve from 0.94434\n",
      "1305/1305 [==============================] - 14s 11ms/step - loss: 0.1613 - categorical_accuracy: 0.9465 - val_loss: 0.1702 - val_categorical_accuracy: 0.9445 - val_f1: 0.9439 - val_recall: 0.9445 - val_precision: 0.9439\n",
      "Epoch 34/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.945138 — val_precision: 0.945132 — val_recall: 0.945600\n",
      "\n",
      "Epoch 34: val_f1 improved from 0.94434 to 0.94514, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 17s 13ms/step - loss: 0.1584 - categorical_accuracy: 0.9473 - val_loss: 0.1664 - val_categorical_accuracy: 0.9456 - val_f1: 0.9451 - val_recall: 0.9456 - val_precision: 0.9451\n",
      "Epoch 35/100\n",
      "762/762 [==============================] - 1s 1ms/step loss\n",
      " — val_f1: 0.943279 — val_precision: 0.943422 — val_recall: 0.943426\n",
      "\n",
      "Epoch 35: val_f1 did not improve from 0.94514\n",
      "1305/1305 [==============================] - 15s 11ms/step - loss: 0.1557 - categorical_accuracy: 0.9483 - val_loss: 0.1711 - val_categorical_accuracy: 0.9434 - val_f1: 0.9433 - val_recall: 0.9434 - val_precision: 0.9434\n",
      "Epoch 36/100\n",
      "762/762 [==============================] - 1s 1ms/step los\n",
      " — val_f1: 0.945665 — val_precision: 0.945724 — val_recall: 0.946174\n",
      "\n",
      "Epoch 36: val_f1 improved from 0.94514 to 0.94566, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 12s 9ms/step - loss: 0.1535 - categorical_accuracy: 0.9487 - val_loss: 0.1661 - val_categorical_accuracy: 0.9462 - val_f1: 0.9457 - val_recall: 0.9462 - val_precision: 0.9457\n",
      "Epoch 37/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.946412 — val_precision: 0.946483 — val_recall: 0.946872\n",
      "\n",
      "Epoch 37: val_f1 improved from 0.94566 to 0.94641, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 14s 11ms/step - loss: 0.1508 - categorical_accuracy: 0.9497 - val_loss: 0.1638 - val_categorical_accuracy: 0.9469 - val_f1: 0.9464 - val_recall: 0.9469 - val_precision: 0.9465\n",
      "Epoch 38/100\n",
      "762/762 [==============================] - 1s 1ms/step lo\n",
      " — val_f1: 0.946409 — val_precision: 0.946432 — val_recall: 0.946872\n",
      "\n",
      "Epoch 38: val_f1 did not improve from 0.94641\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1486 - categorical_accuracy: 0.9505 - val_loss: 0.1618 - val_categorical_accuracy: 0.9469 - val_f1: 0.9464 - val_recall: 0.9469 - val_precision: 0.9464\n",
      "Epoch 39/100\n",
      "762/762 [==============================] - 1s 1ms/step loss\n",
      " — val_f1: 0.945899 — val_precision: 0.945885 — val_recall: 0.946297\n",
      "\n",
      "Epoch 39: val_f1 did not improve from 0.94641\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1475 - categorical_accuracy: 0.9503 - val_loss: 0.1644 - val_categorical_accuracy: 0.9463 - val_f1: 0.9459 - val_recall: 0.9463 - val_precision: 0.9459\n",
      "Epoch 40/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.944501 — val_precision: 0.944613 — val_recall: 0.945108\n",
      "\n",
      "Epoch 40: val_f1 did not improve from 0.94641\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1458 - categorical_accuracy: 0.9512 - val_loss: 0.1661 - val_categorical_accuracy: 0.9451 - val_f1: 0.9445 - val_recall: 0.9451 - val_precision: 0.9446\n",
      "Epoch 41/100\n",
      "762/762 [==============================] - 1s 1ms/step lo\n",
      " — val_f1: 0.945776 — val_precision: 0.945838 — val_recall: 0.946215\n",
      "\n",
      "Epoch 41: val_f1 did not improve from 0.94641\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1440 - categorical_accuracy: 0.9517 - val_loss: 0.1647 - val_categorical_accuracy: 0.9462 - val_f1: 0.9458 - val_recall: 0.9462 - val_precision: 0.9458\n",
      "Epoch 42/100\n",
      "762/762 [==============================] - 1s 1ms/step loss\n",
      " — val_f1: 0.946783 — val_precision: 0.946658 — val_recall: 0.947159\n",
      "\n",
      "Epoch 42: val_f1 improved from 0.94641 to 0.94678, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1408 - categorical_accuracy: 0.9529 - val_loss: 0.1647 - val_categorical_accuracy: 0.9472 - val_f1: 0.9468 - val_recall: 0.9472 - val_precision: 0.9467\n",
      "Epoch 43/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.947613 — val_precision: 0.947807 — val_recall: 0.948103\n",
      "\n",
      "Epoch 43: val_f1 improved from 0.94678 to 0.94761, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1394 - categorical_accuracy: 0.9535 - val_loss: 0.1613 - val_categorical_accuracy: 0.9481 - val_f1: 0.9476 - val_recall: 0.9481 - val_precision: 0.9478\n",
      "Epoch 44/100\n",
      "762/762 [==============================] - 1s 1ms/step lo\n",
      " — val_f1: 0.947528 — val_precision: 0.947703 — val_recall: 0.948144\n",
      "\n",
      "Epoch 44: val_f1 did not improve from 0.94761\n",
      "1305/1305 [==============================] - 11s 9ms/step - loss: 0.1361 - categorical_accuracy: 0.9541 - val_loss: 0.1626 - val_categorical_accuracy: 0.9481 - val_f1: 0.9475 - val_recall: 0.9481 - val_precision: 0.9477\n",
      "Epoch 45/100\n",
      "762/762 [==============================] - 1s 1ms/step lo\n",
      " — val_f1: 0.947430 — val_precision: 0.947526 — val_recall: 0.948021\n",
      "\n",
      "Epoch 45: val_f1 did not improve from 0.94761\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1358 - categorical_accuracy: 0.9543 - val_loss: 0.1613 - val_categorical_accuracy: 0.9480 - val_f1: 0.9474 - val_recall: 0.9480 - val_precision: 0.9475\n",
      "Epoch 46/100\n",
      "762/762 [==============================] - 1s 1ms/step\n",
      " — val_f1: 0.948178 — val_precision: 0.948096 — val_recall: 0.948677\n",
      "\n",
      "Epoch 46: val_f1 improved from 0.94761 to 0.94818, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 12s 9ms/step - loss: 0.1330 - categorical_accuracy: 0.9556 - val_loss: 0.1625 - val_categorical_accuracy: 0.9487 - val_f1: 0.9482 - val_recall: 0.9487 - val_precision: 0.9481\n",
      "Epoch 47/100\n",
      "762/762 [==============================] - 1s 1ms/step loss\n",
      " — val_f1: 0.946552 — val_precision: 0.946629 — val_recall: 0.946749\n",
      "\n",
      "Epoch 47: val_f1 did not improve from 0.94818\n",
      "1305/1305 [==============================] - 12s 9ms/step - loss: 0.1337 - categorical_accuracy: 0.9544 - val_loss: 0.1653 - val_categorical_accuracy: 0.9467 - val_f1: 0.9466 - val_recall: 0.9467 - val_precision: 0.9466\n",
      "Epoch 48/100\n",
      "762/762 [==============================] - 1s 1ms/step loss: \n",
      " — val_f1: 0.947421 — val_precision: 0.947555 — val_recall: 0.947733\n",
      "\n",
      "Epoch 48: val_f1 did not improve from 0.94818\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1319 - categorical_accuracy: 0.9552 - val_loss: 0.1628 - val_categorical_accuracy: 0.9477 - val_f1: 0.9474 - val_recall: 0.9477 - val_precision: 0.9476\n",
      "Epoch 49/100\n",
      "762/762 [==============================] - 2s 2ms/step\n",
      " — val_f1: 0.947779 — val_precision: 0.947881 — val_recall: 0.948349\n",
      "\n",
      "Epoch 49: val_f1 did not improve from 0.94818\n",
      "1305/1305 [==============================] - 12s 9ms/step - loss: 0.1295 - categorical_accuracy: 0.9563 - val_loss: 0.1618 - val_categorical_accuracy: 0.9483 - val_f1: 0.9478 - val_recall: 0.9483 - val_precision: 0.9479\n",
      "Epoch 50/100\n",
      "762/762 [==============================] - 1s 1ms/step loss: \n",
      " — val_f1: 0.947444 — val_precision: 0.947449 — val_recall: 0.947774\n",
      "\n",
      "Epoch 50: val_f1 did not improve from 0.94818\n",
      "1305/1305 [==============================] - 12s 9ms/step - loss: 0.1293 - categorical_accuracy: 0.9562 - val_loss: 0.1620 - val_categorical_accuracy: 0.9478 - val_f1: 0.9474 - val_recall: 0.9478 - val_precision: 0.9474\n",
      "Epoch 51/100\n",
      "762/762 [==============================] - 1s 1ms/step lo\n",
      " — val_f1: 0.948978 — val_precision: 0.948928 — val_recall: 0.949374\n",
      "\n",
      "Epoch 51: val_f1 improved from 0.94818 to 0.94898, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1266 - categorical_accuracy: 0.9571 - val_loss: 0.1615 - val_categorical_accuracy: 0.9494 - val_f1: 0.9490 - val_recall: 0.9494 - val_precision: 0.9489\n",
      "Epoch 52/100\n",
      "762/762 [==============================] - 1s 1ms/step \n",
      " — val_f1: 0.948454 — val_precision: 0.948599 — val_recall: 0.948841\n",
      "\n",
      "Epoch 52: val_f1 did not improve from 0.94898\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1254 - categorical_accuracy: 0.9572 - val_loss: 0.1634 - val_categorical_accuracy: 0.9488 - val_f1: 0.9485 - val_recall: 0.9488 - val_precision: 0.9486\n",
      "Epoch 53/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.947499 — val_precision: 0.947740 — val_recall: 0.948021\n",
      "\n",
      "Epoch 53: val_f1 did not improve from 0.94898\n",
      "1305/1305 [==============================] - 14s 10ms/step - loss: 0.1236 - categorical_accuracy: 0.9582 - val_loss: 0.1688 - val_categorical_accuracy: 0.9480 - val_f1: 0.9475 - val_recall: 0.9480 - val_precision: 0.9477\n",
      "Epoch 54/100\n",
      "762/762 [==============================] - 2s 2ms/step\n",
      " — val_f1: 0.949411 — val_precision: 0.949381 — val_recall: 0.949785\n",
      "\n",
      "Epoch 54: val_f1 improved from 0.94898 to 0.94941, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1224 - categorical_accuracy: 0.9583 - val_loss: 0.1627 - val_categorical_accuracy: 0.9498 - val_f1: 0.9494 - val_recall: 0.9498 - val_precision: 0.9494\n",
      "Epoch 55/100\n",
      "762/762 [==============================] - 1s 1ms/step lo\n",
      " — val_f1: 0.948825 — val_precision: 0.948907 — val_recall: 0.949251\n",
      "\n",
      "Epoch 55: val_f1 did not improve from 0.94941\n",
      "1305/1305 [==============================] - 12s 9ms/step - loss: 0.1208 - categorical_accuracy: 0.9590 - val_loss: 0.1649 - val_categorical_accuracy: 0.9493 - val_f1: 0.9488 - val_recall: 0.9493 - val_precision: 0.9489\n",
      "Epoch 56/100\n",
      "762/762 [==============================] - 1s 1ms/step \n",
      " — val_f1: 0.948879 — val_precision: 0.948971 — val_recall: 0.949374\n",
      "\n",
      "Epoch 56: val_f1 did not improve from 0.94941\n",
      "1305/1305 [==============================] - 14s 11ms/step - loss: 0.1197 - categorical_accuracy: 0.9596 - val_loss: 0.1645 - val_categorical_accuracy: 0.9494 - val_f1: 0.9489 - val_recall: 0.9494 - val_precision: 0.9490\n",
      "Epoch 57/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.947509 — val_precision: 0.947512 — val_recall: 0.948062\n",
      "\n",
      "Epoch 57: val_f1 did not improve from 0.94941\n",
      "1305/1305 [==============================] - 14s 10ms/step - loss: 0.1187 - categorical_accuracy: 0.9597 - val_loss: 0.1666 - val_categorical_accuracy: 0.9481 - val_f1: 0.9475 - val_recall: 0.9481 - val_precision: 0.9475\n",
      "Epoch 58/100\n",
      "762/762 [==============================] - 1s 1ms/step lo\n",
      " — val_f1: 0.950290 — val_precision: 0.950248 — val_recall: 0.950728\n",
      "\n",
      "Epoch 58: val_f1 improved from 0.94941 to 0.95029, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 15s 11ms/step - loss: 0.1179 - categorical_accuracy: 0.9602 - val_loss: 0.1641 - val_categorical_accuracy: 0.9507 - val_f1: 0.9503 - val_recall: 0.9507 - val_precision: 0.9502\n",
      "Epoch 59/100\n",
      "762/762 [==============================] - 1s 1ms/step lo\n",
      " — val_f1: 0.948803 — val_precision: 0.948733 — val_recall: 0.949292\n",
      "\n",
      "Epoch 59: val_f1 did not improve from 0.95029\n",
      "1305/1305 [==============================] - 14s 11ms/step - loss: 0.1162 - categorical_accuracy: 0.9605 - val_loss: 0.1660 - val_categorical_accuracy: 0.9493 - val_f1: 0.9488 - val_recall: 0.9493 - val_precision: 0.9487\n",
      "Epoch 60/100\n",
      "762/762 [==============================] - 1s 1ms/step\n",
      " — val_f1: 0.949391 — val_precision: 0.949357 — val_recall: 0.949703\n",
      "\n",
      "Epoch 60: val_f1 did not improve from 0.95029\n",
      "1305/1305 [==============================] - 14s 10ms/step - loss: 0.1156 - categorical_accuracy: 0.9605 - val_loss: 0.1642 - val_categorical_accuracy: 0.9497 - val_f1: 0.9494 - val_recall: 0.9497 - val_precision: 0.9494\n",
      "Epoch 61/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.950118 — val_precision: 0.950153 — val_recall: 0.950687\n",
      "\n",
      "Epoch 61: val_f1 did not improve from 0.95029\n",
      "1305/1305 [==============================] - 14s 10ms/step - loss: 0.1136 - categorical_accuracy: 0.9611 - val_loss: 0.1649 - val_categorical_accuracy: 0.9507 - val_f1: 0.9501 - val_recall: 0.9507 - val_precision: 0.9502\n",
      "Epoch 62/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.949944 — val_precision: 0.949927 — val_recall: 0.950359\n",
      "\n",
      "Epoch 62: val_f1 did not improve from 0.95029\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1138 - categorical_accuracy: 0.9612 - val_loss: 0.1653 - val_categorical_accuracy: 0.9504 - val_f1: 0.9499 - val_recall: 0.9504 - val_precision: 0.9499\n",
      "Epoch 63/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.950454 — val_precision: 0.950546 — val_recall: 0.950851\n",
      "\n",
      "Epoch 63: val_f1 improved from 0.95029 to 0.95045, saving model to checkpoints/mlp_pos_tagger.weights.h5\n",
      "1305/1305 [==============================] - 14s 11ms/step - loss: 0.1114 - categorical_accuracy: 0.9623 - val_loss: 0.1619 - val_categorical_accuracy: 0.9509 - val_f1: 0.9505 - val_recall: 0.9509 - val_precision: 0.9505\n",
      "Epoch 64/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.948055 — val_precision: 0.948125 — val_recall: 0.948636\n",
      "\n",
      "Epoch 64: val_f1 did not improve from 0.95045\n",
      "1305/1305 [==============================] - 12s 9ms/step - loss: 0.1110 - categorical_accuracy: 0.9621 - val_loss: 0.1729 - val_categorical_accuracy: 0.9486 - val_f1: 0.9481 - val_recall: 0.9486 - val_precision: 0.9481\n",
      "Epoch 65/100\n",
      "762/762 [==============================] - 2s 2ms/step\n",
      " — val_f1: 0.950147 — val_precision: 0.950169 — val_recall: 0.950564\n",
      "\n",
      "Epoch 65: val_f1 did not improve from 0.95045\n",
      "1305/1305 [==============================] - 14s 11ms/step - loss: 0.1097 - categorical_accuracy: 0.9624 - val_loss: 0.1649 - val_categorical_accuracy: 0.9506 - val_f1: 0.9501 - val_recall: 0.9506 - val_precision: 0.9502\n",
      "Epoch 66/100\n",
      "762/762 [==============================] - 1s 1ms/step\n",
      " — val_f1: 0.948299 — val_precision: 0.948398 — val_recall: 0.948882\n",
      "\n",
      "Epoch 66: val_f1 did not improve from 0.95045\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1087 - categorical_accuracy: 0.9629 - val_loss: 0.1692 - val_categorical_accuracy: 0.9489 - val_f1: 0.9483 - val_recall: 0.9489 - val_precision: 0.9484\n",
      "Epoch 67/100\n",
      "762/762 [==============================] - 1s 1ms/step lo\n",
      " — val_f1: 0.949333 — val_precision: 0.949611 — val_recall: 0.949867\n",
      "\n",
      "Epoch 67: val_f1 did not improve from 0.95045\n",
      "1305/1305 [==============================] - 14s 10ms/step - loss: 0.1084 - categorical_accuracy: 0.9633 - val_loss: 0.1670 - val_categorical_accuracy: 0.9499 - val_f1: 0.9493 - val_recall: 0.9499 - val_precision: 0.9496\n",
      "Epoch 68/100\n",
      "762/762 [==============================] - 1s 1ms/step lo\n",
      " — val_f1: 0.948844 — val_precision: 0.948940 — val_recall: 0.949415\n",
      "\n",
      "Epoch 68: val_f1 did not improve from 0.95045\n",
      "1305/1305 [==============================] - 14s 11ms/step - loss: 0.1056 - categorical_accuracy: 0.9637 - val_loss: 0.1671 - val_categorical_accuracy: 0.9494 - val_f1: 0.9488 - val_recall: 0.9494 - val_precision: 0.9489\n",
      "Epoch 69/100\n",
      "762/762 [==============================] - 1s 1ms/step loss: 0.\n",
      " — val_f1: 0.949597 — val_precision: 0.949537 — val_recall: 0.949867\n",
      "\n",
      "Epoch 69: val_f1 did not improve from 0.95045\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1074 - categorical_accuracy: 0.9632 - val_loss: 0.1676 - val_categorical_accuracy: 0.9499 - val_f1: 0.9496 - val_recall: 0.9499 - val_precision: 0.9495\n",
      "Epoch 70/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.950026 — val_precision: 0.949989 — val_recall: 0.950482\n",
      "\n",
      "Epoch 70: val_f1 did not improve from 0.95045\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1051 - categorical_accuracy: 0.9638 - val_loss: 0.1677 - val_categorical_accuracy: 0.9505 - val_f1: 0.9500 - val_recall: 0.9505 - val_precision: 0.9500\n",
      "Epoch 71/100\n",
      "762/762 [==============================] - 1s 1ms/step lo\n",
      " — val_f1: 0.949363 — val_precision: 0.949320 — val_recall: 0.949703\n",
      "\n",
      "Epoch 71: val_f1 did not improve from 0.95045\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1046 - categorical_accuracy: 0.9645 - val_loss: 0.1669 - val_categorical_accuracy: 0.9497 - val_f1: 0.9494 - val_recall: 0.9497 - val_precision: 0.9493\n",
      "Epoch 72/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.949502 — val_precision: 0.949456 — val_recall: 0.949826\n",
      "\n",
      "Epoch 72: val_f1 did not improve from 0.95045\n",
      "1305/1305 [==============================] - 14s 11ms/step - loss: 0.1042 - categorical_accuracy: 0.9643 - val_loss: 0.1692 - val_categorical_accuracy: 0.9498 - val_f1: 0.9495 - val_recall: 0.9498 - val_precision: 0.9495\n",
      "Epoch 73/100\n",
      "762/762 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.948830 — val_precision: 0.948821 — val_recall: 0.949169\n",
      "\n",
      "Epoch 73: val_f1 did not improve from 0.95045\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "1305/1305 [==============================] - 13s 10ms/step - loss: 0.1035 - categorical_accuracy: 0.9645 - val_loss: 0.1708 - val_categorical_accuracy: 0.9492 - val_f1: 0.9488 - val_recall: 0.9492 - val_precision: 0.9488\n",
      "Epoch 73: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "mlp_tagger.fit(train_ds_handler.sentences, dev_ds_handler.sentences, best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2a6632f-bfad-4589-9634-530104851f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_units_0 (Dense)      (None, 192)               57792     \n",
      "                                                                 \n",
      " dropout_layer_0 (Dropout)   (None, 192)               0         \n",
      "                                                                 \n",
      " hidden_units_1 (Dense)      (None, 448)               86464     \n",
      "                                                                 \n",
      " dropout_layer_1 (Dropout)   (None, 448)               0         \n",
      "                                                                 \n",
      " hidden_units_2 (Dense)      (None, 256)               114944    \n",
      "                                                                 \n",
      " dropout_layer_2 (Dropout)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 18)                4626      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 263,826\n",
      "Trainable params: 263,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_tagger.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb0d03ed-a598-46ff-94af-f88207f25b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAADJNklEQVR4nOzdeXhU9fn+8XtmMjPZExJCwhIg7CCrIKsUVxDFpdVKrYJYcMOKSNVKrRv1J1Wr4oq1iin9ulB3bdWKG6LIvskigoIJkBC27MkkmTm/P05mIGZPJplk8n5d17lmcubMmWeitTN3ns9zLIZhGAIAAAAAAACakTXQBQAAAAAAAKDtIZQCAAAAAABAsyOUAgAAAAAAQLMjlAIAAAAAAECzI5QCAAAAAABAsyOUAgAAAAAAQLMjlAIAAAAAAECzI5QCAAAAAABAsyOUAgAAAAAAQLMjlALQ4u3bt08Wi0Wpqan1fu4XX3whi8WiL774wu91AQAABLPm+AzGZzWgbSOUAgAAAAAAQLMjlAKAVqioqEiGYQS6DAAAAABoMEIpALW67777ZLFYtHXrVv36179WTEyM4uLiNG/ePJWVlWnXrl0677zzFBUVpe7du+vhhx+udI60tDRdddVV6tChg5xOp/r3769HH31UHo+nwnEHDx7U5ZdfrqioKMXExGjq1KnKzMyssq7169froosuUlxcnEJDQzVs2DD9+9//btB7PHz4sGbPnq0BAwYoMjJSHTp00FlnnaWVK1dWOtblcmnBggXq37+/QkNDFR8frzPPPFOrVq3yHePxePTUU09p6NChCgsLU2xsrEaPHq333nvPd4zFYtF9991X6fzdu3fXjBkzfD+npqbKYrHo448/1u9+9zslJCQoPDxcLpdLe/bs0TXXXKPevXsrPDxcnTt31oUXXqhvv/220nmzs7P1hz/8QT169JDT6VSHDh10/vnn67vvvpNhGOrdu7cmTZpU6Xn5+fmKiYnRTTfdVM/fKgAAaIy28BmsOu+9957GjBmj8PBwRUVF6dxzz9U333xT4ZjDhw/ruuuuU3JyspxOpxISEjRu3Dh98sknvmM2bdqkKVOm+N5/p06ddMEFF2j//v1+rRdAw4QEugAArcfll1+uq666Stdff72WL1+uhx9+WKWlpfrkk080e/Zs3XbbbXrllVf0xz/+Ub169dKvfvUrSeYHhrFjx6qkpER/+ctf1L17d/3nP//Rbbfdph9++EHPPvusJLP755xzztHBgwe1cOFC9enTR//97381derUSrV8/vnnOu+88zRq1Cg999xziomJ0WuvvaapU6eqsLCwQqhTF8eOHZMk3XvvvUpKSlJ+fr7efvttnXHGGfr00091xhlnSJLKyso0efJkrVy5UnPnztVZZ52lsrIyrV69WmlpaRo7dqwkacaMGfq///s/zZw5UwsWLJDD4dDGjRu1b9++hv3yJf3ud7/TBRdcoH/9618qKCiQ3W7XwYMHFR8fr7/+9a9KSEjQsWPH9M9//lOjRo3Spk2b1LdvX0lSXl6eTj/9dO3bt09//OMfNWrUKOXn5+vLL79URkaG+vXrp5tvvllz587V7t271bt3b9/rLl26VLm5uYRSAAAESDB/BqvKK6+8oiuvvFITJ07Uq6++KpfLpYcfftj3uez000+XJE2bNk0bN27U//t//099+vRRdna2Nm7cqKNHj0qSCgoKdO655yolJUXPPPOMEhMTlZmZqc8//1x5eXmNrhOAHxgAUIt7773XkGQ8+uijFfYPHTrUkGS89dZbvn2lpaVGQkKC8atf/cq378477zQkGWvWrKnw/BtvvNGwWCzGrl27DMMwjMWLFxuSjHfffbfCcddee60hyXjppZd8+/r162cMGzbMKC0trXDslClTjI4dOxput9swDMP4/PPPDUnG559/Xq/3XFZWZpSWlhpnn3228ctf/tK3f+nSpYYk4x//+Ee1z/3yyy8NScZdd91V42tIMu69995K+7t162ZcffXVvp9feuklQ5Ixffr0OtVdUlJi9O7d27j11lt9+xcsWGBIMpYvX17tc3Nzc42oqCjjlltuqbB/wIABxplnnlnrawMAAP9qC5/Bfn6c2+02OnXqZAwaNMh3LsMwjLy8PKNDhw7G2LFjffsiIyONuXPnVnvu9evXG5KMd955p8YaAAQOy/cA1NmUKVMq/Ny/f39ZLBZNnjzZty8kJES9evXSTz/95Nv32WefacCAARo5cmSF58+YMUOGYeizzz6TZP7lLSoqShdddFGF4377299W+HnPnj367rvvdOWVV0oyu5e82/nnn6+MjAzt2rWr3u/vueee06mnnqrQ0FCFhITIbrfr008/1c6dO33HfPjhhwoNDdXvfve7as/z4YcfSpLfO4suvfTSSvvKysr04IMPasCAAXI4HAoJCZHD4dDu3bsr1d2nTx+dc8451Z4/KipK11xzjVJTU1VQUCDJ/Ge3Y8cO/f73v/frewEAAHUX7J/BTrZr1y4dPHhQ06ZNk9V64utqZGSkLr30Uq1evVqFhYWSpJEjRyo1NVUPPPCAVq9erdLS0grn6tWrl9q1a6c//vGPeu6557Rjx45G1QbA/wilANRZXFxchZ8dDofCw8MVGhpaaX9xcbHv56NHj6pjx46VztepUyff497bxMTESsclJSVV+PnQoUOSpNtuu012u73CNnv2bEnSkSNH6vXeHnvsMd14440aNWqU3nzzTa1evVrr1q3Teeedp6KiIt9xhw8fVqdOnSp8SPq5w4cPy2azVaq7sar6Hc6bN0933323LrnkEr3//vtas2aN1q1bpyFDhlSqu0uXLrW+xs0336y8vDy9/PLLkqSnn35aXbp00cUXX+y/NwIAAOolmD+D/Zy3purq9ng8On78uCRp2bJluvrqq/XCCy9ozJgxiouL0/Tp032zsGJiYrRixQoNHTpUf/rTn3TKKaeoU6dOuvfeeysFWAACg5lSAJpcfHy8MjIyKu0/ePCgJKl9+/a+49auXVvpuJ8P2fQeP3/+fN/MhJ/zzlKqq//7v//TGWecocWLF1fY//N5AwkJCfrqq6/k8XiqDaYSEhLkdruVmZlZ5QcqL6fTKZfLVWm/98PYz1kslirrnj59uh588MEK+48cOaLY2NgKNdVloGevXr00efJkPfPMM5o8ebLee+893X///bLZbLU+FwAAtCyt4TNYVTVLqrZuq9Wqdu3a+epZtGiRFi1apLS0NL333nu68847lZWVpY8++kiSNGjQIL322msyDENbt25VamqqFixYoLCwMN15552NqhVA49EpBaDJnX322dqxY4c2btxYYf/SpUtlsVh05plnSpLOPPNM5eXlVbhCnWQOuzxZ37591bt3b23ZskUjRoyocouKiqpXjRaLRU6ns8K+rVu3VrrKy+TJk1VcXKzU1NRqz+Vtpf95wPVz3bt319atWyvs++yzz5Sfn9+ouv/73//qwIEDlWr6/vvvfW36Nbnlllu0detWXX311bLZbLr22mvrXA8AAGg5WsNnsJ/r27evOnfurFdeeUWGYfj2FxQU6M033/Rdke/nunbtqt///vc699xzK71fyfzMNGTIED3++OOKjY2t8hgAzY9OKQBN7tZbb9XSpUt1wQUXaMGCBerWrZv++9//6tlnn9WNN96oPn36SJKmT5+uxx9/XNOnT9f/+3//T71799YHH3yg//3vf5XO+fe//12TJ0/WpEmTNGPGDHXu3FnHjh3Tzp07tXHjRr3++uv1qnHKlCn6y1/+onvvvVcTJkzQrl27tGDBAqWkpKisrMx33BVXXKGXXnpJN9xwg3bt2qUzzzxTHo9Ha9asUf/+/fWb3/xG48eP17Rp0/TAAw/o0KFDmjJlipxOpzZt2qTw8HDdfPPNkswrxtx999265557NGHCBO3YsUNPP/20YmJi6lV3amqq+vXrp8GDB2vDhg165JFHKi3Vmzt3rpYtW6aLL75Yd955p0aOHKmioiKtWLFCU6ZM8X0olaRzzz1XAwYM0Oeff+67hDQAAGh9WsNnsJ+zWq16+OGHdeWVV2rKlCm6/vrr5XK59Mgjjyg7O1t//etfJUk5OTk688wz9dvf/lb9+vVTVFSU1q1bp48++sjXxfWf//xHzz77rC655BL16NFDhmHorbfeUnZ2ts4999xG1QnATwI6Zh1Aq+C98svhw4cr7L/66quNiIiISsdPmDDBOOWUUyrs++mnn4zf/va3Rnx8vGG3242+ffsajzzySIWrqhiGYezfv9+49NJLjcjISCMqKsq49NJLjVWrVlW68othGMaWLVuMyy+/3OjQoYNht9uNpKQk46yzzjKee+453zF1vfKLy+UybrvtNqNz585GaGioceqppxrvvPOOcfXVVxvdunWrcGxRUZFxzz33GL179zYcDocRHx9vnHXWWcaqVat8x7jdbuPxxx83Bg4caDgcDiMmJsYYM2aM8f7771d4zTvuuMNITk42wsLCjAkTJhibN2+u9up769atq1T38ePHjZkzZxodOnQwwsPDjdNPP91YuXKlMWHCBGPChAmVjr3llluMrl27Gna73ejQoYNxwQUXGN99912l8953332GJGP16tU1/t4AAEDTaQufwao77p133jFGjRplhIaGGhEREcbZZ59tfP31177Hi4uLjRtuuMEYPHiwER0dbYSFhRl9+/Y17r33XqOgoMAwDMP47rvvjCuuuMLo2bOnERYWZsTExBgjR440UlNTa6wJQPOxGMZJPZEAAEgaMWKELBaL1q1bF+hSAAAAAAQplu8BACRJubm52rZtm/7zn/9ow4YNevvttwNdEgAAAIAgRigFAJAkbdy4UWeeeabi4+N177336pJLLgl0SQAAAACCGMv3AAAAAAAA0OysgS4AAAAAAAAAbQ+hFAAAAAAAAJodoRQAAAAAAACaHYPOq+DxeHTw4EFFRUXJYrEEuhwAANCCGIahvLw8derUSVZr2/37Hp+XAABAder6eYlQqgoHDx5UcnJyoMsAAAAtWHp6urp06RLoMgKGz0sAAKA2tX1eIpSqQlRUlCTzlxcdHR3gagAAQEuSm5ur5ORk3+eFtorPSwAAoDp1/bxEKFUFbwt6dHQ0H7IAAECV2vqSNT4vAQCA2tT2eantDkIAAAAAAABAwBBKAQAAAAAAoNkRSgEAAAAAAKDZMVOqEdxut0pLSwNdRqtkt9tls9kCXQYAAAAAoI3yeDwqKSkJdBmtkr++0xNKNYBhGMrMzFR2dnagS2nVYmNjlZSU1OYHxQIAAAAAmldJSYn27t0rj8cT6FJaLX98pyeUagBvINWhQweFh4cTqtSTYRgqLCxUVlaWJKljx44BrggAAAAA0FYYhqGMjAzZbDYlJyfLamWyUX348zs9oVQ9ud1uXyAVHx8f6HJarbCwMElSVlaWOnTowFI+AAAAAECzKCsrU2FhoTp16qTw8PBAl9Mq+es7PXFgPXlnSPEvbuN5f4fM5QIAAAAANBe32y1JcjgcAa6kdfPHd3pCqQZiyV7j8TsEAAAAAAQK30kbxx+/P0IpAAAAAAAANDtCKTRI9+7dtWjRokCXAQAAAAAA6qmlfKdn0HkbcsYZZ2jo0KF++Rdv3bp1ioiIaHxRAAAAAACgVsH4nZ5QCj6GYcjtdiskpPZ/LRISEpqhIgAAAAAAUBet8Ts9y/faiBkzZmjFihV64oknZLFYZLFYlJqaKovFov/9738aMWKEnE6nVq5cqR9++EEXX3yxEhMTFRkZqdNOO02ffPJJhfP9vNXPYrHohRde0C9/+UuFh4erd+/eeu+995r5XQIAAAAAEHyC9Ts9oZQfGIahwpKygGyGYdSpxieeeEJjxozRtddeq4yMDGVkZCg5OVmSdMcdd2jhwoXauXOnBg8erPz8fJ1//vn65JNPtGnTJk2aNEkXXnih0tLSanyN+++/X5dffrm2bt2q888/X1deeaWOHTvW6N8vAAAAAABNhe/0pkB8p2f5nh8Ulbo14J7/BeS1dyyYpHBH7f8YY2Ji5HA4FB4erqSkJEnSd999J0lasGCBzj33XN+x8fHxGjJkiO/nBx54QG+//bbee+89/f73v6/2NWbMmKErrrhCkvTggw/qqaee0tq1a3Xeeec16L0BAAAAANDU+E5vCsR3ejqloBEjRlT4uaCgQHfccYcGDBig2NhYRUZG6rvvvqs1VR08eLDvfkREhKKiopSVldUkNQMAAAAAgNb9nZ5OKT8Is9u0Y8GkgL12Y/184v7tt9+u//3vf/rb3/6mXr16KSwsTJdddplKSkpqPI/dbq/ws8VikcfjaXR9AAAAAAA0Fb7TmwLxnZ5Qyg8sFkud2u0CzeFwyO1213rcypUrNWPGDP3yl7+UJOXn52vfvn1NXB0AAAAAAM2P7/SB0/J/6/Cb7t27a82aNdq3b58iIyOrTTx79eqlt956SxdeeKEsFovuvvtuOp4AAM2izO1RRk6x0o8VKq18y3eVyW6zKsRmkcNmld23WeQq86i41K2iEreKSs2tuNSt4lKP7jivr/olRQf6LaEBPB5DN768QSVlHj15xTBFhdprfxIAAEEuGL/TE0q1IbfddpuuvvpqDRgwQEVFRXrppZeqPO7xxx/X7373O40dO1bt27fXH//4R+Xm5jZztQCAlsrjMZRdVKrswhLlFJX6ttyiUmUXlqrE7VF8hEMJUaFKiHL6tgiHTW6PoYycYh3MLtKB7CIdOF5+m12ktGOFOnC8SGWeul2FpjYzxnZXvyS/nArNzGq1aPmOQ/IYUlGJm1AKAAAF53d6i1HX6w+2Ibm5uYqJiVFOTo6ioyv+hbW4uFh79+5VSkqKQkNDA1RhcOB3CQAtR3GpW0fyXTqcV76V3z+S79KxghIdzS/RsQJzO15YoobkRqF2q0rKPLU+1xFiVXK7MHWNC1fXuHDFhNlV6jFU5vao1G2oxO1RaZlHZR5DDptVYQ6bnHarwuw2c3PYFGq3aXzv9uoYE9awX0gNavqc0JY09e+h390fqrjUo5V3nKnkuHC/nx8A0HbxXdQ/avo91vVzAp1SAAC0Yh6PoZ+OFWrr/mx9uz9H+44Wymm3Krw8nAlz2BRuD1G4w6YSt0fHC0p0rLBE2YWlOlZQouzCEh0tKFFecVm9XzvSGaKYMHuFLTbcLrvNqqMFJwVceS4VlJhL6iTJYbOqY2yoOseGmVs787ZrXLi6xocrMSpUVqvF378qtDJ2m1XFpR6VulvmcgMAANB4hFIAALRABa4yHSsoMeclnTQzqbjUowJXmb7PytO3+3P07YGcBgVKVXHYrEqIcqp9lFMJkU4lRDnUPtKpuAiH4iJO3I+PcKhdhEN2m7Ve7+dIvkuhdpsSIp2ETqiVM8SqPEklhFIAAAQtQikAAPykqMSt3OJS5RWXKqeorPx+mXKLSlVS5pHVYs7KsVgs5n2LRR7D0JG8EmXkFCkjp1iZOcXKyClSbj2CJkeIVad0itbgzjHq1SFSZR5DhSUngizzvjksPK48UGoXble7cO99hxIinYoOC5HF0jRhUYQzRBFOPnag7hzloWdJGaEUAADBik+HAACcxDAM5RaX6Wi+S8WlHrnK3L4rvHlvjxWU6FCuS4dyi0/aXMp3+adjycsRYlWEw5yTFOq9LZ+b1C0+XIO7xGhQ51j1ToysV9cS0BrYQwilAAAIdoRSAIA2xTAMHc5zKe1YodKOFZZfBc68GlxGTpEOZhc3KlyyWqSoULuiw0IUHWpXVKh56wixyih/fY9H8hiGb+B3QpRDSdFh6hgTqqSYUN8tVxxDW+brlGL5HgAAQYtQCgDQqnkHfe8+lKeiUrdKyjwqcXvM2/LtaEGJ0stDqPTjhb6B2zWJcoYo1GGTM8QqZ4hVoXbzviPEXALXIcoMjhKjnUqMClViTKgSopyKcjbdEjigLXHQKQUAQNAjlAIAtAqGYchV5tFPRwu17UCOth3M0faDudpxMLfenU1Wi9QxJkzJcWHq0i5cnWLD1Dk2VJ1iw8wtJkxhDlsTvRMAdUEoBQBA8COUAgAEVE5RqXYfytP3h/K1OytPuw/la395N1OFjqcalvA4Q6zqkxilqNAQOUKsctjMjiZHeZdTdJhdXePCfVun2DBmMAEtnPd/o6VuI8CVAACApkIoBQDwq8ycYm1KO67N6dnalJatjNwihVitCrFaZLNaZLdZFWKzyGaxKP14oQ7luup1/giHTad0itEpnaM1sFOMBnaOUc+ECIUQMgFBxentlHK7A1wJAABoKoRSbdwZZ5yhoUOHatGiRYEuBUCAFJe6tTk9W6t/PKrVPx7VviOFOqVTtEamxGlkSpwGdo6psqvIMAxl5BTr+0N52pWZ5wuhMnOL611Dx5hQ9U6MUp8OkeqTGKVu8eEKd4T4up1O7n6KcobIamVmExDsfIPOWb4HAECNWvP3ekIpAAhirjK3ikrcKip1q7DEvF9Y4la+q1Rb9+do9Y9HtTEtu9KXvszcYn36XZYkKcxu0/Bu7TQyJU5hdpt2Z5lL7fZk5Vc5y8lqkfolRWtY11gN69pOKe0j5DEMlbo9KnMbKvN4VOo25PYYSooJVa8OkYrmKnMAfsZOKAUAQNAjlAKAVqyoxK0D2UVKP16o/ccKlX68SOnlV5hLP1aknKLSOp0nIcqp0T3iNbpHnHomRGrbgRyt2XtM6/YdU3Zhqb7ac0Rf7TlS6XkhVotS2keod2KkBneJ1bDkWA3qEqNwB//3AqBxfIPOmSkFAEDQ4ltDG1JQUKAbb7xRb731lqKionTbbbdVeLykpER//vOf9fLLLys7O1sDBw7UQw89pDPOOEM5OTlKSkrS22+/rfPOO8/3nLfeekvTpk3ToUOHFBkZ2dxvCWgTcotLtfGn49qTla8D2UU6mF1UflusYwUldTqH3WZRqN2mcIdN4Y4Qhdpt6pkQoTE94zW6R7x6tI+QxXJiSdzoHvGaNb6HPB5Du7PytXbvUa3bd1xlHo96d4hSn8Qo9U6MVPf4CN8XRwDwJ66+BwBAZcH2vT7godSzzz6rRx55RBkZGTrllFO0aNEijR8/vtrjn3nmGT399NPat2+funbtqrvuukvTp0/3PZ6amqprrrmm0vOKiooUGhraJO9BhiGVFjbNuWtjD5csdZutcvvtt+vzzz/X22+/raSkJP3pT3/Shg0bNHToUEnSNddco3379um1115Tp06dfP+ifvvtt+rdu7cuuOACvfzyyxX+5X3llVd08cUXE0gBfnQot1jr9h3Tur3HtHbfcX2XmSujhkaBSGeIurQLU3JcuJLbhSs5Lqz8NlxJ0aEKd9oafKU5q9WivklR6psUpWljujfsDQFAAxBKAQCaTSv5Ti8F3/f6gIZSy5Yt09y5c/Xss89q3Lhx+vvf/67Jkydrx44d6tq1a6XjFy9erPnz5+sf//iHTjvtNK1du1bXXnut2rVrpwsvvNB3XHR0tHbt2lXhuU0WSEnmv7wPdmq689fkTwclR0Sth+Xn5+vFF1/U0qVLde6550qS/vnPf6pLly6SpB9++EGvvvqq9u/fr06dzPdy22236aOPPtJLL72kBx98UFdeeaWmT5+uwsJChYeHKzc3V//973/15ptvNt37A4KMx2Mo/XihDhwv0uF8l7JyXeW3xTqc71LaMXPZ3c91jQvXoM4x6tIuTJ3bhalTTPltbJhiwpjHBCD4eAedl7oJpQAATawVfKeXgvN7fUBDqccee0wzZ87UrFmzJEmLFi3S//73Py1evFgLFy6sdPy//vUvXX/99Zo6daokqUePHlq9erUeeuihCqGUxWJRUlJS87yJVuKHH35QSUmJxowZ49sXFxenvn37SpI2btwowzDUp0+fCs9zuVyKj4+XJF1wwQUKCQnRe++9p9/85jd68803FRUVpYkTJzbfGwFaCMMwdDjPpR8OF8hqkSJDQxTltCsyNESRTvOqcaVuj/Zk5Wv7wVxtP5ij7QdytTMjV3lVDAc/mcUi9U+K1mnd2+m0lDid1j1OidFNGKzDPw5tl374XEoaJHUdI4U4GnYej1s6ukfK2CLlH5JCY6TQWCks9sT90BjJlWc+npcp5Weat3mZkqdMGnSZ1PPsuv3VraTAfK0O/aWwdg2ruTEMQyo4bG4xXcz3BujkmVKEUgAASMH5vT5goVRJSYk2bNigO++8s8L+iRMnatWqVVU+x+VyVep4CgsL09q1a1VaWiq73ewWyM/PV7du3eR2uzV06FD95S9/0bBhw6qtxeVyyeVy+X7Ozc2t35uxh5vpZiDYw+t0mFHT2h9JHo9HNptNGzZskM1mq/CYt4XP4XDosssu0yuvvKLf/OY3euWVVzR16lSFhAR8FSjQpA7nubQzI1ffH8rTnqx87c7K1+5Decotrj5ccoRYZRiGSqsY0OsIsSq5XZg6RIUqIcqpDlFOJZRvSdGhGtglhqvR+dOxH6XcDCm6oxTVUbKH+ff8x/dJnz8obf23pPJ/3o5IqccZUq9zpN7nmmHLz7nLpKJjZpB0aJt0cLMZDmV+K5UWNK6mLa9KCf2k0TdKg6dWfs+GIe1fL236l7TtLakkT7LapZ5nSaf8Uup3fvXhkLtMOrJLOrTDDN4iOkiRHaSIBMkZVTEI87ilgiNSQZaUn2UGTzn7pZx0KTtNyk4375cVn3hOZJLUvrfUvk/51ts8t7tUcrskd4l5v8xlBnBRSVJsNykyUbIy3yyYOLj6HgCgubSC7/RScH6vD1iacOTIEbndbiUmJlbYn5iYqMzMzCqfM2nSJL3wwgu65JJLdOqpp2rDhg1asmSJSktLdeTIEXXs2FH9+vVTamqqBg0apNzcXD3xxBMaN26ctmzZot69e1d53oULF+r+++9v+JuxWOrcbhcovXr1kt1u1+rVq31LI48fP67vv/9eEyZM0LBhw+R2u5WVlVXjTK8rr7xSEydO1Pbt2/X555/rL3/5S3O9BaBZFLjK9O2BHG1Jz9aW/dnakp6jA9mVl9NJktViLquzWizKc5WpwFWmwhK3pBNfoqJCQzSgY7RO6RSjUzpF65TO0eqZENngGU9BzeORDm6Udr5vdh1FJJhBUnQnKapTeajUydxfW/iQl2mGLd++bp7zZGHtTjpfkmSxlgceJeZWVn5rDzM7nnpMkBIHVX7N/Czpy79J65dInvKrHHYfLx3eZYYw3/3H3CSpwwAprodUeNQMaQqPSEXZ8oVYP2cPNzuuYrtKxblScbZUnGM+pzjbDHGsdjOIiUo0g5yo8q3giLT5Zenwd9L7t0ifLpBGzJROm2W+162vSZv+z3zcKzTGPP/u/5mbzWF2Wp3ySymhjxmUeUOzQ9sqhkgnCwk1QypHePn7PFr9e6zAIoVGmzXkl3d+7VtZh+edxOaU2nUzA6p23c37/S4wf+9olbz/nXQRSgEAmlor+E4vBef3+oC3uFh+trTAMIxK+7zuvvtuZWZmavTo0TIMQ4mJiZoxY4YefvhhXwo4evRojR492veccePG6dRTT9VTTz2lJ598ssrzzp8/X/PmzfP9nJubq+Tk5Ma+tRYlMjJSM2fO1O233674+HglJibqrrvukrX8S1afPn18a0sfffRRDRs2TEeOHNFnn32mQYMG6fzzz5ckTZgwQYmJibryyivVvXv3Cr9roCUzDEMHsou07UCOMnKKlVtUptziUuUWlZbflulwvks/Hs6X52ffoS0WqUf7CPOKcx0i1SsxSn3KrzwXaq/4F4gyt0cFJW7lly/R6xQTWu1/0/zGlW+GKB63ZHgqbpIZMIQ4zFubQ7KGmG+qKNvs8sn+ybw9Xn5bki/1mSQN+a0Z3NSXYUiFx6ScNLMbpswlRXeWYjqbYdDJy9rcZVLaKjOI2vkfKa8Of6GyR5hBSUI/KaHvidvQWGnXB2bH0r6VJ96/xSbFJkt5h6SyIqnouLllba/9tXZ9YN6GxUkpvzADquTR0o53pFVPn+ho6nmWdPY9UqdhZriWuUXa/Ym0+2PpwHopa4e5VWKRwuOkhP5SxyHm1mmoFN9LstqqOL5cmcsMpaoL5866S9r4L2nN381/Dl8+LH29yPydeMo7/EJCpQEXS8OmSd3GSUe+N9/XtrfMTqjvPzS3qjiipMRTJBknOqBK8s2wKietivcYbwZokQnmvwOxXc1/JrFdpZhk89+PEIcZSh3ZY9Zy8lacY4ZOvn+P7ebPFqv570zOAbOLynu8V0I/QqlWzLt8j5lSAACYgvF7fcBCqfbt28tms1XqisrKyqrUPeUVFhamJUuW6O9//7sOHTqkjh076vnnn1dUVJTat29f5XOsVqtOO+007d69u9panE6nnE5nw99MK/HII48oPz9fF110kaKiovSHP/xBOTk5vsdfeuklPfDAA/rDH/6gAwcOKD4+XmPGjPH9iyuZIeIVV1yhRx55RPfcc08g3gZQK8MwlJXn0tb9Ofp2f7a2HsjRt/tzdLSgpE7P7xwbpiHJMRrSJVaDu8RqUJcYRTrr9p/LEJtVMWHWphk+bhhmyJP57UnbVnP5U71YzGDK291TlfQ10mcPSL0nSsOukvqcZwYBJytzmUHLwc1m98zxn8qXZaXXsPzMYoYTMZ3Njqf0teYSNi9HpPma3U83O4JyM6Tcg2bwkJthzlAqLZAObjK3mnQZKQ2+XBpwiRmGGEblc+YdMo+tEHaU3y84LO39UvpplVnjjnfM7WSdTpXOuc8Mq7ysVjOc6jRMmnC7GdD9+Ll5G9FeCm9/4jY8rubwqTohtfx/VmiMNPb30qgbpO/el755Vtq/9kTNw64y506dvESvQz+pw53SGXdKWTul7W9L298xu76SBpWHZkPNLa5H5UCspOCkgKrAfI8RHcxAylbHjxuhMVKX4eZWH+5Sc1ngzwPW9lV3SKN14Op7AABUFmzf6y1GbYsSm9CoUaM0fPhwPfvss759AwYM0MUXX1zloPOqTJgwQZ07d9Yrr7xS5eOGYWjkyJEaNGiQlixZUqdz5ubmKiYmRjk5OYqOjq7wWHFxsfbu3auUlJSmvaJfG8DvEo3l9hhKP1aoHw7na09W/km3Bcopqhy4hFgt6tcxSt3iIhQdZldMmF3RYSGKDrUrOsyu2DC7+nWMUoeoUDPAyD8kHdtrziQ6OTj5ufD25sygmM7lHR9+CLndpeYyMG/w5L0tzqnliRYz5LBYzc0wzA6S6kQkmEudfEueukuGW9rympT2TcXjBk81H8/YYm5ZO2sOtiITzU6YkFAzBMrZX3UtYXHmDKP+F0kpEyR7Df89cJeaYcPh78q3Xebtkd1ml077vtLgX0sDL5PiUmr8TdWZu1Q6sEH6cYW0d4UZpMX1MLuR+l9Ur0v4BtShHWYYmdCn9mNRo5o+JwTKl19+qUceeUQbNmxQRkaG3n77bV1yySXVHv/WW29p8eLF2rx5s1wul0455RTdd999mjRpUp1fs6l/D/9a/ZPufmebzjslSc9Nq2dQCQBADfgu6h81/R7r+jkhoMv35s2bp2nTpmnEiBEaM2aMnn/+eaWlpemGG26QZC6rO3DggJYuXSpJ+v7777V27VqNGjVKx48f12OPPaZt27bpn//8p++c999/v0aPHq3evXsrNzdXTz75pDZv3qxnnnkmIO8RQMN4PIYyc4v14+EC7T9eqEO5LmXlFetQrkuHy2+P5LtU9vO1duWsFqlPYpQGdY7R4C4xGtQlVv2Soiott/M5+oO06Xlp424z9Dj2o3lp2IaI6GCGVO26S8kjzblEiQOr7xbxuM2AZ/9aM/zI/Nb82V1FZ5fVbna0JA02u1eSBpnLqJwxZjhSVUBiGOZreIdEe2cmhbWTnJFV1zR8hhn0bPo/c2h2/iHpm6crHxfWrrx7ZrAU19NckhXT1Xz/Pw+XDMOcMZSTbi63ysswB1l3G1f3ThqbvXwIdm+p/4mrrsrjNpcjhsf5PySy2aWuo83tjD+ay/Na40DtxAGBrgBNqKCgQEOGDNE111yjSy+9tNbjv/zyS5177rl68MEHFRsbq5deekkXXnih1qxZU+PFYZqTw2b+b5nlewAABK+AhlJTp07V0aNHtWDBAmVkZGjgwIH64IMP1K1bN0lSRkaG0tJOzKZwu9169NFHtWvXLtntdp155platWqVunfv7jsmOztb1113nTIzMxUTE6Nhw4bpyy+/1MiRI5v77QGog5zCUv14JF/7jhbox8Pl25EC7TtSoKJSd63Pd4RYzXlPCaEaGX5Igy27lVy4U9GebNkG/lIaOKrmzqWCI9KKh6X1L56YteNlsZrzbuJSzKCpysDHYy5Zytkv5R4wu3UKsszt4EZp+1vlhUZJyadJXcea4UZpodlxs3+tdGCjOY/n55zRJ4KnpMFS0kBz9tDJM5nqwmIxQx9biKR6DHBs31s6937prD9Lu5ebA7JLCivOPopJrnsIZLGUL+lqby5t8yerTYqI9+85q32tVhhIIehNnjxZkydPrvPxixYtqvDzgw8+qHfffVfvv/9+ywmlvMv3CKUAAAhaAR90Pnv2bM2ePbvKx1JTUyv83L9/f23aVPMMkccff1yPP/64v8oD2q7jP0mrnzXn6XjKzM1danakeH+O7ljeJVM+aybxlGqXXhWXurX6x6PafjBXPx4u0L6jBdp7pEDHapjzFGK1qGt8uLrFhSsxOlQdokPVIcqpDpEOJVsPKyl/u2KObpX14EZp7+bKVwTb87G0/B7zymMjfmdepcyrpFBas1j6apHkyjX39TrHnGcU10Nql1K+9KweAZBvwHe6GVBl7ZTSVpvzmVy50g+fmVtVHJFS51OlLqeZv8ukQWanVUtYGmazm8vr+p1f+7EAWiWPx6O8vDzFxcUFuhQfR/lFbLj6HgAAwSvgoRSAFubgZmnVk+aAY6OWTqWCLHO2kJfFJnXob17xynCruDBP2Tm5KizIVVlxgXoYxeplMWQYFnlUvjmsslqtsoXYVRyaoLKYbrLHpyi6U2/Fdekje3x389wHNpgdRT+sN+8XHqlcjzOmPNgZYQ6q3pBqhkMr/iqtfFQaeKk06jop6ztziLf3Sm9Jg6WJf5F6nNG4353FYnbrRMSbXUT9LjD3e9zSoe3mjKa0b6T0dZI9zFza12WEOZC7Q/+GDbwGAD949NFHVVBQoMsvv7zaY1wul1yuE3PhcnNzm7QmO8v3AAAIeoRSAMwOnx8+lb5+0hzk7NXjTHO2UFg7c0CybysfpH18rxliZWyRMjab84IObTM3SaGSkrznspRvOun2ZGWS8vdJ+eukA5K21lKz1W4uZ+s8Quo83Ax34npWXFp1+q3Szvek1c+Zy+S2vmZuXjHJ0ll3S4N+3bRLsqw2c+ZSx8HSqOub7nUAoAFeffVV3XfffXr33XfVoUOHao9buHCh7r///mari6vvAQAQ/AilGsjj4QNSY/E7DJCSQnOI99E90rEfzAHfBzaYVzCTzG6ngZdKY282Q5SadBwsDbhYWXnFem/TAa3YsFWhh7equyVTJbKrSE4lxrdT3+REDereUV2T2stiDTFDMMNTcXO7zOHXvku67zOXEBZkma8V18MMn7whVNKgmq/SJpnLzgZeam77N5jL9ba/LdkjpF/8QRp5fe3nAIAgtmzZMs2cOVOvv/66zjnnnBqPnT9/vubNm+f7OTc3V8nJyU1WG6EUAKCpGUbVF01C3fjjOz2hVD05HA5ZrVYdPHhQCQkJcjgcsrSEmS+tiGEYKikp0eHDh2W1WuVw1HNoc7ApOCKFxpgBSl14PGY3U9ExKTRWCos1b0NjzfNYbeY5j+8rD3j2ngh4ju2VcvdXfV57hHTqdGnMbHOWUi0KS8r08fZDemvTAX21+7DMi+A5ZLedpjP6dtCkU5J0Rt8EtY+sYch4XZQUmLOswmIbd54uw6UuL0hTFpm/65qGnwNAG/Dqq6/qd7/7nV599VVdcMEFtR7vdDrldDbffzudDDoHADQRu90ui8Wiw4cPKyEhge/09eTP7/SEUvVktVqVkpKijIwMHTx4MNDltGrh4eHq2rWrrG31SlbuMumLheaso4gEadiV0qlXm1d6q0pxrrT5ZWnN382gqTo2h+Sufni4JDPAat/bXO4W30uK72nOUwqvOODW7TGUkVOkveVXw/vxSIHvfvrxIrk9J/6yMKxrrH51ahdNGdRR7SL8GDQ66nG1uLpwRvr3fADQAuTn52vPnj2+n/fu3avNmzcrLi5OXbt21fz583XgwAEtXbpUkhlITZ8+XU888YRGjx6tzMxMSVJYWJhiYmIC8h5+zm4zPx+U0ikFAPAzm82mLl26aP/+/dq3b1+gy2m1/PGdnlCqARwOh7p27aqysjK53bVfsh6V2Ww2hYSEtN1EOme/9MZMKX21+XNBlvTV4+bW8yxzjlPf882OnqM/SGuflza9LJXkmceHxkiJA6XiHHMryj7xmLtEkkWK7iy162Zewa1ddym2mxl4xfeqED55PIZ2ZOTqx90FSj+2R/uPFyr9WJH2Hy/Ugewilbqrb2lNjgvTL4d10S+HdVZKez+HRwCAOlu/fr3OPPNM38/eZXZXX321UlNTlZGRobS0NN/jf//731VWVqabbrpJN910k2+/9/iWwEGnFACgCUVGRqp3794qLS0NdCmtkr++0xNKNZDFYpHdbpfdXsclV4DXdx9I79woFWdLjihpyuPmUrINqdIPn53YIhPNK7L9uEJSeTDUvo806gZpyG8qdxC5y8yAqrTAfG4Ny9PcHkPr9x3Th9sy9eG2DB3KdVV7rN1mUde4cKW0jyjfIn33E6OdbTdYBIAW5IwzzqhxLsbPg6YvvviiaQvyA0d5p5SLTikAQBOx2Wyy2bgCdiARSgF1VXRc2ve1tO8rqeBw1cdYbeayuE6nSp2GVVwOV+aSlt9rDtuWzMcvW2IO8JakAReZs582/FPa9H9S/iFzk6Re50qjb5B6nFXlVeJyikq14adjWrP3mHZl5ik27KgSo0OVGB2qpJgTt2lHC/XBtxn6aHumDuedCKIinSHq3zFKye3C1SUuXMntwtSlXbiS48KUFB2qEFsbXWIJAAgY3/I9OqUAAAhahFJAdYpzpJ++kfatlPZ+KWV+K1/HUl21626GTx2HStvfkjK2mPtH3ySdc58U4qh8/Dn3SmfMl3Z9YF4dr/9FZtB1kqP5Lq3Ze0xr95pB1HeZuarvhSOiQkM0cUCSzh+UpNN7t5czhL8QAABaDidX3wMAIOgRSqHt8ril7W9LR743r1ZXeNTcCo5IhUfM25+HUO37SinjzQHhVS1bKy2SDm2XDm6Ujv1YftW7febrSFJYnHTJYqnveTXXFuKQTrnE96NhGNqdla/lOw7pk52HtDk9u1II1aN9hE7rHqdBXWJU4CpTZm6xDuUWKzOnWIdyXTqUW6wIZ4gmDkjU+YM6alyv9r55HQAAtDTe/4/yGFKZ20PXLgAAQYhQCm1Tfpb05ixp74qaj4vraYZQ3cu3qMS6v0bRcengZungJjOkckZLZ94lxXSu09NLyjxat++YPtlpBlHpx4oqPN4vKUqjUuI0MiVep6W0U4eo0BrP5/EYsljEDCgAQKtgPymEKiGUAgAgKBFKoe35cYUZSBVkSfZwadBl5mDw8PZSRHspPN68jUySIhMa/jph7aSeZ5pbHWXlFeuLXYf1+XdZWrn7iPJdZb7HHCFWjesZr3MGJOrsfolKiqk5hPo5q5UwCgDQepzczVtaZkiOGg4GAACtEqEU2g6PW1rxkLTiYUmGlNBf+nWq1KFfwEoyDEPfHsjRJzuz9MWuLG3dn1Ph8faRDp3Vr4PO7p+o8b3bK9zB/2QBAG1DiNUii0UyDMnldkviiscAAAQbvuGibcjLNLuj9q00fx52lTT5EckRHpByDmYX6e1NB/Tmhv368UhBhccGd4nRmX076Kx+HTSocwwdTgCANslischhs8pV5mHYOQAAQYpQCq1L4TFzi+5Uc6BkGFL+Ienwd+bg8a8elwoOS/YIacrj0pCpzVdzucKSMv1ve6be3HBAX/9wxDeoPMxu0xl9E3Rmvw46o29CrbOhAABoK7yhVKm7npeYBQAArQKhFFo+w5DS10hr/yHteFfylJr7w9pJMV2k6C7m8PDIRCknXTq8ywyjiisuhVOHU8zlegl9mqhMQ7sO5Skjp1hH8lw6kl+io/kuHck3729KO66CErfv+FEpcbpseBdNHtRRkU7+pwgAwM85QqySS3RKAQAQpPgmjJarpED69nVp7QvSoW9P7LeHS6WF5tXtio5Lmd9W/XyLVWqXIiX0k7oMl0bPluxhfi/TMAx9sjNLT366W98eyKnx2K5x4br01C761amdlRwXmKWDAAC0Ft5h54RSAAAEJ0IptDxHf5DWvSBtellylYc8IWHmVfJOmyV1HGJ2QeUekHIOSLn7pZz95nK9qE5SQl8ziIrvJdmbbimcx2Po4x2H9OSnu7UjI1eSFGq3qkf7SLWPcqp9pEPtI0/cdm8foWHJsbJYmBEFAEBd2G3loZTbXcuRAACgNSKUQsvg8Ug/fCqt+bu0Z/mJ/e1SzCBq2JXmcj2vsFhzSzyluSuVx2Poo+2ZevLT3fouM0+SFOGwafrY7pp1eoriI53NXhMAAMHoRKcUM6UAAAhGhFIIrOIcafMr5ryoYz+U77RIvSdKI6+Tep4lWa0BLbHU7dF3GXnamHZcG9OOa/2+4zqQXSRJinSGaMbY7pp5eoraRTgCWicAAMHG4euUYvkeAADBiFAKzas417wa3qFt0sHN0va3pdIC8zFnjDTsKmnkLCmuR0DL/OlogV5dm66NPx3X1gPZKi6t+GE4KjRE14xL0cxxKYoJtweoSgAAghszpQAACG6EUmhax340O6G8QVR2WuVjEvqZXVGDp0rOyOav8SSGYei1dela8P4OFZWemF8RHRqiYV3baVjXWJ3atZ2Gd2unCK6YBwBAk/J2SpXSKQUAQFDiWzWazsHN0tKLpeLsivujO0uJA815UD3OkFJ+IbWA4d9H8126861vtXzHIUnSyJQ4XTa8i07tGqse7SNltQa+RgAA2hI6pQAACG6EUmgaBzeVB1I5Useh0tDfmiFUhwFSeFygq6vk811Zuv31rTqS75LDZtXtk/pq5ukpBFEAAAQQoRQAAMGNUAr+d2CD9K9fmoFUl5HSVW9KodGBrqpKRSVuLfxwp5Z+85MkqU9ipBZNHaYBnVpmvQAAtCV2m/nHIRfL9wAACEqEUvCv/eWBlCtHSh4tXfWG5IwKdFUVlLk92pSerS92Zen9LRlKO1YoSbpmXHf98bx+CrXbAlwhAACQJEeI+f/JpXRKAQAQlAil4D/715cHUrlS17HSlf9uMYFUVl6xVuw6rC++P6yV3x9WbnGZ77EOUU797ddD9Is+CQGsEAAA/Jx30HkJnVIAAAQlQin4R/pa6V+/kkrypG7jpN/+O+BX0pOkNT8e1VOf7dFXe45U2B8bbtcveifojL4JOmdAoqJD7QGqEAAAVIeZUgAABDdCKTScxy2lrZa2vy1teVUqyZe6j5d+u0xyRAS0tG9+OKonPv1eq3885ts3uEuMzuiToAl9O2hocqxsDDEHAKBFc5TPlCqlUwoAgKBEKIX68Xik9DVmELXjXSk/88RjKb+QrngtYIGUYRj65oejWvTpbq3da4ZRdptFl49I1g0Teio5LjwgdQEAgIahUwoAgOBGKIW6W71Y+voJKS/jxD5njNR/inTKL6UeZ0q25v9XyjAMfb3H7Ixat++4JHMGxdTTknXjGT3VKTas2WsCAACN5w2lXIRSAAAEJUIp1M23b0gf3Wned8ZI/S4oD6LOkEIcASnJMAyt+P6wnvx0tzamZUsyP7xecVqybjijpzrGEEYBANCa2Rl0DgBAUCOUQu2yvpPem2PeH/N76ex7pBBnwMoxDEOffZelJz/drS37cyRJzhCrfjuqq67/RU8lxYQGrDYAAOA/3k6pUjqlAAAISoRSqJkrX/r3dKm0wJwZde4CyWoLSCneMOrxT77XtgO5kqRQu1VXjeqm6yb0UIcowigAAIKJg04pAACCGqEUqmcY0vu3SEd2SVEdpUuXBCyQ2pOVrwX/2aEvvz8sSQp32DRtTDddO76H2kcGrmsLAAA0HQadAwAQ3AilUL11L0jb3pAsNumyl6TIhGYvIbe4VE9+slupq/apzGPIYbPqmtO76/pf9FRcRGBmWQEAgObh7ZQqpVMKAICgRCiFqu3fIH0037x/7v1StzHN+vIej6E3Nu7Xwx99pyP5JZKkc/p30J8vGKDu7SOatRYAABAYXH0PAIDgRiiFygqPSa9fLXlKpX5TzOHmzWj7wRz96a1vfUPMe7SP0N0XDtCZfTs0ax0AACCwWL4HAEBwI5RCRR6P9NZ1Uk661C5FuuRZyWJpppc2tOTrvXr4o10qcXsU6QzRLWf31tVju/s+lAIAgLbDzvI9AACCGqEUTIYh7VspffGQ9NNXUkioNPVfUmhMs7z84TyXbnt9i1aUDzI/p3+iHvzVQK6oBwBAG+brlCKUAgAgKBFKtXWGIf34ubTiYSntG3Of1S5d9JSUNKhZSvhiV5Zue32LjuSXyBli1Z+nDNBVo7rK0kwdWgAAoGVy2li+BwBAMCOUaqsMQ9rzibTiIWn/OnOfzSGderV0+lwppkuTl+Aqc+vhj3bpxa/2SpL6JkbpySuGqW9SVJO/NgAAaPnszJQCACCoEUq1Ra586ZXLpZ++Nn8OCZWGXyONmyNFd2qWErLyinXNS+u0/WCuJGnG2O66c3I/hdptzfL6AACg5XP4ZkoZAa4EAAA0BUKptsYwpPdvMQMpe7h02kxpzM1SVGKzlZCVV6wrnl+tHw4XKC7CoUcuG6yz+zff6wMAgNbBO1PKRacUAABBiVCqrVn/orTtDclik6a9LXUd3awvn5VbrCv+YQZSnWJC9ep1o9UtPqJZawAAAK2Db9B5mTvAlQAAgKZAKNWWHNgofTTfvH/u/QEJpH7zj9X6sTyQeu26MeoaH96sNQAAgNaD5XsAAAQ3Qqm2oui49PrVkrtE6jdFGvP7Zn35kwOpzrFhevXa0QRSAACgRr5OKTfL9wAACEbWQBeAZuDxSG/fKGWnSe26Sxc/I1kszfbyh3KL9ZvnTwRSr11HIAUAAGrn7ZRyewy5PXRLAQAQbAil2oJVT0rffyjZnNLlS6Ww2GZ76cwcc6j5j0dOBFLJcQRSAACgdvaQEx9VSxh2DgBA0GH5XrDb97X06QLz/uSHpI5Dmu2lP9qWoT+/s01H8ksIpAAAQL15O6UkcwlfmGwBrAYAAPgboVQwy8+S3vidZLilwVOl4TOa5WWPFZTo3ve26/0tByVJfRIj9eLVpxFIAQCAerHbTowboFMKAIDgQygVzD6aL+VnSgn9pSmPN8scqY+2ZerP73yrI/klslktumFCD805u7ecIfxlEwAA1I/FYpEjxKqSMg/DzgEACEKEUsEq/7C0413z/i+fkxwRTfpyx8u7o94r747q3SFSj14+RIO7xDbp6wIAgODmsJmhVCmdUgAABB1CqWC15RXJUyp1HiF1GtqkL7XtQI5mvLROR/JdslqkGyb01C3n0B0FAAAazxFilVyiUwoAgCBEKBWMDEPauNS8P/zqJn2pHw7n6+ola3W0oES9OkTqb78eoqHJsU36mgAAoO3wDjtnphQAAMHHWvshTevZZ59VSkqKQkNDNXz4cK1cubLG45955hn1799fYWFh6tu3r5YuXVrpmDfffFMDBgyQ0+nUgAED9PbbbzdV+S3TT19LR/dIjkjplF812csczC7StBfW6GhBiQZ2jtbbs8cSSAEAAL+yh5gzMV2EUgAABJ2AhlLLli3T3Llzddddd2nTpk0aP368Jk+erLS0tCqPX7x4sebPn6/77rtP27dv1/3336+bbrpJ77//vu+Yb775RlOnTtW0adO0ZcsWTZs2TZdffrnWrFnTXG8r8Db807wddJnkjGySlzia79JVL67RwZxi9UiI0D+vGamoUHuTvBYAAGi7vJ1SpSzfAwAg6FgMwzAC9eKjRo3SqaeeqsWLF/v29e/fX5dccokWLlxY6fixY8dq3LhxeuSRR3z75s6dq/Xr1+urr76SJE2dOlW5ubn68MMPfcecd955ateunV599dU61ZWbm6uYmBjl5OQoOjq6oW8vMAqPSY/2k9wu6drPpc6n+v0l8opLdcU/VmvbgVx1ignV6zeOVefYML+/DgAALVGr/pzgR831e5j8xErtzMjV0t+N1C/6JDTZ6wAAAP+p6+eEgHVKlZSUaMOGDZo4cWKF/RMnTtSqVauqfI7L5VJoaGiFfWFhYVq7dq1KS0slmZ1SPz/npEmTqj2n97y5ubkVtlZr6zIzkEoaJHUa5vfTF5e6Neuf67XtQK7iIhz616xRBFIAAKDJOGzm8j1mSgEAEHwCFkodOXJEbrdbiYmJFfYnJiYqMzOzyudMmjRJL7zwgjZs2CDDMLR+/XotWbJEpaWlOnLkiCQpMzOzXueUpIULFyomJsa3JScnN/LdBYhhnFi6d+rVksXi19OXuj36/SsbtWbvMUU6Q7T0dyPVM6FplgcCAABI5VffE8v3AAAIRgEfdG75WXBiGEalfV533323Jk+erNGjR8tut+viiy/WjBkzJEk2m61B55Sk+fPnKycnx7elp6c38N0E2P510uGdUkiYNPhyv57aMAzNf+tbfbIzS84Qq164eoQGdo7x62sAAAD8nDeUKiGUAgAg6AQslGrfvr1sNlulDqasrKxKnU5eYWFhWrJkiQoLC7Vv3z6lpaWpe/fuioqKUvv27SVJSUlJ9TqnJDmdTkVHR1fYWiVvl9Qpv5RC/RsYvbYuXW9s2C+b1aJnrzxVo3vE+/X8AAAAVfEOOufqewAABJ+AhVIOh0PDhw/X8uXLK+xfvny5xo4dW+Nz7Xa7unTpIpvNptdee01TpkyR1Wq+lTFjxlQ658cff1zrOVu94lxp+1vm/eFX+/XU32Xm6r73tkuS7pjUV2f3rz7gAwAA8Cd7eSjFTCkAAIJPSCBffN68eZo2bZpGjBihMWPG6Pnnn1daWppuuOEGSeayugMHDmjp0qWSpO+//15r167VqFGjdPz4cT322GPatm2b/vnPf/rOecstt+gXv/iFHnroIV188cV699139cknn/iuzhe0vn1dKi2U2veVkkf57bQFrjLd9PJGuco8OqNvgq4d38Nv5wYAAKgNM6UAAAheAQ2lpk6dqqNHj2rBggXKyMjQwIED9cEHH6hbt26SpIyMDKWlpfmOd7vdevTRR7Vr1y7Z7XadeeaZWrVqlbp37+47ZuzYsXrttdf05z//WXfffbd69uypZcuWadQo/wU1LdLG8mBuuH8HnN/z7nb9cLhAidFOPXb5UFmt/h2eDgAAUBPfTCk6pQAACDoBDaUkafbs2Zo9e3aVj6Wmplb4uX///tq0aVOt57zssst02WWX+aO81uHgZilji2RzSIN/47fTvrFhv97cuF9Wi/Tkb4YpLsLht3MDAADUhYPlewAABK2AX30PfuDtkup/oRThnwHke7LydPc72yRJ887to1EMNgcAAAHA8j0AAIIXoVRrV1IgffuGef9U/ww4Ly5166aXN6mo1K3Te7XXjWf08st5AQAA6st39T1CKQAAgg6hVGtmGNIHt0uuXKlditR9vF9Oe//727XrUJ7aRzr1+NShsjFHCgAABAgzpQAACF6EUq3ZqielzS9LFps05THJ2vh/nO9uPqBX16bLYpGe+M1QJUQ5/VAoAABAw9htLN8DACBYEUq1Vt99IC2/17w/+SGp51mNPuWPh/P1p7e+lSTdfGYvjevVvtHnBAAAaAw6pQAACF6EUq1R5jbpzVmSDGnETGnktY0+ZXGpWze9skkFJW6NSonTLef0aXydAAAAjeQklAIAIGgRSrU2+VnSq7+RSguklAlml5QfPPDfHdqZkav4CIeevGIYc6QAAECL4F2+V8LyPQAAgg6hVGtSWiy9dqWUky7F95Iu/6dkszf6tP/ZelD/tzpNkvTY1KFKjA5t9DkBAAD84cTyPSPAlQAAAH8jlGotDEN6f460f60UGiNdsUwKa9fo0/50tEB3vmnOkbrpzJ6a0Ceh0ecEAADwFwedUgAABC1CqdZi1ZPS1mXmlfYuXyq179XoU7rK3LrplY3Kd5VpZPc43cocKQAAWqUvv/xSF154oTp16iSLxaJ33nmn1uesWLFCw4cPV2hoqHr06KHnnnuu6QttgBOdUu4AVwIAAPyNUKo18HiklY+Z9yc/JPU4wy+nXfjBd9p2IFftwu164oqhCrHxrwMAAK1RQUGBhgwZoqeffrpOx+/du1fnn3++xo8fr02bNulPf/qT5syZozfffLOJK60/70ypUjfL9wAACDYhgS4AdXB0j1ScLYWEScNn+OWUH36bodRV+ySZc6Q6xoT55bwAAKD5TZ48WZMnT67z8c8995y6du2qRYsWSZL69++v9evX629/+5suvfTSJqqyYbj6HgAAwYvWmNZg/1rzttMwvww2P15Qojve3CpJun5CD53Zt0OjzwkAAFqPb775RhMnTqywb9KkSVq/fr1KS0sDVFXVHIRSAAAELTqlWoP968zb5NP8crr/W/2T8orL1C8pSrdN7OuXcwIAgNYjMzNTiYmJFfYlJiaqrKxMR44cUceOHSs9x+VyyeVy+X7Ozc1t8jqlE8v3GHQOAEDwoVOqNUgvD6W6ND6UKi5165/f/CRJumFCT98HPQAA0LZYLJYKPxuGUeV+r4ULFyomJsa3JScnN3mNEp1SAAAEMxKJls6VJ2XtMO/7IZR6b/NBHcl3qWNMqC4YXPmvoAAAIPglJSUpMzOzwr6srCyFhIQoPj6+yufMnz9fOTk5vi09Pb05SpWDTikAAIIWy/daugMbJBlSTFcpKqlRpzIMQy989aMk6Zpx3emSAgCgjRozZozef//9Cvs+/vhjjRgxQnZ71fMrnU6nnE5nc5RXgSPE7NyiUwoAgOBDKtHSeedJdRnR6FOt+P6wvj+Ur0hniH4zsmujzwcAAFqG/Px8bd68WZs3b5Yk7d27V5s3b1ZaWpoks8tp+vTpvuNvuOEG/fTTT5o3b5527typJUuW6MUXX9Rtt90WiPJr5LDZJEmldEoBABB06JRq6bzzpJJHNvpUL6zcK0maelqyokMbfxU/AADQMqxfv15nnnmm7+d58+ZJkq6++mqlpqYqIyPDF1BJUkpKij744APdeuuteuaZZ9SpUyc9+eSTuvTSS5u99towUwoAgOBFKNWSGcZJnVKNmye142CuvtpzRDarRdeM69742gAAQItxxhln+AaVVyU1NbXSvgkTJmjjxo1NWJV/eEOpMo8hj8eQ1Vr1IHYAAND6sHyvJTv2o1R0TLI5paTBjTqVd5bU5IFJ6tIu3B/VAQAANDm77UQIxbBzAACCC6FUS+btkuo4RApxNPg0h3KL9f6Wg5Kka8f38EdlAAAAzcLbKSURSgEAEGwIpVqy9LXmbSPnSaWu2qdSt6GR3eM0JDm28XUBAAA0E8dJVwtmrhQAAMGFUKol88OV9wpcZXp59U+SpFnjU/xRFQAAQLOxWCy+JXyEUgAABBdCqZaqpEA6tN2836XhnVKvr09XbnGZUtpH6Jz+iX4qDgAAoPl4u6VKWb4HAEBQIZRqqQ5ukgy3FNVJiuncoFO4PYaWfL1PkvS701O4Wg0AAGiVvHOl6JQCACC4EEq1VN6le8mnNfgUH2/PVNqxQrULt+uyU7v4qTAAAIDm5Q2lXIRSAAAEFUKplirdO0+q4aHU0m/MWVJXje6mMIfNH1UBAAA0O3v58j2uvgcAQHAhlGqJDOOkIecNmyd1KLdYq/celSRNPS3ZX5UBAAA0O2+nVCmdUgAABBVCqZYo+yepIEuy2qWOQxp0iv9szZBhSMO7tVOXduF+LhAAAKD5OOiUAgAgKBFKtUT715u3HQdL9tAGneK9LQclSRcN6eSvqgAAAAKCQecAAAQnQqmWKH2tedvAeVI/HS3QlvRsWS3S+YM6+rEwAACA5uftlCqlUwoAgKBCKNUS7W/ckPP3y7ukxvVqr4Qop7+qAgAACAiuvgcAQHAilGppSoukzK3m/QaGUt6lexeydA8AAAQBlu8BABCcCKVamowtkqdMikyUYrvW++nfZebq+0P5ctismnRKUhMUCAAA0LzsvuV7RoArAQAA/kQo1dKcPE/KYqn309/bbHZJTeiboJgwuz8rAwAACIgTnVLuAFcCAAD8iVCqpWnEPCnDMPT+Vq66BwAAgouzvFOqhEHnAAAEFUKplsQwGhVKbUrPVvqxIoU7bDqnf6KfiwMAAAgM7/I9ZkoBABBcCKVaktwDUl6GZLFJnYbV++nepXvnDkhUmMPm7+oAAAACwrd8j5lSAAAEFUKplsTbJZU0UHKE1+upbo+h/36bIYmlewAAILhw9T0AAIIToVRLkvWdedtxSL2fuubHozqc51JMmF3jeyf4uTAAAIDAYfkeAADBiVCqJcnPNG+jO9f7qe9tMZfunT8oyffXRAAAgGDg/WxTyqBzAACCCulFS5KfZd5GdqjX00rKPPpwmxloXcjSPQAAEGScLN8DACAoEUq1JHnlnVKRSfV62pffH1ZOUak6RDk1KiW+CQoDAAAIHId3+R6dUgAABBVCqZbE1ymVWK+neZfuTRncSTarxd9VAQAABJTdZn6+oVMKAIDgQijVUhiGlH/IvB9V91CqsKRMy3eYz7toKEv3AABA8HGE2CTRKQUAQLAhlGopio5LnlLzfkTdZ0p9tfuIikrdSo4L05AuMU1UHAAAQOA4mCkFAEBQIpRqKbzzpMLipBBHnZ+2MS1bkjSuZ3tZLCzdAwAAwYflewAABCdCqZYivzyUiqrfkPPN6cclScO6xvq5IAAAgJbBe/W9UpbvAQAQVAilWgrfkPO6L90rc3u0dX+OJGlY13ZNURUAAEDA+ZbvEUoBABBUCKVaCu/yvci6d0p9fyhfhSVuRTlD1CshsokKAwAACCyHrXzQOcv3AAAIKoRSLUUDOqU2lS/dG5IcK6uVeVIAACA4MVMKAIDgRCjVUjRgptSm8iHnQ5Nj/V8PAABAC8HyPQAAghOhVEuRd8i8jUys81M2p2dLYsg5AAAIbr5Qik4pAACCCqFUS5Ffv1Aqp6hUe7LyJdEpBQAAgpvDRqcUAADBKOCh1LPPPquUlBSFhoZq+PDhWrlyZY3Hv/zyyxoyZIjCw8PVsWNHXXPNNTp69Kjv8dTUVFkslkpbcXFxU7+VxvGGUnVcvrelvEuqW3y44iOdTVQUAABA4Hk7pUrplAIAIKgENJRatmyZ5s6dq7vuukubNm3S+PHjNXnyZKWlpVV5/FdffaXp06dr5syZ2r59u15//XWtW7dOs2bNqnBcdHS0MjIyKmyhoaHN8ZYapqRQcuWa9+s46Jx5UgAAoK1gphQAAMEpoKHUY489ppkzZ2rWrFnq37+/Fi1apOTkZC1evLjK41evXq3u3btrzpw5SklJ0emnn67rr79e69evr3CcxWJRUlJSha1F83ZJhYRJzug6PcV75b1hhFIAACDIeZfvlboNeTxGgKsBAAD+ErBQqqSkRBs2bNDEiRMr7J84caJWrVpV5XPGjh2r/fv364MPPpBhGDp06JDeeOMNXXDBBRWOy8/PV7du3dSlSxdNmTJFmzZtqrEWl8ul3NzcCluzys8ybyM7SBZLrYcbhnHSkPN2TVgYAABA4NlDTnxkpVsKAIDgEbBQ6siRI3K73UpMrDjYOzExUZmZmVU+Z+zYsXr55Zc1depUORwOJSUlKTY2Vk899ZTvmH79+ik1NVXvvfeeXn31VYWGhmrcuHHavXt3tbUsXLhQMTExvi05Odk/b7Ku8svfbx3nSe07WqjswlI5Qqzq37FunVUAAACtlbdTSpJKCaUAAAgaAR90bvlZZ5BhGJX2ee3YsUNz5szRPffcow0bNuijjz7S3r17dcMNN/iOGT16tK666ioNGTJE48eP17///W/16dOnQnD1c/Pnz1dOTo5vS09P98+bq6s875X36jpPyly6N6hzjG/GAgAAQLA6OZQqYdg5AABBIyRQL9y+fXvZbLZKXVFZWVmVuqe8Fi5cqHHjxun222+XJA0ePFgREREaP368HnjgAXXs2LHSc6xWq0477bQaO6WcTqeczgBewc47Uyqybp1SDDkHAABtidVqUYjVojKPwfI9AACCSMDabBwOh4YPH67ly5dX2L98+XKNHTu2yucUFhbKaq1Yss1mk2R2WFXFMAxt3ry5ysCqxfAt36s6jPu5E/OkYpumHgAAgBbG2x1eWsagcwAAgkXAOqUkad68eZo2bZpGjBihMWPG6Pnnn1daWppvOd78+fN14MABLV26VJJ04YUX6tprr9XixYs1adIkZWRkaO7cuRo5cqQ6deokSbr//vs1evRo9e7dW7m5uXryySe1efNmPfPMMwF7n7XyDTqvPZQqKnFrZ4Y5iJ0h5wAAoK1whFhVWOJWidsd6FIAAICfBDSUmjp1qo4ePaoFCxYoIyNDAwcO1AcffKBu3bpJkjIyMpSWluY7fsaMGcrLy9PTTz+tP/zhD4qNjdVZZ52lhx56yHdMdna2rrvuOmVmZiomJkbDhg3Tl19+qZEjRzb7+6uzvPJOqTos39t2MEdlHkMdopzqFBPaxIUBAAC0DPbyuVIuZkoBABA0AhpKSdLs2bM1e/bsKh9LTU2ttO/mm2/WzTffXO35Hn/8cT3++OP+Kq95+Dqlah907h1yPqxrbLUD4QEAAIKNd9g5g84BAAgeXLot0DxuqaA8lIqqvVPqxJBzlu4BAIC2w+mdKeVmphQAAMGCUCrQCo5IhkeSRQpvX+vhDDkHAABtkXfQOZ1SAAAED0KpQMs/ZN5GJEi2mldTZuQUKSOnWFaLNLhLTDMUBwAA0DJ4Z0ox6BwAgOBBKBVo3lAqqvYr720uX7rXLyla4Y6AjwMDAABoNic6pVi+BwBAsCCUCjRvKBVZeyi1iaV7AACgjfINOnezfA8AgGBBKBVoeZnmbWRdhpybV94bmhzbhAUBAAC0PHZmSgEAEHQIpQItv/zKe5Edajys1O3RtwdyJEnDunLlPQAA0LZ4O6VK6ZQCACBoEEoFWn55p1RUzZ1SuzLzVFzqUXRoiHq0j2iGwgAAAFoOJ51SAAAEHUKpQMvzzpSquVPKt3SvaztZrZamrgoAAKBFcRBKAQAQdAilAs036LzmTqlN5VfeG8Y8KQAA0AbZbeYf5Rh0DgBA8CCUCiTDOBFKRdV89b3N+7MlSUO58h4AAGiD6JQCACD4EEoFUkm+VFpo3o+sPpRyewylHzOP65MY1RyVAQAAtCgOm00SnVIAAAQTQqlA8s6TckRJjuqHl2fmFqvUbchusygpOrSZigMAAGg57CHly/folAIAIGgQSgWS98p7tQw593ZJdYoNk40h5wAAoA1y2syPraV0SgEAEDQIpQLJN0+q5iHn3lCqa1x4U1cEAADQIjFTCgCA4EMoFUje5Xu1dUodL5IkdWlHKAUAANomQikAAIIPoVQgeTulIuvWKZUcF9bUFQEAALRI9vLley6W7wEAEDQIpQLJt3yv+ivvSSeFUnRKAQCANsrbKVVKpxQAAEGDUCqQfJ1StYRSx72dUoRSAACgbXKUd0qV0CkFAEDQIJQKpLzaQ6niUrcO5bokMegcAAC0XcyUAgAg+BBKBVJ+pnlbQyh1INscch7hsKlduL05qgIAAGhxvJ1SpXRKAQAQNAilAsVdKhUeNe9HVT/oPO3YiaV7FoulOSoDAABoceiUAgAg+BBKBUp+lnlrDZHC4qo9bH95KNWFIecAAKAN8119j1AKAICgQSgVKN4h5xEdJGv1/xjSj5vL95LjwpqjKgAA0Eo9++yzSklJUWhoqIYPH66VK1fWePzLL7+sIUOGKDw8XB07dtQ111yjo0ePNlO19efrlGL5HgAAQYNQKlC8oVRULVfeK++UYsg5AACozrJlyzR37lzddddd2rRpk8aPH6/JkycrLS2tyuO/+uorTZ8+XTNnztT27dv1+uuva926dZo1a1YzV1533lCKmVIAAAQPQqlAya/9ynuSlH68fKYUy/cAAEA1HnvsMc2cOVOzZs1S//79tWjRIiUnJ2vx4sVVHr969Wp1795dc+bMUUpKik4//XRdf/31Wr9+fTNXXnfeQefMlAIAIHgQSgVKXt1CqbSjJwadAwAA/FxJSYk2bNigiRMnVtg/ceJErVq1qsrnjB07Vvv379cHH3wgwzB06NAhvfHGG7rggguqfR2Xy6Xc3NwKW3Ni0DkAAMGHUCpQ8jPN2xpCqZyiUuUWl0mSurRjphQAAKjsyJEjcrvdSkys+JkiMTFRmZmZVT5n7NixevnllzV16lQ5HA4lJSUpNjZWTz31VLWvs3DhQsXExPi25ORkv76P2ng7pUrdRrO+LgAAaDqEUoHivfpeDTOlvPOk4iMcinCGNEdVAACglbJYLBV+Ngyj0j6vHTt2aM6cObrnnnu0YcMGffTRR9q7d69uuOGGas8/f/585eTk+Lb09HS/1l8bOqUAAAg+JB2Bkld7p9T+4yzdAwAANWvfvr1sNlulrqisrKxK3VNeCxcu1Lhx43T77bdLkgYPHqyIiAiNHz9eDzzwgDp27FjpOU6nU06n0/9voI7sthNX36spcAMAAK0HnVKB4u2Uikyq9pD0Y0WSCKUAAED1HA6Hhg8fruXLl1fYv3z5co0dO7bK5xQWFspqrfgx0GazSTI7rFoib6eUZAZTAACg9SOUCgTDODFTqoble2nHvFfeY54UAACo3rx58/TCCy9oyZIl2rlzp2699ValpaX5luPNnz9f06dP9x1/4YUX6q233tLixYv1448/6uuvv9acOXM0cuRIderUKVBvo0bOk0Ip5koBABAcWL4XCEXHJXeJeT+iQ7WHpbN8DwAA1MHUqVN19OhRLViwQBkZGRo4cKA++OADdevWTZKUkZGhtLQ03/EzZsxQXl6enn76af3hD39QbGyszjrrLD300EOBegu18i7fk8rnSgVuJSEAAPATQqlA8C7dC42V7KHVHpbu65QilAIAADWbPXu2Zs+eXeVjqamplfbdfPPNuvnmm5u4Kv+xWS2yWS1yewyGnQMAECRYvhcI+bUPOTcMQ/uPmzOlutIpBQAAIEd5t1QpM6UAAAgKhFKB4O2UqmGe1OE8l1xlHlktUsfY6rupAAAA2grvsHMXnVIAAAQFQqlAyKu9U8o75LxjTFiFGQoAAABtlfczEcv3AAAIDqQdgZB/yLytIZQ6MeScK+8BAABIJ67Ax/I9AACCA6FUIHhDqaikag9JP2bOk2LIOQAAgMm7fK+EUAoAgKBAKBUIdVi+573yHkPOAQAATA6W7wEAEFQIpQLBO+i8DjOlkgmlAAAAJEn2EIskQikAAIIFoVQg5NfeKbX/ePnyPWZKAQAASDqpU4rlewAABAVCqeZWWiwV55j3o6oOpUrdHmXkMFMKAADgZL6ZUnRKAQAQFBoUSn3xxRd+LqMNceVK8b2liAQpNLbKQw5mF8ljmFeYSYhyNm99AAAALZSdmVIAAASVBoVS5513nnr27KkHHnhA6enp/q4puEV2kG5eL92+R7JYqjzEe+W9Lu3CZKnmGAAAgLbGWd4pVcryPQAAgkKDQqmDBw/qlltu0VtvvaWUlBRNmjRJ//73v1VSUuLv+tqkNK68BwAAUIlv+R6hFAAAQaFBoVRcXJzmzJmjjRs3av369erbt69uuukmdezYUXPmzNGWLVv8XWebkn6cK+8BAAD8nIPlewAABJVGDzofOnSo7rzzTt10000qKCjQkiVLNHz4cI0fP17bt2/3R41tTnp5pxRDzgEAAE7wzpRyEUoBABAUGhxKlZaW6o033tD555+vbt266X//+5+efvppHTp0SHv37lVycrJ+/etf+7PWNiP9ePmV9+LCAlwJAABAy+FgphQAAEElpCFPuvnmm/Xqq69Kkq666io9/PDDGjhwoO/xiIgI/fWvf1X37t39UmRbs7+8U6oLnVIAAAA+vplSdEoBABAUGhRK7dixQ0899ZQuvfRSORyOKo/p1KmTPv/880YV1xYVuMp0tMAcGN81nlAKAADAi5lSAAAElwaFUp9++mntJw4J0YQJExpy+jbNO+Q8Jsyu6FB7gKsBAABoOVi+BwBAcGnQTKmFCxdqyZIllfYvWbJEDz30UKOLasvSjzFPCgAAoCq+TilCKQAAgkKDQqm///3v6tevX6X9p5xyip577rlGF9WWceU9AACAqtlDuPoeAADBpEGhVGZmpjp27Fhpf0JCgjIyMup1rmeffVYpKSkKDQ3V8OHDtXLlyhqPf/nllzVkyBCFh4erY8eOuuaaa3T06NEKx7z55psaMGCAnE6nBgwYoLfffrteNQWSd/lechyhFAAAwMmYKQUAQHBpUCiVnJysr7/+utL+r7/+Wp06darzeZYtW6a5c+fqrrvu0qZNmzR+/HhNnjxZaWlpVR7/1Vdfafr06Zo5c6a2b9+u119/XevWrdOsWbN8x3zzzTeaOnWqpk2bpi1btmjatGm6/PLLtWbNmvq/0QDwdUoRSgEAAFTATCkAAIJLg0KpWbNmae7cuXrppZf0008/6aefftKSJUt066236tprr63zeR577DHNnDlTs2bNUv/+/bVo0SIlJydr8eLFVR6/evVqde/eXXPmzFFKSopOP/10XX/99Vq/fr3vmEWLFuncc8/V/Pnz1a9fP82fP19nn322Fi1a1JC32ux8M6XaMVMKAADgZN5Qik4pAACCQ4NCqTvuuEMzZ87U7Nmz1aNHD/Xo0UM333yz5syZo/nz59fpHCUlJdqwYYMmTpxYYf/EiRO1atWqKp8zduxY7d+/Xx988IEMw9ChQ4f0xhtv6IILLvAd880331Q656RJk6o9Z0tiGAbL9wAAAKrBoHMAAIJLSEOeZLFY9NBDD+nuu+/Wzp07FRYWpt69e8vpdNb5HEeOHJHb7VZiYmKF/YmJicrMzKzyOWPHjtXLL7+sqVOnqri4WGVlZbrooov01FNP+Y7JzMys1zklyeVyyeVy+X7Ozc2t8/vwp2MFJSoscUuSOsfSKQUAAHAy3/K9MiPAlQAAAH9oUKeUV2RkpE477TQNHDiwXoHUySwWS4WfDcOotM9rx44dmjNnju655x5t2LBBH330kfbu3asbbrihweeUpIULFyomJsa3JScnN+i9NFb6cXPpXmK0U6F2W0BqAAAAaKm8nVIuOqUAAAgKDeqUkqR169bp9ddfV1pamkpKSio89tZbb9X6/Pbt28tms1XqYMrKyqrU6eS1cOFCjRs3TrfffrskafDgwYqIiND48eP1wAMPqGPHjkpKSqrXOSVp/vz5mjdvnu/n3NzcgARTaeVDzruydA8AAKASOzOlAAAIKg3qlHrttdc0btw47dixQ2+//bZKS0u1Y8cOffbZZ4qJianTORwOh4YPH67ly5dX2L98+XKNHTu2yucUFhbKaq1Yss1mdhQZhtnGPWbMmErn/Pjjj6s9pyQ5nU5FR0dX2AIhI9vslGLpHgAAQGW+mVJl7gBXAgAA/KFBnVIPPvigHn/8cd10002KiorSE088oZSUFF1//fXq2LFjnc8zb948TZs2TSNGjNCYMWP0/PPPKy0tzbccb/78+Tpw4ICWLl0qSbrwwgt17bXXavHixZo0aZIyMjI0d+5cjRw5Up06dZIk3XLLLfrFL36hhx56SBdffLHeffddffLJJ/rqq68a8labVVGp+QEr3NngBjYAAICg5Zsp5WamFAAAwaBBnVI//PCD74p3TqdTBQUFslgsuvXWW/X888/X+TxTp07VokWLtGDBAg0dOlRffvmlPvjgA3Xr1k2SlJGRobS0NN/xM2bM0GOPPaann35aAwcO1K9//Wv17du3wnLBsWPH6rXXXtNLL72kwYMHKzU1VcuWLdOoUaMa8lablbcV3ftXQAAAENz++c9/6r///a/v5zvuuEOxsbEaO3asfvrppwBW1jI5Wb4HAEBQaVBLTlxcnPLy8iRJnTt31rZt2zRo0CBlZ2ersLCwXueaPXu2Zs+eXeVjqamplfbdfPPNuvnmm2s852WXXabLLrusXnW0BN4PWN4PXAAAILg9+OCDWrx4sSTpm2++0dNPP61FixbpP//5j2699dY6zelsS+ze5XsMOgcAICg0KJQaP368li9frkGDBunyyy/XLbfcos8++0zLly/X2Wef7e8a2wzvBywHoRQAAG1Cenq6evXqJUl65513dNlll+m6667TuHHjdMYZZwS2uBbIt3yPTikAAIJCg0Kpp59+WsXFxZLMuU92u11fffWVfvWrX+nuu+/2a4FtCcv3AABoWyIjI3X06FF17dpVH3/8sW699VZJUmhoqIqKigJcXcvjDaVcdEoBABAU6h1KlZWV6f3339ekSZMkSVarVXfccYfuuOMOvxfX1vhCKTqlAABoE84991zNmjVLw4YN0/fff++b2bl9+3Z17949sMW1QHabRZL5mckwDFkslgBXBAAAGqPe6UdISIhuvPFGuVyupqinTXOxfA8AgDblmWee0ZgxY3T48GG9+eabio+PlyRt2LBBV1xxRYCra3mcNpvvPlfgAwCg9WvQ8r1Ro0Zp06ZNvqvkwT/olAIAoG2JjY3V008/XWn//fffH4BqWr6TPyOVuj18ZgIAoJVrUCg1e/Zs/eEPf9D+/fs1fPhwRUREVHh88ODBfimurWGmFAAAbctHH32kyMhInX766ZLMzql//OMfGjBggJ555hm1a9cuwBW2LCeHUCVlHkU4A1gMAABotAaFUlOnTpUkzZkzx7fPYrH41va73W7/VNfG0CkFAEDbcvvtt+uhhx6SJH377bf6wx/+oHnz5umzzz7TvHnz9NJLLwW4wpbFZrXIapE8xomrFgMAgNarQaHU3r17/V0HdOLDlZNQCgCANmHv3r0aMGCAJOnNN9/UlClT9OCDD2rjxo06//zzA1xdy+QIsaq41OP7Yx4AAGi9GhRKMUuqadApBQBA2+JwOFRYWChJ+uSTTzR9+nRJUlxcnHJzcwNZWovlsJWHUnRKAQDQ6jUolFq6dGmNj3s/UKF+TsyUstVyJAAACAann3665s2bp3Hjxmnt2rVatmyZJOn7779Xly5dAlxdy+T94x2dUgAAtH4NCqVuueWWCj+XlpaqsLBQDodD4eHhhFIN5P2LH51SAAC0DU8//bRmz56tN954Q4sXL1bnzp0lSR9++KHOO++8AFfXMnkvCFNKpxQAAK1eg0Kp48ePV9q3e/du3Xjjjbr99tsbXVRbxfI9AADalq5du+o///lPpf2PP/54AKppHeiUAgAgeDQolKpK79699de//lVXXXWVvvvuO3+dtk1x+ZbvEUoBANBWuN1uvfPOO9q5c6csFov69++viy++WDaW81fJbiOUAgAgWPgtlJIkm82mgwcP+vOUbUpJmVsSnVIAALQVe/bs0fnnn68DBw6ob9++MgxD33//vZKTk/Xf//5XPXv2DHSJLY73c5KL5XsAALR6DQql3nvvvQo/G4ahjIwMPf300xo3bpxfCmuLvDOlnIRSAAC0CXPmzFHPnj21evVqxcXFSZKOHj2qq666SnPmzNF///vfAFfY8nhDqVI6pQAAaPUaFEpdcsklFX62WCxKSEjQWWedpUcffdQfdbVJzJQCAKBtWbFiRYVASpLi4+P117/+lT/0VcM75qCETikAAFq9BoVSHg8fAvytzO2RxzDvM1MKAIC2wel0Ki8vr9L+/Px8ORyOAFTU8jHoHACA4EH60UKc/Nc+OqUAAGgbpkyZouuuu05r1qyRYRgyDEOrV6/WDTfcoIsuuijQ5bVI3j/eldIpBQBAq9eg9OOyyy7TX//610r7H3nkEf36179udFFt0cl/7SOUAgCgbXjyySfVs2dPjRkzRqGhoQoNDdXYsWPVq1cvLVq0KNDltUh0SgEAEDwatHxvxYoVuvfeeyvtP++88/S3v/2t0UW1Rd4PVhaLFGK1BLgaAADQHGJjY/Xuu+9qz5492rlzpwzD0IABA9SrV69Al9Zi2cs7pVyEUgAAtHoNCqWqm3Ngt9uVm5vb6KLaIu8HK4fNKouFUAoAgGA1b968Gh//4osvfPcfe+yxJq6m9fF1SrF8DwCAVq9BodTAgQO1bNky3XPPPRX2v/baaxowYIBfCmtrvB+sWLoHAEBw27RpU52O449UVfN+ViotMwJcCQAAaKwGhVJ33323Lr30Uv3www8666yzJEmffvqpXn31Vb3++ut+LbCt8C7fcxJKAQAQ1D7//PNAl9CqeQedl7jdAa4EAAA0VoNCqYsuukjvvPOOHnzwQb3xxhsKCwvT4MGD9cknn2jChAn+rrFNKDlp+R4AAACqxqBzAACCR4NCKUm64IILdMEFF/izljaN5XsAAAC18/4Br9TN8j0AAFq7BiUg69at05o1ayrtX7NmjdavX9/ootoiX6cUoRQAAEC1vJ+VuPoeAACtX4MSkJtuuknp6emV9h84cEA33XRTo4tqiwilAAAAame3sXwPAIBg0aAEZMeOHTr11FMr7R82bJh27NjR6KLaIhczpQAAAGrlmynlJpQCAKC1a1AC4nQ6dejQoUr7MzIyFBLS4DFVbRozpQAAAGrnvVJxcSlX3wMAoLVrUAJy7rnnav78+crJyfHty87O1p/+9Cede+65fiuuLTmxfM8W4EoAAABarsToUElSRk5RgCsBAACN1aC2pkcffVS/+MUv1K1bNw0bNkyStHnzZiUmJupf//qXXwtsK0pYvgcAAFCrbvHhkqSfjhbKMAxZLJYAVwQAABqqQaFU586dtXXrVr388svasmWLwsLCdM011+iKK66Q3W73d41tQkmZ2YLuZPkeAABAtZLbmaFUXnGZsgtL1S7CEeCKAABAQzV4AFRERIROP/10de3aVSUlJZKkDz/8UJJ00UUX+ae6NoSZUgAAALULc9jUIcqprDyX0o4VEkoBANCKNSiU+vHHH/XLX/5S3377rSwWS6XWabebwZP1xfI9AACAuukWH66sPJd+OlaoIcmxgS4HAAA0UIMSkFtuuUUpKSk6dOiQwsPDtW3bNq1YsUIjRozQF1984ecS24YTg84JpQAAAGqSHGcu4Us7WhDgSgAAQGM0qFPqm2++0WeffaaEhARZrVbZbDadfvrpWrhwoebMmaNNmzb5u86g52L5HgAAQJ10i4uQJKUdKwxwJQAAoDEalIC43W5FRkZKktq3b6+DBw9Kkrp166Zdu3b5r7o2hE4pAACAujn5CnwAAKD1alACMnDgQG3dulWSNGrUKD388MP6+uuvtWDBAvXo0cOvBbYVzJQCAACN8eyzzyolJUWhoaEaPny4Vq5cWePxLpdLd911l7p16yan06mePXtqyZIlzVRt4/iW79EpBQBAq9ag5Xt//vOfVVBgruF/4IEHNGXKFI0fP17x8fFatmyZXwtsK+iUAgAADbVs2TLNnTtXzz77rMaNG6e///3vmjx5snbs2KGuXbtW+ZzLL79chw4d0osvvqhevXopKytLZWVlzVx5w3g7pTJzi1Vc6lao3RbgigAAQEM0KJSaNGmS736PHj20Y8cOHTt2TO3atatwFT7UXUn5TCknoRQAAKinxx57TDNnztSsWbMkSYsWLdL//vc/LV68WAsXLqx0/EcffaQVK1boxx9/VFxcnCSpe/fuzVlyzdyl0k9fS3mHpMGXSz/7fBkf4VCEw6aCErf2Hy9Srw6RASoUAAA0ht8SkLi4OAKpRqBTCgAANERJSYk2bNigiRMnVtg/ceJErVq1qsrnvPfeexoxYoQefvhhde7cWX369NFtt92moqKial/H5XIpNze3wtZkDENaerH09nVS0fFKD1sslpOW8HEFPgAAWisSkBaCmVIAAKAhjhw5IrfbrcTExAr7ExMTlZmZWeVzfvzxR3311Vfatm2b3n77bS1atEhvvPGGbrrppmpfZ+HChYqJifFtycnJfn0fFYQ4pPB4835e1e/Bu4QvjWHnAAC0WiQgLYR3+R6dUgAAoCF+3rFuGEa1Xewej0cWi0Uvv/yyRo4cqfPPP1+PPfaYUlNTq+2Wmj9/vnJycnxbenq6399DBZFJ5m1eRpUPd4uPkCT9xLBzAABaLRKQFsLF8j0AANAA7du3l81mq9QVlZWVVal7yqtjx47q3LmzYmJifPv69+8vwzC0f//+Kp/jdDoVHR1dYWtSUd5QqupOqa5xdEoBANDakYC0ECzfAwAADeFwODR8+HAtX768wv7ly5dr7NixVT5n3LhxOnjwoPLz8337vv/+e1mtVnXp0qVJ660zbyiVX3MoRacUAACtFwlIC8GgcwAA0FDz5s3TCy+8oCVLlmjnzp269dZblZaWphtuuEGSufRu+vTpvuN/+9vfKj4+Xtdcc4127NihL7/8Urfffrt+97vfKSwsLFBvo6JaOqW8M6XSjxXK4zGaqyoAAOBHIYEuACZmSgEAgIaaOnWqjh49qgULFigjI0MDBw7UBx98oG7dukmSMjIylJaW5js+MjJSy5cv180336wRI0YoPj5el19+uR544IFAvYXKImsOpTrFhslmtchV5lFWnktJMaHNWBwAAPAHQqkWwtsp5SSUAgAADTB79mzNnj27ysdSU1Mr7evXr1+lJX8tSi2dUnabVZ1iQ5V+rEg/HS0glAIAoBUiAWkhTsyUsgW4EgAAgBaglplSktQtzrwCXxpzpQAAaJUIpVoIlu8BAACc5OROKaPqmVFdy+dKEUoBANA6kYC0EAw6BwAAOElkonnrLpGKjld5iO8KfEcJpQAAaI1IQFoIQikAAICThDilsDjzfnVX4IujUwoAgNaMBKQFMAzjxPI9G/9IAAAAJElRHc3bauZKsXwPAIDWjQSkBfAGUhKdUgAAAD5R5Uv4qumU8i7fO1ZQorzi0uaqCgAA+AkJSAvgXbonSU5CKQAAAJO3Uyovo+qHQ+2Ki3BIolsKAIDWKOAJyLPPPquUlBSFhoZq+PDhWrlyZbXHzpgxQxaLpdJ2yimn+I5JTU2t8pji4uLmeDsNcnIoxfI9AACAct5h53mHqj3E2y2VxrBzAABanYAmIMuWLdPcuXN11113adOmTRo/frwmT56stLS0Ko9/4oknlJGR4dvS09MVFxenX//61xWOi46OrnBcRkaGQkNDm+MtNYh3+V6I1SKr1RLgagAAAFqIWjqlpJOuwEenFAAArU5AQ6nHHntMM2fO1KxZs9S/f38tWrRIycnJWrx4cZXHx8TEKCkpybetX79ex48f1zXXXFPhOIvFUuG4pKSk5ng7DcaV9wAAAKrgnSmVX32nVDeGnQMA0GoFLAUpKSnRhg0bNHHixAr7J06cqFWrVtXpHC+++KLOOeccdevWrcL+/Px8devWTV26dNGUKVO0adMmv9XdFAilAAAAqlCPTimW7wEA0PqEBOqFjxw5IrfbrcTExAr7ExMTlZlZ9RVWTpaRkaEPP/xQr7zySoX9/fr1U2pqqgYNGqTc3Fw98cQTGjdunLZs2aLevXtXeS6XyyWXy+X7OTc3twHvqOG8y/eYJwUAAHCSk2dKGYZkqTzm4MTyvYLmrAwAAPhBwFMQy88+XBiGUWlfVVJTUxUbG6tLLrmkwv7Ro0frqquu0pAhQzR+/Hj9+9//Vp8+ffTUU09Ve66FCxcqJibGtyUnJzfovTQUnVIAAABViCofweB2SUXHqzykW3yEJOlgdrFK3Z4qjwEAAC1TwFKQ9u3by2azVeqKysrKqtQ99XOGYWjJkiWaNm2aHA5HjcdarVaddtpp2r17d7XHzJ8/Xzk5Ob4tPT297m/EDwilAAAAqhDilMLamfermSvVIcopZ4hVbo+hg9lFzVgcAABorIClIA6HQ8OHD9fy5csr7F++fLnGjh1b43NXrFihPXv2aObMmbW+jmEY2rx5szp27FjtMU6nU9HR0RW25sTyPQAAgGrUMlfKarUo2buEj7lSAAC0KgGbKSVJ8+bN07Rp0zRixAiNGTNGzz//vNLS0nTDDTdIMjuYDhw4oKVLl1Z43osvvqhRo0Zp4MCBlc55//33a/To0erdu7dyc3P15JNPavPmzXrmmWea5T01hLdTykmnFAAAQEWRiVLWDnOuVDW6xYVrT1Y+V+ADAKCVCWgoNXXqVB09elQLFixQRkaGBg4cqA8++MB3Nb2MjAylpaVVeE5OTo7efPNNPfHEE1WeMzs7W9ddd50yMzMVExOjYcOG6csvv9TIkSOb/P00FMv3AAAAqlGXK/DFl1+Bj1AKAIBWJaChlCTNnj1bs2fPrvKx1NTUSvtiYmJUWFj9B47HH39cjz/+uL/Kaxa+5XuEUgAAABVFlc8arWamlHTSFfiOcgU+AABaE1KQFsBVxkwpAACAKtWhU6qbr1OKQecAALQmpCAtAMv3AAAAqhGVZN7mZVZ7SNe4CElS2tECGYbRHFUBAAA/IAVpAU6EUrYAVwIAANDCRNYeSnVpFyaLRSoocetoQUkzFQYAABqLUKoF8M6UstssAa4EAACghTm5U6qaLqhQu01J0aGSGHYOAEBrQijVAng7pZws3wMAAKgosnzQudslFWdXe5h32HnaUUIpAABaC1KQFqCEQecAAABVs4dKYe3M+zUs4fMOO/+JUAoAgFaDFKQF8C7fY9A5AABAFeowV8rXKcXyPQAAWg1SkBaAq+8BAADUoC5X4IsvvwLfsYLmqAgAAPgBKUgL4PIt3+PqewAAAJV4Q6n8GpbvxbF8DwCA1oZQqgWgUwoAAKAGdemUKg+lsvJcKipxN0dVAACgkUhBWgBmSgEAANSgDjOlYsPtigoNkSSlH6dbCgCA1oAUpAUoKTP/mkcoBQAAUIU6dEpZLBb1aG/OldqZkdscVQEAgEYiBWkBvMv3nDb+cQAAAFTiC6Uyajzs1G7tJEnr9h1r6ooAAIAfkIK0ACzfAwAAqIFv0PkhyTCqPWxk9zhJ0rq9x5ujKgAA0EikIC0Ag84BAABq4J0pVVYsFWdXe9hpKWYotetQnrILS5qhMAAA0BikIC2AL5Ri+R4AAEBl9lApNNa8n3eo2sPaRzrVI8GcK7V+H91SAAC0dKQgLYCLTikAAICaRXU0b2uZK+VbwsdcKQAAWjxSkBaAmVIAAAC1iEo0b/Or75SSpNPKQ6k1ewmlAABo6UhBWgBmSgEAANSirp1S5XOlth3IUWFJWVNXBQAAGoEUpAVgphQAAEAtIss7pWqYKSVJXdqFKSk6VGUeQ5vTspu+LgAA0GCkIC2Ad/mek04pAACAqtWxU8pisfi6pdYyVwoAgBaNFKQFYPkeAABALeo4U0qSTkth2DkAAK0BKUgLQCgFAABQizp2SkknrsC38adslZZ3pAMAgJaHFCTAPB5DZR5DEjOlAAAAquWbKZUpGUaNh/buEKmYMLuKSt3adiCnGYoDAAANQQoSYCUn/fWOTikAAIBqRCWZt2XFUnHNQZPVatFp3dtJYgkfAAAtGSlIgLnKCKUAAABqZQ+TQmPM+3mZtR5+WvkSvrV7jzdlVQAAoBFIQQKs5ORQiuV7AAAA1fPOlcqvQyhVPux8/U/H5PHUvNwPAAAEBilIgHmX7zlsVlkslgBXAwAA0IKdPFeqFgM7xSjMblN2Yal2Z+U3cWEAAKAhCKUCjCvvAQAA1JHvCny1h1KOEKuGdY2VJK1lrhQAAC0SSUiAEUoBAADUkXfYeR1CKenEXKl1ewmlAABoiUhCAswXSjFPCgAAoGbeUKoOM6UkaWT5XKl1+47JMJgrBQBAS0MSEmAlbrckOqUAAABqVc9OqWFdYxVitSgjp1j7jxc1YWEAAKAhSEICzMXyPQAAgLqJrF8oFe4I0SmdYySZ3VIAAKBlIQkJMJbvAQAA1NHJnVJ1XI43qnwJ31rmSgEA0OKQhAQYg84BAADqyBtKlRVJxTl1eop32DlX4AMAoOUhCQmwEjehFAAAQJ3Yw6RQczme8g/V6SkjurWTJP14uEBH8l1NVRkAAGgAkpAA83ZKOQmlAAAAauebK5VRp8PbRTjUJzFSkrSebikAAFoUkpAAY6YUAABAPfjmStWtU0o6aQnf3uNNUREAAGggkpAAY/keAABAPUTVr1NKkkaWDzv/5sejTVERAABoIJKQAGPQOQAAQD14Q6k6zpSSpNN7tVeI1aKdGbnak5XXRIUBAID6IgkJMBfL9wAAAOouqqN5m7O/zk+Jj3TqjL4JkqQ3Nx5oiqoAAEADkIQEGJ1SAAAA9dBhgHl7cFO9nvarU7tIkt7ZdEBuj+HvqgAAQAOQhAQYM6UAAADqofNwyWKTctKlnLp3PZ3Vr4OiQ0OUkVOs1cyWAgCgRSAJCTA6pQAAAOrBGSklDTTvp6+p89NC7TZdOKSTJOnNjXVf+gcAAJoOSUiAeUMpJzOlAAAA6iZ5lHmbvrZeT/Mu4ftoW6YKXGX+rgoAANQTSUiA0SkFAABQT75QanW9nnZq11h1jw9XYYlb/9ue2QSFAQCA+iAJCTBmSgEAANSTN5TK2CqVFNT5aRaLxdct9RZX4QMAIOBIQgLM1ynF8j0AAIC6iU2WojtLhls6sLFeT/3lsM6SpK9/OKKD2UVNUR0AAKgjkpAAc/mW79kCXAkAAEArkjzSvK3HsHNJSo4L18iUOBmG9M5muqUAAAgkQqkAY/keAABAAySPNm/rGUpJ0qWnmt1Sb208IMMw/FkVAACoB5KQACspc0silAIAAI3z7LPPKiUlRaGhoRo+fLhWrlxZp+d9/fXXCgkJ0dChQ5u2QH/zdUqtlTyeej31/EEd5Qyxak9Wvr49kNMExQEAgLogCQkwZkoBAIDGWrZsmebOnau77rpLmzZt0vjx4zV58mSlpaXV+LycnBxNnz5dZ599djNV6kdJgyR7uFScLR35vl5PjQq1a9IpSZIYeA4AQCCRhASYd/mek04pAADQQI899phmzpypWbNmqX///lq0aJGSk5O1ePHiGp93/fXX67e//a3GjBnTTJX6kc0udR5u3m/AEr5flS/he2/LQd8fCQEAQPMiCQkwX6cUoRQAAGiAkpISbdiwQRMnTqywf+LEiVq1alW1z3vppZf0ww8/6N57763T67hcLuXm5lbYAq6Bw84l6fRe7ZUQ5dSxghKt+P6wnwsDAAB1QRISYIRSAACgMY4cOSK3263ExMQK+xMTE5WZmVnlc3bv3q0777xTL7/8skJCQur0OgsXLlRMTIxvS05ObnTtjdaIYechNqsuGdpJkvTmhv3+rAoAANRRwJOQ+gzlnDFjhiwWS6XtlFNOqXDcm2++qQEDBsjpdGrAgAF6++23m/ptNBgzpQAAgD9YLJYKPxuGUWmfJLndbv32t7/V/fffrz59+tT5/PPnz1dOTo5vS09Pb3TNjdZlhHl7dI9UcKTeT//VqV0kSZ9+d0jZhSX+rAwAANRBQJOQ+g7lfOKJJ5SRkeHb0tPTFRcXp1//+te+Y7755htNnTpV06ZN05YtWzRt2jRdfvnlWrOm/n9Baw7emVJ0SgEAgIZo3769bDZbpa6orKysSt1TkpSXl6f169fr97//vUJCQhQSEqIFCxZoy5YtCgkJ0WeffVbl6zidTkVHR1fYAi48TkroZ95PX1vvp/fvGK0BHaNV6jYYeA4AQAAENAmp71DOmJgYJSUl+bb169fr+PHjuuaaa3zHLFq0SOeee67mz5+vfv36af78+Tr77LO1aNGiZnpX9eNi+R4AAGgEh8Oh4cOHa/ny5RX2L1++XGPHjq10fHR0tL799ltt3rzZt91www3q27evNm/erFGjRjVX6f7hmyu1ukFP/+2orpKkF1b+yMBzAACaWcCSkIYO5TzZiy++qHPOOUfdunXz7fvmm28qnXPSpEk1njOQgztZvgcAABpr3rx5euGFF7RkyRLt3LlTt956q9LS0nTDDTdIMpfeTZ8+XZJktVo1cODACluHDh0UGhqqgQMHKiIiIpBvpf58c6Xq3yklSZcN76L2kU4dzCnWu5vplgIAoDkFLAlpyFDOk2VkZOjDDz/UrFmzKuzPzMys9zkDNbjTMAzf8j0nnVIAAKCBpk6dqkWLFmnBggUaOnSovvzyS33wwQe+P9xlZGRUOx6h1Usu7+w6sFEqc9X76aF2m64dnyJJWrziB7k9hj+rAwAANQh4ElLXoZw/l5qaqtjYWF1yySWNPmegBneWeQwZ5Z97WL4HAAAaY/bs2dq3b59cLpc2bNigX/ziF77HUlNT9cUXX1T73Pvuu0+bN29u+iKbQnxPKTxecrukjK0NOsWVo7spOjREPx4u0P+21/7HUQAA4B8BS0LqO5TzZIZhaMmSJZo2bZocDkeFx5KSkup9zkAN7jx5bgGhFAAAQANYLCe6pRo4VyrSGaIZY7tLkp75fI8Mg24pAACaQ8CSkPoO5TzZihUrtGfPHs2cObPSY2PGjKl0zo8//rjWcwZChVCKmVIAAAAN4wulGn615RnjUhRmt2n7wVyt+P6wnwoDAAA1CWgSUp+hnCd78cUXNWrUKA0cOLDSY7fccos+/vhjPfTQQ/ruu+/00EMP6ZNPPtHcuXOb+u3Um3eelNUihRBKAQAANIw3lEpbIzWwyykuwuG7Et+zX/zgr8oAAEANApqENGQoZ05Ojt58880qu6QkaezYsXrttdf00ksvafDgwUpNTdWyZcta5OWNfVfeY+keAABAw3UaJlntUkGWdHxfg09z7fgestssWrv3mNbtO+a/+gAAQJUsBovmK8nNzVVMTIxycnKadL7Unqx8nfPYCkWHhmjrfZOa7HXw/9u78/CoqvMP4N/ZJzNJJvtOwk6AQJDVAEJVZBEVbBWs1g2stVgVrVYRd6tQW9vqT8Ed3ArUfQGVaFkFlCUIAkIghASyrzPJJLOe3x83GRKSkElyZyaE7+d5znMnM3fOe+7kOJy8nnMuERGRfPw1Tujuut3n8MYU4ORO4OpXgfTrOl3Noo/3YdWP+bh4UDRW3DpWxgYSERGdP7wdJ3CKTgCdnimlCnBLiIiIiM5xMuwrBQB/mNQPSgWw4XApDhRUy9AwIiIiaguTUgHUuKeUjsv3iIiIiLqm6b5SXdA7yoiZwxMAAMu5txQREZFPMRsSQNxTioiIiEgmjUmpkoNAfddmOC34VT8AwNr9hcgprelqy4iIiKgNzIYEkCcpxTvvEREREXVNSCwQ3geAAH54rUtVDY4PxaWpMRACeHVTjjztIyIiohaYDQkgu8sFgDOliIiIiGQx6X7puPFZIGdjl6pacHF/AMCHe05iF+/ER0RE5BPMhgQQl+8RERERyeiC30lFuIEP5wPmgk5XNSolHLNHJMDlFvjTf7JQXmOTsaFEREQEMCkVUDYu3yMiIiKS1+X/AOKGAdYy4L83A057p6t65uph6BdtRJG5HgvX7IXbLWRsKBERETEbEkCcKUVEREQkM00QMOcdQGcCTv4IZD7W6aqMOjWW3TAKeo0SW7LL8PKGozI2lIiIiJgNCSC7i0kpIiIiItlF9AWuXi49/mE58PPHna5qUFwI/jp7GADgX98ewbajZXK0kIiIiMCkVEBxphQRERGRj6TOBCbcIz3+/C6g9Einq7pmVBLmjE6CWwB3r96LEnO9TI0kIiI6vzEbEkCNSSkd95QiIiIikt8ljwEpEwF7DfDfmwB7baerevKqNKTGhaCsxoa7VmXB2TDjnYiIiDqP2ZAA4kwpIiIiIh9SqYFr3gKCY4HSQ8BXD3a6qiCtCi/fMBJGrQo/HK/Av7/NlrGhRERE5ydmQwKIe0oRERER+VhIrJSYAoCfVgGW4k5X1S86GEt/MxwA8NKGo9jwS4kcLSQiIjpvMRsSQJ6ZUly+R0REROQ7vScCSWMBt1NKTHXBlekJuPHCFADA3auzcKy0Ro4WEhERnZeYDQkgG5fvEREREfnHyJuk4553ACG6VNUjVwzG6JRwWOqd+P3bu1Bd55ChgUREROcfZkMCiMv3iIiIiPxk6NWANhioOAac2NalqnRqFZb/bhQSTHrklNXirlVZcLm7lugiIiI6HzEbEkDc6JyIiIjIT3TBQNqvpcd73ulyddEhOrx202joNUpsPlKKpV8d6nKdRERE5xtmQwKIe0oRERER+dHIm6XjwU+BuqouV5eWaMLz144AALy+5Tg+3H2yy3USERGdT5gNCaDGpJSOM6WIiIiIfC9xFBAzBHDWA/s/kKXKmcPjcfcl/QEAD3+8H3vyKmWpl4iI6HzAbEgAcU8pIiIiIj9SKJpveC6ThVMGYuqQWNhdbvzh3d0orK6TrW4iIqKejNmQAOKeUkRERER+NnwuoNICRfuAgr2yVKlUKvCvuSOQGheCUosNt7+zG3V2lyx1ExER9WTMhgTQ6T2lVAFuCREREdF5whABDL5SeizjbCmjTo3XbxqNcIMG+09VY+Ea3pGPiIioPUxKBZCNy/eIiIiI/K9xCd/+DwC7VbZqe0UY8NpNo6FVK/HNgWI8s5Z35CMiIjobZkMCiMv3iIiIiAKg9yQgLAWwmYGDn8la9ZjeEXj+2nQAwFvfH8eK74/LWj8REVFPwmxIANmd0l4DWhV/DURERER+o1QCI2+UHme9K3v1V6Yn4MHpqQCAp748iPUHimSPQURE1BMwGxJAvPseERERUYCMuAFQKIET3wNlR2Wv/o7JfXH9uGQIAdy9Ogt786tkj0FERHSuYzYkgBqX7+mYlCIiIiLyr9AEYMBU6XGWfBueN1IoFHjqqqGYPDAa9Q43bnt7J/Ir5Nu/ioiIqCdgNiSAuKcUERERUQA1bni+9z+AyyF79WqVEi/fMBJD4kNRVmPHLSt+RLVV/jhERETnKmZDAsiTlOKeUkRERET+N2AqEBwL1JZKd+LzgWCdGm/dMgbxJj2Oldbit6/vQG5ZrU9iERERnWuYDQkg7ilFREREFEAqDTDm99LjtfcDJYd8EibOpMdbt4xBhFGLg4VmXPl/W/HV/kKfxCIiIjqXMBsSIG63gMMlADApRURERBQwE+8F+kwCHLXA6uuBuiqfhBkcH4q1d0/EmN7hsNic+OP7e/DE5wdga7gbMxER0fmI2ZAAaZwlBTApRURERBQwKjVwzUrA1AuoyAE+/j3gdrf7ts6INwXhP7+/EH+Y3BcAsHJbLua8sp0boBMR0XmL2ZAAaZaU4p5SRERERIFjjATmvgeo9UD2emDTUp+F0qiUWDRjMN68eTRMQRr8dLIaM1/cgvUHinwWk4iIqLtiNiRAGjc5B5iUIiIiIgq4hBHAFf+WHm/6G/DLWp+Gu3RwLNbdcxEuSA6Dud6J29/djb9+ebDZGJGIiKinYzYkQBoHHBqVAkqlIsCtISIiIiKM+C0w9g/S44//AJQe8Wm4xLAgrLk9A/Mn9gEAvLH1OOa8uh0nK7mcj4iIzg9MSgVIY1KKs6SIiIiIupFpzwDJ4wG7BVhzA1Bv9mk4rVqJR68YgldvHIVQvRp786sw88Wt+PZgsU/jEhERdQfMiARI455S3OSciIiIqBtRaYA5bwMhCUDZEWnjc0edz8NOGxqHtXdfhPQkE6rrHLjtnV14dt0hOFxczkdERD0XMyIB4pkpxaQUERERUfcSHAPMfRdQaYEjXwMrZgDVJ30etleEAR/cMR7zJkjL+V7bnIM5r27HqSrfJ8WIiIgCgRmRALExKUVERETUfSWNBm74EAiKAAqygNd+BZzY7vOwWrUSj105BK/8bhRC9Gpk5VVh+r8344Nd+RBC+Dw+ERGRPzEjEiDcU4qIiIiom+s7Gbh9AxCbBtSWAm9fAex80y+hp6fFYd3dF2FErzBY6p144MN9mLdyJ4qq6/0Sn4iIyB+YEQmQ03tKqQLcEiIiIiJqU3hvYP56YOjVgNsJrL0P+OIewGnzeeheEQZ8eEcGHpyeCq1KiQ2HS3HZvzZx1hQREfUYTEoFCPeUIiIiIjpHaI3ANSuAKU8AUAC7VwJvXwlYfH+HPLVKiT/+qh/W3j0R6Zw1RUREPQwzIgHSmJTScfkeERERUfenUAAT75X2mdKZgPwfgJUzAUuRX8IPiA3BR3dk4KEZqdCqT8+aWv1jHmdNERHROYsZkQCxu1wAOFOKiIiI6JwyYArw+/8Bpl5AeTaw8gq/JabUKiXumNwP65rMmnro4/24/vUfkFtW65c2EBERyYkZkQDh8j0iIiKic1RUf+DmLwKSmAKA/jHSrKlHZg6GXqPE9pxyTPv3Zryy6RicDfuWEhERnQuYEQkQ3n2PiIiI6BwW0SegiSm1SonbLuqL9QsnY2L/KNicbiz96hfMevl7/Hyq2m/tICIi6gpmRALExplSREREROe2xsRUaFJAElMAkBxpwLvzx+Lv1wyHKUiDAwVmzHr5ezyz9iAqau1+bQsREVFHMSMSIHYXk1JERERE57yIPsAtXwY0MaVQKHDt6F749r7JmDk8Hi63wOtbjmPC0v/hmbUHUWLhXfqIiKh7YkYkQLinFBEREVEPcWZi6q3pwP4PAZfTr82IDtHh5etHYsUtY5CWGIo6hwuvbzmOiX/bgMc/+xkFVXV+bQ8REVF7mBEJEO4pRURERNSDNE1MVR4HPpoPvDgC2P4yYLP4tSkXp8bgiz9NxIpbx2BkchjsTjfe3n4Ck/++AYs+3oec0hq/toeIiKgtzIgESGNSSseZUkREREQ9Q0Qf4I4twK8eBgxRQHU+8M3DwD+HAusfBapP+a0pCoUCFw+KwUd/HI//3DYOF/aNgMMlsOrHfFzy/Cbc9NaP+O5QMVxu4bc2ERERnYkZkQDhnlJEREREPZAhAvjVg8C9PwNXvgBEDQRs1cC2F4EXhgNfPww4bX5rjkKhwPj+UVh9ewY+uCMDl6bGQKEANh8pxfy3d+FX/9iA1zYfQ5WVm6ITEZH/MSMSIFy+R0RERNSDaYKAUbcAC34AfrsGSJkIuJ3AjpelPacqc/3epDG9I/DmLWOw6f6LcfukvjAFaZBfUYdn1/2Ccc9+hwc/3IfsYv8uNSQiovMbMyIBwo3OiYiIiM4DSiUwaDpw61opORUUDhTsAV6dBBz6MiBNSo404OHLB2PHokvxt98Mw+D4UNicbqzZlY/L/rUZ81fuxA855RCCS/uIiMi3mBEJEBuX7xERERGdXwZNB/6wBUgaC9RXA2tuaFjOF5ilc0FaFeaOSca6uyfigzsyMG1oLBQK4LtfSjD3tR2YvWwb1u0v5L5TRETkMwHPiCxbtgx9+vSBXq/HqFGjsGXLlrOeb7PZsHjxYqSkpECn06Ffv3546623PK+vXLkSCoWiRamvr/f1pXQIZ0oRERERnYfCegG3rgMy/iT9vONlYMUMoCovYE1SKBQY0zsCr944Gt/dNxnXj0uGVq3ET/lVWPD+Hlzy/Ea8t+ME6h2ugLWRiIh6poBmRNasWYOFCxdi8eLFyMrKwkUXXYQZM2YgL6/tf5TnzJmD7777Dm+++SYOHz6MVatWITU1tdk5oaGhKCwsbFb0er2vL6dDuKcUERER0XlKpQGmPQNctwrQm4BTu4BXJgKb/wHUVQW0aX2jg/Hs1cOw7aFLcPcl/RFm0OBEuRWPfPozJj23AW9syYHV7gxoG4mIqOdQiAAuFh83bhxGjhyJ5cuXe54bPHgwZs+ejSVLlrQ4/+uvv8Z1112HnJwcREREtFrnypUrsXDhQlRVVXW6XWazGSaTCdXV1QgNDe10PWfz29d2YHtOOV64bgRmjUj0SQwiIiKSnz/GCecCfg4yqTwBfHgrcGq39LM2BBh9K5BxJxASF9i2AbDanfjvzny8tjkHBdXSyoMIoxbzJvTGjRm9YQrSBLiFRETUHXk7TgjYNB273Y7du3dj6tSpzZ6fOnUqtm3b1up7Pv/8c4wePRrPPfccEhMTMXDgQNx///2oq6trdl5NTQ1SUlKQlJSEK664AllZWWdti81mg9lsblZ8ze7iTCkiIiKi8154CjBvPfDr14GYIYDdAmx7Efj3MOCLe4DyYwFtnkGrxi0T+mDjAxfjb78Zht6RBlTU2vGP9Ucwcen/8PdvfsHxstqAtpGIiM5d6kAFLisrg8vlQmxsbLPnY2NjUVRU1Op7cnJysHXrVuj1enzyyScoKyvDggULUFFR4dlXKjU1FStXrsSwYcNgNpvxwgsvYMKECfjpp58wYMCAVutdsmQJnnzySXkvsB3cU4qIiIiIAAAqNTB8DjDsWiB7PbDln0D+DmD3SmDPO0D/y4DUmcCgGUBwTECaqFUrMXdMMn4zMglr9xfi5Q1HcaS4Bi9vOIaXNxxDalwIpg2Nw4xhcRgUGwKFQhGQdhIR0bklYMv3CgoKkJiYiG3btiEjI8Pz/DPPPIN3330Xv/zyS4v3TJ06FVu2bEFRURFMJhMA4OOPP8Y111yD2tpaBAUFtXiP2+3GyJEjMWnSJLz44outtsVms8Fms3l+NpvN6NWrl0+no0/712YcLrbg3fljcdGAaJ/EICIiIvlx2ZqEn4OPndgObP0XkP1NkycVQK+xwKDLpSRVVOv/w9Uf3G6BzEPFeG/HCWw/Vg5nkzv09Y40YHpaPGYOi0daYigTVERE5yFvxwkBmykVFRUFlUrVYlZUSUlJi9lTjeLj45GYmOhJSAHSHlRCCJw8ebLVmVBKpRJjxoxBdnZ2m23R6XTQ6XSdvJLO4fI9IiIiImpTSoZUSg8DBz8HDq8FCrKA/B+k8u3jQOQAYPhcYMT1gMm/e5QqlQpMGxqHaUPjUGW149tDJfj65yJszi5FbrkVr2w6hlc2HcOg2BBcMyoJsy5IQExI97rxEBERBV7AMiJarRajRo1CZmZms+czMzMxfvz4Vt8zYcIEFBQUoKamxvPckSNHoFQqkZSU1Op7hBDYu3cv4uPj5Wu8DLh8j4iIiIjaFT0ImPwAcPtG4N6DwOX/APpdAig1QHk2sOGvwL/TgPevlZJXTrvfmxhm0OKaUUl44+bR2PPoZXjp+gswc1g8tGolDhdb8My6Q8hY8j/c9vZOfP1zoWccTEREFNCMyH333Yc33ngDb731Fg4dOoR7770XeXl5uOOOOwAAixYtwk033eQ5//rrr0dkZCRuvfVWHDx4EJs3b8YDDzyAefPmeZbuPfnkk/jmm2+Qk5ODvXv3Yv78+di7d6+nzu7CxqQUERERyWjZsmXo06cP9Ho9Ro0ahS1btrR57scff4zLLrsM0dHRCA0NRUZGBr755ps2z6duwpQIjP09cOMnwF+OAbNfAVImAMIt7UX13xuBfw4G1j8CFOwFXA6/NzFYp8YVwxPw8g0jsXPxFDxzdRouSA6Dyy3w7aES3PHeHox79lvc8e5uvPS/bGw8XILyGlv7FRMRUY8UsOV7ADB37lyUl5fjqaeeQmFhIdLS0rBu3TqkpKQAAAoLC5GXl+c5Pzg4GJmZmbjrrrswevRoREZGYs6cOfjrX//qOaeqqgq33367Z9+pCy64AJs3b8bYsWP9fn1nY3e6AAA6JqWIiIioi9asWYOFCxdi2bJlmDBhAl599VXMmDEDBw8eRHJycovzN2/ejMsuuwzPPvsswsLCsGLFClx55ZX44YcfcMEFFwTgCqjD9CZgxG+lUn4MyHoX2PsfoKYY2PZ/UlHpgNihQHx6QxkOxAwFNP5ZRmcK0uCGcSm4YVwKjpbU4MPdJ/HxnpMosdjw9YEifH3g9DYe8SY90hJNGNErDNOGxqJ/TIhf2khERIEVsI3OuzN/bNyZ+uhXqHe4sfmBi5EcafBJDCIiIpJfd9zge9y4cRg5ciSWL1/ueW7w4MGYPXs2lixZ4lUdQ4cOxdy5c/HYY495dX53/BzOey4ncDQT2PMukLsFsJlbnqNQARoDoFQBSnWTogQMUcDIm4D06wBNyxsIycHpcmP3iUrsO1mNnwuqsf9UNY6X1eLMv0j6RRsxIy0e09PiMDSBm6UTEZ1ruv1G5+c77ilFREREcrDb7di9ezceeuihZs9PnToV27Zt86oOt9sNi8WCiIiINs9p7W7F1M2o1MCgGVJxu4HK40DhT0DRPulY+BNgLQfsltbfX5UHFOwB/vdXYNwfgNHzAWOkrE1Uq5QY1zcS4/qerrfG5sTBAjP2n6rG90fLsDW7DMdKa/HShqN4acNRJIUHYfrQOEweFI2RyeEw6vgnDBFRT8Fv9ABwutxovGsuk1JERETUFWVlZXC5XC3uXhwbG9viLsdtef7551FbW4s5c+a0ec6SJUvw5JNPdqmt5EdKJRDZTyppv5aeE0Ja3mevBdwuQLgAt7OhuID8H4Edy4HqPGDDM8CWfwIX3ABcuECqx0eCdWqM7ROBsX0iMH9iH5jrHdjwi3Q3v42HS3Gysg5vbD2ON7Yeh0qpwNCEUIzpHYExvcMxuncEooL9exdtIiKSD5NSAWB3nb7jCJNSREREJIczlzcJIbxa8rRq1So88cQT+OyzzxATE9PmeYsWLcJ9993n+dlsNqNXr16dbzD5n0IBhMS1/XrSaGDs7cDBT4FtL0ozq3a+Aex8E+g7GRgwFeg/BYgaKNXlI6F6DWaNSMSsEYmos7uw6Ugp1h8swg85FThVVYd9J6ux72Q13tx6HIC01G/KkFjMSItHepKJS/2IiM4hTEoFQNPb4GpVTEoRERFR50VFRUGlUrWYFVVSUtJi9tSZ1qxZg/nz5+ODDz7AlClTznquTqeDTscZKT2eSg0MuwZI+420L9W2/5Pu7JezUSrfPAyYkoH+lwIDLgP6TAJ0vtuUPEirwvS0OExPk5Jpp6rqsCu3Aj8er8DO3AocKa7BsdJaHNuUg1c35SDBpMe0tDjMSIvHqJRwqJRMUBERdWdMSgVA06SURsV/KImIiKjztFotRo0ahczMTFx99dWe5zMzMzFr1qw237dq1SrMmzcPq1atwsyZM/3RVDqXKBRSwqnPJOnufke+Bo5+C+R+Ly3v271CKoC0ebpKAyg1UlJLqZE2Tw+OBuJHAAkXSCVmCKDWth5PCGlZoUIBaI1tNisxLAiJDbOoAKDKasfWo2X46ucibPilBAXV9VjxfS5WfJ+L6BAdLuofhcHxoUiND0FqXCiiQ5hYJSLqTpiUCgBbk03OOb2YiIiIuuq+++7DjTfeiNGjRyMjIwOvvfYa8vLycMcddwCQlt6dOnUK77zzDgApIXXTTTfhhRdewIUXXuiZZRUUFASTyRSw66BuKrIfkHGnVOy1UmLqaCaQnSltpi5cgNMFoL75+ywF0hLAPW9LP6u0QGwaEJcm3SnQWgbUlgK15dLRWScltFIvl+4C2Pdi6S6BZxFm0OKK4Qm4YngC6h0ubD5Siq9/LkLmoWKUWmz4OOsUkHXKc35UsBapcaHoHxMMlVIBm9MFu9MNm9MNm8MNu8uNcIMWV41IwMT+UZxpRUTkYwohzrwBK/n6FsfHSmtw6fObEKJTY/+T02Svn4iIiHzH1+OEzlq2bBmee+45FBYWIi0tDf/6178wadIkAMAtt9yC3NxcbNy4EQDwq1/9Cps2bWpRx80334yVK1d6Fa+7fg7kZ9YKwGkD3A7A5ZA2TXc5pJ+r8oCCrIayF6iv6ljdpl7ABb8DRtwAhHVs/zK7040dOeX4Kb8KvxRZcKjIjNyyWs/NhrwRG6rDr0cm4Tcjk9A/JrhjbSciOs95O05gUqoVvh5kHSo0Y8YLWxBp1GL3o5fJXj8RERH5DpMxEn4O1CFCAJW5UoKq5BCgCQKM0YAxqvmx4jiw5x1g32qgvrrhzQppD6v4EdKyQJVaOjYuE9QagJihQOxQQKNvswl1dheySyz4pdCCY2U1UEABnVoJrVoJXUPRqpU4WGDGZz8VoMrq8Lz3guQwXDMqCZMGRCMpPIirHYiI2sGkVBf4epD1U34VZr38PeJNemxfdKns9RMREZHvMBkj4edAPuWoAw59KS39y93i3XsUKiBmMBCfLiWw4tOB8N6ALhjQGDp0x0Cb04X/HSrBR3tOYsPhUriaTLEK0asxOE7ap2pwfCgGx4diYGwwDFrujEJE1MjbcQK/OQPA7jq9pxQREREREZ1BEwQMv1Yq5ceAnz8Casuk5YFuB+B2nV4uWFcJFO0DrOVA8c9S2fv+GRUqAG2wtIm6ruGoMQBqvRRLrZd+1kg/67QhmKE1YsZQI8yD9dhxsh4bc+vwTXkUyuuN+DG3Aj/mVjSLoFUrEarXwBSkRmiQpuGxBoPjQ3HViAQkhgX57/MjIjpHMCkVAI1339OqmJQiIiIiIjqryH7A5L+c/RwhAHMBULhX2ly98CdpH6uaosYTALtFKjUdCx8KYGpDeUanhjU+A9kRk7BZNQ47y/U4VGhGWY0ddqcbZTU2lNXYmr3/858K8Levf8HYPhGYPSIRM4fFw2TQdKwRREQ9FJNSAWB3cqYUEREREZFsFArAlCiV1Jmnn3e7AYdVumugvaah1AK2Guluf4566XVnvbRk0FnfcG7TYpGO1nIoKnNhPLUFI05twQgASBgJTL4CtUkXocatgaXehRqbCzU2Jyw2F6rqXNiUW4vv8lz48XgFfjxegSc+P4BfDYrGrBGJGNMnHDEhbe+D1S67FTCfAqpPStdmjJZKcIw0M6yze1857dJ7VUye0XnEXAhkPga4bEDGXUCvMYFuke85bYBCGdD/1pmUCgAbk1JERERERL6nVErL9XTBAGK7Xl/5MeCXtcAvXwL5PwIFe4CCPTACMLYR4bcAoANs6hCUukNQ5AxGeXYoqo4E41soEKRRIdygQbhBgzCDBuEGLUL06obN1BVSckihlB5DAJZiwHxSSkRZy9tuq8bQkKCKBaIGAsnjgF7jgMgB0ufSlBBAWTZw7Dvg6LdA7lYpZt+LgUHTgQHTgBAZPj8KLLdLuuFAWDITjk0JIS35/fphwNZwg4WDnwF9JgOTHgB6T2w7wet2STMzLUXSXULDewO6EL81/azqq6Xfd2WulHCzFAI1xVJbLUXSTNK6SuCGj4ABUwLWTCalAsCzpxSX7xERERERnTsi+wET7paKpRg4vE5KUBX+BAi39McthHRsfGyvAYQbOqcFSbAg6cw/AQSA2obSGdpgwJQk/SFcWwbUlkoxHVag6oRUTv4I7H1POl8fBvQaK5Ww3sCJ74Gj3wHVeS3rPrxWKoA0K2zQDGDgNCBmiG+TGm63lHBTKICgcECp8l2sns7llG4WcPAzqa/WlgKGKGDYtUD6ddINAeS8m6SjDqjKB6rzpb3aIvtLM/e8iWGvlfaK05vkbdPZVOUDXy6UkrEAkHCB1L/3rQGOb5JKr3FScqp/Q+Km9BcgZxNwfLOUwG1MZDUyRErJqbAUIDwF0Bgbvh9cDUe3lMwSLmlWoquhOG2nH7udp89xu5u8X0j74OlCpP/2dcGnj06bdAfTyuPSsa75vndt8ixzDgzefa8Vvr6bzIe7T+L+D37CRQOi8O78cbLXT0RERL7Du85J+DkQecntAuqqAGuZlDRqPNZVwuFyo9RiQ0mNDSVmG4otNpRabHC63JDmSQkoIaCAgE6jQGywDsIYDXtwIpwhiUBoEoJCwhFq0CLSqEXf6GBEGLXSH/c1JQ2lSEqa5f0AnNotLVtsjUoLpIyX/vDud6n0R/GRr4HDX0kzwppSKKVEWHgf6Y9vT0kBTMmAMersSQW7Fag4BpQflf54tjTM4rAUSTM6aoqk+I2xgsKlRIoxSvqD3xABKNWQZo+hIVbDrDJ9GJAwQkouhMR1+tfmtfpqoPQwUHJISlaUHJLaHtlPSshE9pdmp4Wn+G92ktMuJUwOfirN7GuanFAopQRHo+jBUnJq+BwgNEFKgFgKTs+wqcwFqvKkfqzSSteg0p5+7HZKCajGRFRtacv2aEOAyL7SZxHRT+o71jKgumHpaeMS1Poq6XyNUWpLaDwQmig9DomXEjIOq5T4ctQ2HOsaluDapWV3jYkdZ72U4AqJBxJHSv0h4QKpLkCqa/cKYP1j0hJdlQ64+GEg40+ASi1d8/cvAHveleoFgOhUKVl65jXqQqX+X33S+0SQvxiipLaZEqXPIjhWOobEAsFx0n8jQeE+SQJ6O05gUqoVvh5k/eeHPDz8yX5MGRyDN24+D9apEhER9SBMxkj4ORD5hsstcKy0BvtOVmP/ySrsO1WNAwVmz7607YkwatEv2oj+McHoFx2MfjHBGBgbggSTHgq3EyjaLy09zP9BSjgkjZYSUb0nSnclbI2lCDjyjZSkytkkJQTORq2XEg+mXg3HJOmP+bJsKRFVne/FlTQsV+yKkPjTyYj4dOm5xsSgtRyoLZceO+qkP8w9Sa/I08kvt1ta4nRmqS2RklHmU961RaGSElOGSCmJoQsB9KENj0OlOz82mxnjOv2zUiO9rg5qfoRCSuZVn2yS3DklJfWaJp4MkcDgK4Ehs4DkDOD4FuCnVVLCqjHhAoXUPnOBlNTpCm2I9Dt3WKXftfCu7/pFcJzUH2xmaZYgACSNBWa9DEQPbHm+pQjY9n/Arrek6wGkzz/5QqDvZKDPJCAuXUpkAUC9WZqd2DSh17hvk1IlHRUNR6VSSoaptIBa2/BYA6h10u+86Xsaj1BI7bBZpBmRtoa98mwWKVEb0ZgobjjqA/fvM5NSXeDrQdbK74/jiS8O4vJhcVh2wyjZ6yciIiLfYTJGws+ByH8cLjeOFFtwsMCMilo7zPUOmOucqK5zwFzvQHWdAyVmG05VtTELCkCwTo0BscEYFBuCAbEhGBQbgoGxwYgO0TXsX+Ult1val6bpTBrPH+AnpD/ivUkm6cOAqAHSzJnQhIbZMHENszjipBkdAGCtOGOWWbmUFGpcytS4XLLxaCkCCrKAssP+S4aEJAAxqdKso5hUKaHQOBOs/Ki0F1ljQsNfjDHAkKsaElHjTydNmqqrkmZT/bQayNt++nmlWkoohveWkhxhyVLCxGUH3A5pBpLLLh2B0wnIsF7Sufqw0zNvnDapb5Q3zow7JiW+DFENNydIAkKTpMehiVJSxlzQpJySjpZCqV0ag7R8TWs4/VgdJCVy1I0JHl1DgkctzcQr2CPdjbPkkNRvGqmDgEsfA8b9of0lorXlQPY30pK8pNFSDDorb8cJ3FMqALinFBEREREReUujUmJogglDE0xnPc9qdyKntBbHSmtwrKQGR0trcLSkBsfLalFjcyIrrwpZeVXN3mMK0mBATDAGxAajf0yI53FcqL71ZJVS2bCsKh5IyWj5utPeMGOncUnXSWlj9qBwaRlb1ABpGZch0rslQyGxndtk3VYjzQoryAIK9wJFP0sJjxazoSKl5EZdpTR7ytowe8paIT1WqoGgMKn9TYshUrqe6EHS62fjdktJlYocabmfzSzNbKk3Nzw2S3eCbDYrRnX66HZIrzfeMdJZJyV73C7pszH1khI6TZM8xuiWG9qfKSgMGHWLVCpzpd9XWHJDckimVIFaJ31G0YO8f09kP6nIoR8AzJce262n+0RtKTDieu/jGCOl80l2TEoFgJ133yMiIiIiIpkZtGqkJZqQltg8eeVwuZFbVovDxRYcKbLgcLEF2cU1yC2vRXWdA7tOVGLXicpm7wnSqNArIgjJEQYkhRuQHGFArwjpmBJpgF7TxswStVaaXRPRx1eX6R1dsJQ0ay1x5m9KZUPCKDHQLWlb475gPZnWIN2FMpn7OncnTEoFAJNSRERERETkLxqVEgMalu1h+Onn6x0u5JTWIrvEgqMlNcgurkF2iQW55VbUOVw4UlyDI8U1LepTKoDkCAP6x0izq/rHBGNAjLR/VbCOf2ISkff4jREANs/yPd7alIiIiIiIAkOvUWFIQiiGJDTf78XudONkpRX5lXXIr7Aiv9IqHSvqcKK8FuZ6J3LLrcgtt+LbQyXN3htp1KJXw2yq5IjTJSpEh1C9BqYgDf/nPBF5MCkVAJwpRURERERE3ZVWrUTf6GD0jQ5u8ZoQAmU1dmSXWHCspAbZDTOsjpbWoNRiQ3mtHeW1duzNr2qzfr1GCVOQBqF6DcIMGsSE6BEdokNsqB4xDcfYUB1iQvUI1as7thE7EZ1TmJQKACaliIiIiIjoXKRQKBAdokN0iA7j+0U1e81S70BehTSr6kS5FXkVp0tFrR2WeicAoN7hRr3DhmKzrd14Rq0KcSY9EsKCEBeqR3xYEBJMegyKC8Hg+NC297YionMCk1IB0JiU0jEpRUREREREPUSIXnPWuwS63AI19U6Y6x2ornPAXOdAhdWOUouUoCqx1KOk4VhstqG6zoFauwvHSmtxrLS2RX0qpQL9oo1ISzBhSEIo0hJN6B8TjHCDFiolZ1cRnQuYlAoAu2dPKSaliIiIiIjo/KBSKmAyaGAyaNDLi/Pr7C4UVtehqLoehdX1KKyuQ2F1PfIr63CwoBplNXbPZuwfZ53yvE+hAMKCNAg3ahFp1CLcoEVksBb9ooORlmjC0IRQhOg1vrtQIvIak1IBwOV7REREREREZxekVZ11b6sSiw0HCqrx8ymz53iqqg5CAJVWByqtDuS0MsMKAPpEGZGWaMKwxFAMiAmBTq2EWqWEWqWARikd1UoFYkL1MAUxgUXkK0xKBQCTUkRERERERJ2nUCgaNkTX45LUWM/zTpcbVXUOVNTam5VSiw2/FJk9iavjZbU4XlaLL34qaDdWXKgeA+NCMDAmWDrGhqBPpBFOtxtWuwt1Dhesdhesdifq7C5oVErEm/SIM+k5I4uoHUxKBQCX7xEREREREclPrVIiKliHqGBdm+eU19jwc4EZP5+qxv6T1ThRYYXT5YbTLeB0u+F0CThcAg6XG9V1DhSZ61FkrsfmI6Udbk+wTo04k15KUoXqkRJpQO8oI/pEGdE70gijjn+S0/mN/wUEgI0zpYiIiIiIiAIiMliHyQOjMXlgdLvnmusdyC6uwZFiCw4XWZBdYsHhohqU1Uh3DtSplTBoVTBo1QjSqmDQqmBzuFFYXQdzvRM1NieOltTgaElNq/XHhOjQJ8qIeJMeKqUSSgWgVCigVEqzwZQKaabWgNgQDIgJRkqkkZu4U4/CpFQAcPkeERERERFR9xeq12BUSjhGpYQ3e77eIS3TO1uCqNbmlGZZVdejoKoOBVX1OFEhLRvMLatFpdWBEosNJRab1+3RqpXoFx2MATHB6BcdjMhgLcIMGoQbtDA1bO4ebtAgSKOCQsHkFXV/TEoFAJNSRERERERE5y69RtXuOUadGv2ipeRRa6qtDhwvlxJUpRYb3ELAJQSEANxuAbcAnG43TlbWIbvEgqMlNah3uHGo0IxDheazxg7SqBAbqvPsuxVn0iMmRPo5wiglssIMTGBR4DEpFQCNe0rpuKcUERERERHReclk0GCEIQwjeoV5db7LLXCqsg5Hii04UmLBiTIrKq12VNU5UGW1o9IqHR0ugTqHC7nlVuSWW9utV6tWIrxhtlV0iA4xIfqGo85zDDdKM7FMQRqvEnJE3mJSKgA4U4qIiIiIiIg6QqVUIDnSgORIA6YMiW31HCEErHYXympsKKquR7HFhpKGJYTFFhuKzfUtElh2pxvFZhuKzTb8UmRptx06tdKToDIFaRAapEGIXo1QfcOx4edgnRpGrRoGnQpGrRpGnbT3llGnRqhezdlZBIBJqYBgUoqIiIiIiIjkplAoYNRJiZ+USONZz21MYFVa7aiyOlBea0epxYYSS33D0YZSsw2lNTZUWu0w1zngFtKNuzq6F9aZdGqltKwwVI9Ykx5xDUsNo4J10GuU0GlUCNKooG84BmlUiArRwqBlCqOn4W80ABqX7zEpRURERERERIHQNIGVFN7++W63QI3diWqrA9V1DpjrpKOl3glzvQPmeifMdQ7pcZ0TVrsTtXYXrDYnrHYXau1OWG0u2F1u2Jxu5FVYkVfR/vLCpsINGiSEBSEhLAiJYUFICNMjwqiDWwi43QJOt4CrobiFQIRRi95RRvSNMiLMoO3kJ0W+xKRUADgaZ0pxTykiIiIiIiI6ByiVCoTqNQjVa9CrC/XUO1wotdg8dyYsbjgWmetRZXWg3uFCvdOFOrsL9Q436h0uWO0u1DlcqLQ6UGl14EDB2Td6b024QYM+UUb0jjIiOcIAg1YFjUoJjUoJrUoJrVp6bNCpEGnUItygRWSwlhvB+xiTUgFg40wpIiIiIiIiOg/pNSr0ijCgV4ShQ+8z1ztQUFXXUOo9jyusDqgUgEqphEoJqJVKKJUKKBVAidmG42W1KDLXSwmtvCrsyavqUFydWokIoxYRRm2LfbMafzbq1FApFVArFQ1HpefnOJMe/WOCuUF8G5iU8jMhBPeUIiIiIiIiIuqAUL0GoXEapMaFdvi9VrsTuWVWHC+rxfGyGpyqqoPN6YbDJeBwumF3ueFoWFZYa3OiotaO8lo77E7pucLqehRW13e67UoFkBxhwIDYEAyKDcGA2GAkhgWhrMaOouo6FJltDcd6FJtt0KgUSI6QZnSlNGxunxJhQFK4ocflEZiU8jOHS3ge61TMlBIRERERERH5kkGrxpCEUAxJ8D6h1bgRfEWtXSoNm7037qFlqXfC0mT/LFfDnlZuIeB0Sfta2V3S3llVVgdyy63ILbci82CxV/GPFNe0+rxOrZSKRiVtCq9WQaduWH6oVEKtUkCtUkKjVHgeGzQqGHVqGLTS0ahVwaCT7pA4olcYEsKCvP5c5MaklJ81bnIOcKYUERERERERUXfUdCP4ji41bEoIgdIaG7KLa3Ck2IIjxTXILragyFyP6BCddAfCUD3iTXrEmaTHNqcbeeW1OFFuxYkKK/LKrThRUYt6hzRzy+Z0A/VOWa7z/357AZNS5xMhBCb0j4TDKZiUIiIiIiIiIurBFAoFYkL0iAnRY0L/qA68M7rZT0IIVNTaUedwSYkphxs2p6shUeWC3emG0y3gcLnhdAk43Q3LE11u1DlcsNpO3wGxxu6E1SbdHTHOpJf3gjuISSk/C9Fr8P5tFwa6GURERERERER0jlAoFIgM1gW6GbLjVB0iIiIiIiIiIvI7JqWIiIiIiIiIiMjvmJQiIiIiIiIiIiK/Y1KKiIiIiIiIiIj8jkkpIiIiIiIiIiLyOyaliIiIiIiIiIjI75iUIiIiIiIiIiIiv2NSioiIiIiIiIiI/I5JKSIiIiIiIiIi8jsmpYiIiIiIiIiIyO+YlCIiIiIiIiIiIr9jUoqIiIiIiIiIiPyOSSkiIiIiIiIiIvK7gCelli1bhj59+kCv12PUqFHYsmXLWc+32WxYvHgxUlJSoNPp0K9fP7z11lvNzvnoo48wZMgQ6HQ6DBkyBJ988okvL4GIiIiIiIiIiDoooEmpNWvWYOHChVi8eDGysrJw0UUXYcaMGcjLy2vzPXPmzMF3332HN998E4cPH8aqVauQmprqeX379u2YO3cubrzxRvz000+48cYbMWfOHPzwww/+uCQiIiIiIiIiIvKCQgghAhV83LhxGDlyJJYvX+55bvDgwZg9ezaWLFnS4vyvv/4a1113HXJychAREdFqnXPnzoXZbMZXX33leW769OkIDw/HqlWrvGqX2WyGyWRCdXU1QkNDO3hVRERE1JNxnCDh50BERERt8XacELCZUna7Hbt378bUqVObPT916lRs27at1fd8/vnnGD16NJ577jkkJiZi4MCBuP/++1FXV+c5Z/v27S3qnDZtWpt1AtKSQLPZ3KwQEREREREREZHvqAMVuKysDC6XC7Gxsc2ej42NRVFRUavvycnJwdatW6HX6/HJJ5+grKwMCxYsQEVFhWdfqaKiog7VCQBLlizBk08+2cUrIiIiIiIiIiIibwV8o3OFQtHsZyFEi+caud1uKBQKvP/++xg7diwuv/xy/POf/8TKlSubzZbqSJ0AsGjRIlRXV3tKfn5+F66IiIiIiIiIiIjaE7CZUlFRUVCpVC1mMJWUlLSY6dQoPj4eiYmJMJlMnucGDx4MIQROnjyJAQMGIC4urkN1AoBOp4NOp+vC1RARERERERERUUcELCml1WoxatQoZGZm4uqrr/Y8n5mZiVmzZrX6ngkTJuCDDz5ATU0NgoODAQBHjhyBUqlEUlISACAjIwOZmZm49957Pe9bv349xo8f73XbGvd+595SREREdKbG8UEA7xXTLXC8RERERG3xerwkAmj16tVCo9GIN998Uxw8eFAsXLhQGI1GkZubK4QQ4qGHHhI33nij53yLxSKSkpLENddcIw4cOCA2bdokBgwYIG677TbPOd9//71QqVRi6dKl4tChQ2Lp0qVCrVaLHTt2eN2u/Px8AYCFhYWFhYWFpc2Sn58v36DoHMTxEgsLCwsLC0t7pb3xUsBmSgHA3LlzUV5ejqeeegqFhYVIS0vDunXrkJKSAgAoLCxEXl6e5/zg4GBkZmbirrvuwujRoxEZGYk5c+bgr3/9q+ec8ePHY/Xq1XjkkUfw6KOPol+/flizZg3GjRvndbsSEhKQn5+PkJCQs+5F5Qtmsxm9evVCfn6+T2+v3NPi+DNWT4vjz1g9LY4/Y/W0OP6M1dPi+DNWT4sjVywhBCwWCxISEmRu3bmF46VzL44/Y/W0OP6M1dPi+DNWT4vjz1g9LY4/Y/GaWufteCmgSSkAWLBgARYsWNDqaytXrmzxXGpqKjIzM89a5zXXXINrrrmm021quhwwUEJDQ33eoXtiHH/G6mlx/Bmrp8XxZ6yeFsefsXpaHH/G6mlx5IjVdH/L8xXHS+duHH/G6mlx/Bmrp8XxZ6yeFsefsXpaHH/G4jW15M14KeB33yMiIiIiIiIiovMPk1JEREREREREROR3TEp1MzqdDo8//jh0Oh3jdNNYPS2OP2P1tDj+jNXT4vgzVk+L489YPS2Ov2OR7/S0vtkT/xvoaXH8GaunxfFnrJ4Wx5+xelocf8biNXWNQojz/H7GRERERERERETkd5wpRUREREREREREfsekFBERERERERER+R2TUkRERERERERE5HdMSnUTmzdvxpVXXomEhAQoFAp8+umnPonzxBNPQKFQNCtxcXE+iWWxWLBw4UKkpKQgKCgI48ePx86dO7tUZ3uf0xNPPIHU1FQYjUaEh4djypQp+OGHH3wS68zPsbH8/e9/9zrGkiVLMGbMGISEhCAmJgazZ8/G4cOHm53z8ccfY9q0aYiKioJCocDevXs7dT3exLrllltaXM+FF14oe5zi4mLccsstSEhIgMFgwPTp05Gdnd3ha1q+fDmGDx+O0NBQhIaGIiMjA1999ZXndbn6Q3tx5OgLrVmyZAkUCgUWLlzoeU6u/tBeHDn6grex5OgP7X23yfnd0F4sOfvDqVOn8Lvf/Q6RkZEwGAwYMWIEdu/e7Xldrv7QXhw5+0N7seToD7179271d3DnnXcCkLc/kH9xvOQdjpc4XmqK4yWOlxpxvMTxUlPdZbzEpFQ3UVtbi/T0dLz00ks+jzV06FAUFhZ6yv79+30S57bbbkNmZibeffdd7N+/H1OnTsWUKVNw6tSpTtfZ3uc0cOBAvPTSS9i/fz+2bt2K3r17Y+rUqSgtLZU9VtPPsLCwEG+99RYUCgV+85vfeB1j06ZNuPPOO7Fjxw5kZmbC6XRi6tSpqK2tbdaOCRMmYOnSpR2+ho7GAoDp06c3u65169bJGkcIgdmzZyMnJwefffYZsrKykJKSgilTprRoS3uSkpKwdOlS7Nq1C7t27cIll1yCWbNm4cCBAwDk6w/txZGjL5xp586deO211zB8+PBmz8vVH9qLA3S9L3gTS87+cLbvNjm/G9qLJVd/qKysxIQJE6DRaPDVV1/h4MGDeP755xEWFuY5R47+4E0cQJ7+0F4sufrDzp07m7U1MzMTAHDttdcCkL8/kP9wvOQdjpc6j+Mljpc6EgfgeKmzsThe6nysHjdeEtTtABCffPKJT+p+/PHHRXp6uk/qbspqtQqVSiW+/PLLZs+np6eLxYsXyxLDm8+purpaABDffvutz2PNmjVLXHLJJV2KU1JSIgCITZs2tXjt+PHjAoDIysrqUoyzxbr55pvFrFmzZKm/rTiHDx8WAMTPP//sOcfpdIqIiAjx+uuvdzleeHi4eOONN1p9Ta7+0F6crvYFi8UiBgwYIDIzM8XkyZPFPffc0+IcOfrD2eLI3RfaiiVXf+jod1tX+kJHY3W2Pzz44INi4sSJXp3blf7gTRy5+kN7sXz1/XDPPfeIfv36Cbfb3errcn43kP9wvOQdjpe6huMl38XheMn7WBwvtY3jJcm5PF7iTKnzUHZ2NhISEtCnTx9cd911yMnJkT2G0+mEy+WCXq9v9nxQUBC2bt0qe7zW2O12vPbaazCZTEhPT/dprOLiYqxduxbz58/vUj3V1dUAgIiICDma1alYGzduRExMDAYOHIjf//73KCkpkTWOzWYDgGZ9Q6VSQavVdqlvuFwurF69GrW1tcjIyGjxulz9ob04cvSFO++8EzNnzsSUKVM6XYccceTsC23FkrM/ePvdJkdf8DZWV/rD559/jtGjR+Paa69FTEwMLrjgArz++uudaq8cceToD+3F8sX3g91ux3vvvYd58+ZBoVC0+rq//q2gcwvHS/LjeMn7OBwvtY/jJY6XAI6XGp3T4yVZU1wkC/jw//ytW7dOfPjhh2Lfvn2eDHxsbKwoKyuTPVZGRoaYPHmyOHXqlHA6neLdd98VCoVCDBw4UJb62/qcvvjiC2E0GoVCoRAJCQnixx9/9FmsRn/7299EeHi4qKur63QMt9strrzyyjaz4nL+n7+2Yq1evVp8+eWXYv/+/eLzzz8X6enpYujQoaK+vl62OHa7XaSkpIhrr71WVFRUCJvNJpYsWSIAiKlTp3Y4xr59+4TRaBQqlUqYTCaxdu3aZq/L1R/ai9Ooq31h1apVIi0tzfN+X/2fv/biyNkXzhZLrv7gzXebXH2hI9+jXekPOp1O6HQ6sWjRIrFnzx7xyiuvCL1eL95+++0W53alP3gTR67+0F4sub8fhBBizZo1QqVSiVOnTjV73hf/VpB/cbzkHY6XOo/jpY7jeInjpY7EasTxUsdi9bTxEpNS3ZAvB1lnqqmpEbGxseL555+Xve6jR4+KSZMmCQBCpVKJMWPGiBtuuEEMHjxYlvrb+pxqampEdna22L59u5g3b57o3bu3KC4u9kmsRoMGDRJ/+tOfuhRjwYIFIiUlReTn57f6upyDrPZiNSooKBAajUZ89NFHssbZtWuXSE9P9/SNadOmiRkzZogZM2Z0OIbNZhPZ2dli586d4qGHHhJRUVHiwIEDntfl6g/txWnUlb6Ql5cnYmJixN69ez3P+WKQ1ZE4jTrbF7yJJWd/aNTad5svvhvaitWoK/1Bo9GIjIyMZs/ddddd4sILL2xxblf6Q0fiNOpsf/Amltz9YerUqeKKK65o8byv+gP5D8dL3uF4yXexGnG85H2cRhwvdTwWx0ut43jp3B8vMSnVDflzkCWEEFOmTBF33HGHz+qvqakRBQUFQggh5syZIy6//HJZ6vX2c+rfv7949tlnfRZr8+bNAkCzf0Q66k9/+pNISkoSOTk5bZ4j1yDLm1hN9e/fXyxdutQncaqqqkRJSYkQQoixY8eKBQsWdDjOmS699FJx++23t/m6HP2hrThd7QuffPKJ5x+WxgJAKBQKoVKphNPp9Jzblf7QkThNdaYvdCSW3P2hve82ufpCW7G62h+Sk5PF/Pnzmz23bNkykZCQ0OLcrvSHjsRpqjP9oSOx5OgPubm5QqlUik8//bTdc+XsD+QfHC95h+Ml38VqiuMl7+NwvNS1WBwvNcfx0rk/XlJ3bfEfnetsNhsOHTqEiy66yGcxjEYjjEYjKisr8c033+C5557zWazWCCE862594c0338SoUaM6tbZWCIG77roLn3zyCTZu3Ig+ffr4oIWdj1VeXo78/HzEx8f7JI7JZAIgrTfftWsXnn76aa/jnC3+2X7fcvWH1urpSl8AgEsvvbTF3Z1uvfVWpKam4sEHH4RKpep0e7sapzN9oaOx5OwP3ny3ydUX2orV1f4wYcKEFrcHP3LkCFJSUjrdVrnidLY/dCSWHP1hxYoViImJwcyZM9s919f/VtC5jeOlruN4qfNxOF5qjuMljpea4nipB4yXZE1xUadZLBaRlZUlsrKyBADxz3/+U2RlZYkTJ07IGufPf/6z2Lhxo8jJyRE7duwQV1xxhQgJCRG5ubmyxhFCiK+//lp89dVXIicnR6xfv16kp6eLsWPHCrvd3uk6z/Y51dTUiEWLFont27eL3NxcsXv3bjF//nyh0+ma3ZlAjliNqqurhcFgEMuXL+/U9fzxj38UJpNJbNy4URQWFnqK1Wr1nFNeXi6ysrLE2rVrBQCxevVqkZWVJQoLC2WNZbFYxJ///Gexbds2cfz4cbFhwwaRkZEhEhMThdlslvWa/vvf/4oNGzaIY8eOiU8//VSkpKSIX//61x26HiGEWLRokdi8ebM4fvy42Ldvn3j44YeFUqkU69evl7U/nC1Oo672hbacOXVbrv5wtjhy9QVvYgkhT38423eb3N8N3nyPytEffvzxR6FWq8UzzzwjsrOzxfvvvy8MBoN47733POfI0R/aiyNnf/DmmuT6fnC5XCI5OVk8+OCDzZ6Xuz+Qf3G85B2OlzheaorjJY6XGnG8xPHSmbrDeIlJqW5iw4YNAkCLcvPNN8saZ+7cuSI+Pl5oNBqRkJAgfv3rX7e6zlsOa9asEX379hVarVbExcWJO++8U1RVVXWpzrN9TnV1deLqq68WCQkJQqvVivj4eHHVVVd1ejM2b34nr776qggKCur0dbVWPwCxYsUKzzkrVqxo9ZzHH39c1lhWq1VMnTpVREdHC41GI5KTk8XNN98s8vLyZL+mF154QSQlJXniPPLII8Jms3UojhBCzJs3T6SkpAitViuio6PFpZde6hn4yNkfzhanUVf7QlvOHJDI1R/OFkeuvuBNLCHk6Q9n+26T+7vBm+9RufrDF198IdLS0oROpxOpqanitddea/a6XP3hbHHk7g/tXZNc3w/ffPONACAOHz7c7Hm5+wP5F8dL3uF4ieOlpjhe4nipEcdLHC+dqTuMlxRCCNHaDCoiIiIiIiIiIiJfUQa6AUREREREREREdP5hUoqIiIiIiIiIiPyOSSkiIiIiIiIiIvI7JqWIiIiIiIiIiMjvmJQiIiIiIiIiIiK/Y1KKiIiIiIiIiIj8jkkpIiIiIiIiIiLyOyaliIiIiIiIiIjI75iUIiLykY0bN0KhUKCqqirQTSEiIiLqljheIjq/MSlFRERERERERER+x6QUERERERERERH5HZNSRNRjCSHw3HPPoW/fvggKCkJ6ejo+/PBDAKeniq9duxbp6enQ6/UYN24c9u/f36yOjz76CEOHDoVOp0Pv3r3x/PPPN3vdZrPhL3/5C3r16gWdTocBAwbgzTffbHbO7t27MXr0aBgMBowfPx6HDx/27YUTEREReYnjJSIKJCaliKjHeuSRR7BixQosX74cBw4cwL333ovf/e532LRpk+ecBx54AP/4xz+wc+dOxMTE4KqrroLD4QAgDY7mzJmD6667Dvv378cTTzyBRx99FCtXrvS8/6abbsLq1avx4osv4tChQ3jllVcQHBzcrB2LFy/G888/j127dkGtVmPevHl+uX4iIiKi9nC8RESBpBBCiEA3gohIbrW1tYiKisL//vc/ZGRkeJ6/7bbbYLVacfvtt+Piiy/G6tWrMXfuXABARUUFkpKSsHLlSsyZMwc33HADSktLsX79es/7//KXv2Dt2rU4cOAAjhw5gkGDBiEzMxNTpkxp0YaNGzfi4osvxrfffotLL70UALBu3TrMnDkTdXV10Ov1Pv4UiIiIiNrG8RIRBRpnShFRj3Tw4EHU19fjsssuQ3BwsKe88847OHbsmOe8pgOwiIgIDBo0CIcOHQIAHDp0CBMmTGhW74QJE5CdnQ2Xy4W9e/dCpVJh8uTJZ23L8OHDPY/j4+MBACUlJV2+RiIiIqKu4HiJiAJNHegGEBH5gtvtBgCsXbsWiYmJzV7T6XTNBlpnUigUAKQ9FhofN2o6uTQoKMirtmg0mhZ1N7aPiIiIKFA4XiKiQONMKSLqkYYMGQKdToe8vDz079+/WenVq5fnvB07dngeV1ZW4siRI0hNTfXUsXXr1mb1btu2DQMHDoRKpcKwYcPgdrub7blAREREdK7geImIAo0zpYioRwoJCcH999+Pe++9F263GxMnToTZbMa2bdsQHByMlJQUAMBTTz2FyMhIxMbGYvHixYiKisLs2bMBAH/+858xZswYPP3005g7dy62b9+Ol156CcuWLQMA9O7dGzfffDPmzZuHF198Eenp6Thx4gRKSkowZ86cQF06ERERkVc4XiKiQGNSioh6rKeffhoxMTFYsmQJcnJyEBYWhpEjR+Lhhx/2TAdfunQp7rnnHmRnZyM9PR2ff/45tFotAGDkyJH473//i8ceewxPP/004uPj8dRTT+GWW27xxFi+fDkefvhhLFiwAOXl5UhOTsbDDz8ciMslIiIi6jCOl4gokHj3PSI6LzXe6aWyshJhYWGBbg4RERFRt8PxEhH5GveUIiIiIiIiIiIiv2NSioiIiIiIiIiI/I7L94iIiIiIiIiIyO84U4qIiIiIiIiIiPyOSSkiIiIiIiIiIvI7JqWIiIiIiIiIiMjvmJQiIiIiIiIiIiK/Y1KKiIiIiIiIiIj8jkkpIiIiIiIiIiLyOyaliIiIiIiIiIjI75iUIiIiIiIiIiIiv2NSioiIiIiIiIiI/O7/AcX5dJOvPHHUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot accuracy and loss curves\n",
    "mlp_tagger.plot_curves()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0590afaa-72f8-4574-b2f0-e86038028336",
   "metadata": {},
   "source": [
    "### Evaluating the MLP on the training set (Classification Report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75bca5b4-573d-473f-8026-54122150ecd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5217/5217 [==============================] - 7s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "train_set = train_ds_handler.sentences\n",
    "train_classification_report_df, train_macro_average_df = mlp_tagger.classification_report(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac9ed425-1a14-4d76-9c20-9ec0e81d9a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Id</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision-Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AUX</td>\n",
       "      <td>0.993761</td>\n",
       "      <td>0.993085</td>\n",
       "      <td>0.993423</td>\n",
       "      <td>0.999529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>0.999560</td>\n",
       "      <td>0.999297</td>\n",
       "      <td>0.999428</td>\n",
       "      <td>0.999988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>0.996852</td>\n",
       "      <td>0.998701</td>\n",
       "      <td>0.997776</td>\n",
       "      <td>0.999920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>0.944380</td>\n",
       "      <td>0.916918</td>\n",
       "      <td>0.930446</td>\n",
       "      <td>0.981140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NUM</td>\n",
       "      <td>0.988561</td>\n",
       "      <td>0.982008</td>\n",
       "      <td>0.985273</td>\n",
       "      <td>0.997966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0.949785</td>\n",
       "      <td>0.902759</td>\n",
       "      <td>0.925675</td>\n",
       "      <td>0.982976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>0.960517</td>\n",
       "      <td>0.837297</td>\n",
       "      <td>0.894684</td>\n",
       "      <td>0.960093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0.988630</td>\n",
       "      <td>0.986502</td>\n",
       "      <td>0.987565</td>\n",
       "      <td>0.998712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>_</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.976512</td>\n",
       "      <td>0.938440</td>\n",
       "      <td>0.984402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>PART</td>\n",
       "      <td>0.995672</td>\n",
       "      <td>0.993901</td>\n",
       "      <td>0.994786</td>\n",
       "      <td>0.999545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0.983110</td>\n",
       "      <td>0.974333</td>\n",
       "      <td>0.978702</td>\n",
       "      <td>0.997613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>ADV</td>\n",
       "      <td>0.965487</td>\n",
       "      <td>0.976931</td>\n",
       "      <td>0.971175</td>\n",
       "      <td>0.995926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>SYM</td>\n",
       "      <td>0.980237</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.955684</td>\n",
       "      <td>0.976032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>DET</td>\n",
       "      <td>0.997370</td>\n",
       "      <td>0.995799</td>\n",
       "      <td>0.996584</td>\n",
       "      <td>0.999831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0.985332</td>\n",
       "      <td>0.989725</td>\n",
       "      <td>0.987524</td>\n",
       "      <td>0.999208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.963764</td>\n",
       "      <td>0.988093</td>\n",
       "      <td>0.975777</td>\n",
       "      <td>0.997395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>X</td>\n",
       "      <td>0.971751</td>\n",
       "      <td>0.540881</td>\n",
       "      <td>0.694949</td>\n",
       "      <td>0.831576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>PRON</td>\n",
       "      <td>0.993700</td>\n",
       "      <td>0.994637</td>\n",
       "      <td>0.994168</td>\n",
       "      <td>0.999750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class Id Class Name  Precision    Recall        F1  Precision-Recall AUC\n",
       "0          0        AUX   0.993761  0.993085  0.993423              0.999529\n",
       "1          1      PUNCT   0.999560  0.999297  0.999428              0.999988\n",
       "2          2      CCONJ   0.996852  0.998701  0.997776              0.999920\n",
       "3          3      SCONJ   0.944380  0.916918  0.930446              0.981140\n",
       "4          4        NUM   0.988561  0.982008  0.985273              0.997966\n",
       "5          5      PROPN   0.949785  0.902759  0.925675              0.982976\n",
       "6          6       INTJ   0.960517  0.837297  0.894684              0.960093\n",
       "7          7       VERB   0.988630  0.986502  0.987565              0.998712\n",
       "8          8          _   0.903226  0.976512  0.938440              0.984402\n",
       "9          9       PART   0.995672  0.993901  0.994786              0.999545\n",
       "10        10        ADJ   0.983110  0.974333  0.978702              0.997613\n",
       "11        11        ADV   0.965487  0.976931  0.971175              0.995926\n",
       "12        12        SYM   0.980237  0.932331  0.955684              0.976032\n",
       "13        13        DET   0.997370  0.995799  0.996584              0.999831\n",
       "14        14        ADP   0.985332  0.989725  0.987524              0.999208\n",
       "15        15       NOUN   0.963764  0.988093  0.975777              0.997395\n",
       "16        16          X   0.971751  0.540881  0.694949              0.831576\n",
       "17        17       PRON   0.993700  0.994637  0.994168              0.999750"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classification_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "832d9ee0-f328-43a9-bf06-ecba348f939c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Macro Average Precision</th>\n",
       "      <th>Macro Average Recall</th>\n",
       "      <th>Macro Average F1</th>\n",
       "      <th>Macro Average Precision Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.97565</td>\n",
       "      <td>0.943317</td>\n",
       "      <td>0.95567</td>\n",
       "      <td>0.983422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Macro Average Precision  Macro Average Recall  Macro Average F1  \\\n",
       "0                  0.97565              0.943317           0.95567   \n",
       "\n",
       "   Macro Average Precision Recall AUC  \n",
       "0                            0.983422  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_macro_average_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bca4d0-f05b-40f4-b5a6-760415aa987a",
   "metadata": {},
   "source": [
    "### Evaluating the MLP on the dev set (Classification Report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4446200f-72a7-43e8-8ad2-5560771ba936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762/762 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "dev_set = dev_ds_handler.sentences\n",
    "dev_classification_report_df, dev_macro_average_df = mlp_tagger.classification_report(dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16bc5714-8ae6-4e8a-bf72-7d4bbbf2a09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Id</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision-Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AUX</td>\n",
       "      <td>0.985174</td>\n",
       "      <td>0.982262</td>\n",
       "      <td>0.983716</td>\n",
       "      <td>0.997072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>0.997802</td>\n",
       "      <td>0.999371</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.999961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>0.986811</td>\n",
       "      <td>0.993961</td>\n",
       "      <td>0.990373</td>\n",
       "      <td>0.999369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>0.833773</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.807152</td>\n",
       "      <td>0.884030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NUM</td>\n",
       "      <td>0.963446</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>0.962190</td>\n",
       "      <td>0.990591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0.858661</td>\n",
       "      <td>0.785992</td>\n",
       "      <td>0.820721</td>\n",
       "      <td>0.896626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>0.909502</td>\n",
       "      <td>0.785156</td>\n",
       "      <td>0.842767</td>\n",
       "      <td>0.930959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0.947813</td>\n",
       "      <td>0.922675</td>\n",
       "      <td>0.935075</td>\n",
       "      <td>0.981827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>_</td>\n",
       "      <td>0.936842</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.956989</td>\n",
       "      <td>0.977987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>PART</td>\n",
       "      <td>0.977511</td>\n",
       "      <td>0.986384</td>\n",
       "      <td>0.981928</td>\n",
       "      <td>0.998205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0.920433</td>\n",
       "      <td>0.912879</td>\n",
       "      <td>0.916640</td>\n",
       "      <td>0.967204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>ADV</td>\n",
       "      <td>0.897785</td>\n",
       "      <td>0.915725</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.968062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>SYM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.855593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>DET</td>\n",
       "      <td>0.989974</td>\n",
       "      <td>0.989451</td>\n",
       "      <td>0.989712</td>\n",
       "      <td>0.999486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0.959875</td>\n",
       "      <td>0.967206</td>\n",
       "      <td>0.963527</td>\n",
       "      <td>0.992213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.914079</td>\n",
       "      <td>0.952835</td>\n",
       "      <td>0.933055</td>\n",
       "      <td>0.975771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>X</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.373083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>PRON</td>\n",
       "      <td>0.985068</td>\n",
       "      <td>0.984204</td>\n",
       "      <td>0.984636</td>\n",
       "      <td>0.997431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class Id Class Name  Precision    Recall        F1  Precision-Recall AUC\n",
       "0          0        AUX   0.985174  0.982262  0.983716              0.997072\n",
       "1          1      PUNCT   0.997802  0.999371  0.998586              0.999961\n",
       "2          2      CCONJ   0.986811  0.993961  0.990373              0.999369\n",
       "3          3      SCONJ   0.833773  0.782178  0.807152              0.884030\n",
       "4          4        NUM   0.963446  0.960938  0.962190              0.990591\n",
       "5          5      PROPN   0.858661  0.785992  0.820721              0.896626\n",
       "6          6       INTJ   0.909502  0.785156  0.842767              0.930959\n",
       "7          7       VERB   0.947813  0.922675  0.935075              0.981827\n",
       "8          8          _   0.936842  0.978022  0.956989              0.977987\n",
       "9          9       PART   0.977511  0.986384  0.981928              0.998205\n",
       "10        10        ADJ   0.920433  0.912879  0.916640              0.967204\n",
       "11        11        ADV   0.897785  0.915725  0.906667              0.968062\n",
       "12        12        SYM   1.000000  0.800000  0.888889              0.855593\n",
       "13        13        DET   0.989974  0.989451  0.989712              0.999486\n",
       "14        14        ADP   0.959875  0.967206  0.963527              0.992213\n",
       "15        15       NOUN   0.914079  0.952835  0.933055              0.975771\n",
       "16        16          X   0.500000  0.333333  0.400000              0.373083\n",
       "17        17       PRON   0.985068  0.984204  0.984636              0.997431"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_classification_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43a01610-322b-4326-948b-6eac44ac546d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Macro Average Precision</th>\n",
       "      <th>Macro Average Recall</th>\n",
       "      <th>Macro Average F1</th>\n",
       "      <th>Macro Average Precision Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.920253</td>\n",
       "      <td>0.890698</td>\n",
       "      <td>0.903479</td>\n",
       "      <td>0.932526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Macro Average Precision  Macro Average Recall  Macro Average F1  \\\n",
       "0                 0.920253              0.890698          0.903479   \n",
       "\n",
       "   Macro Average Precision Recall AUC  \n",
       "0                            0.932526  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_macro_average_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471e8dc3-a14d-4a82-b594-838db08ff665",
   "metadata": {},
   "source": [
    "### Evaluating the MLP on the test set (Classification Report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2aa8b8a5-7f0d-4659-8669-dd4dda09e524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761/761 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "test_set = test_ds_handler.sentences\n",
    "test_classification_report_df, test_macro_average_df = mlp_tagger.classification_report(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c1d7c00-4926-447e-8af3-a2edf504f40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Id</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision-Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AUX</td>\n",
       "      <td>0.981340</td>\n",
       "      <td>0.973087</td>\n",
       "      <td>0.977196</td>\n",
       "      <td>0.994956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>0.998678</td>\n",
       "      <td>0.998348</td>\n",
       "      <td>0.998513</td>\n",
       "      <td>0.999924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>0.991677</td>\n",
       "      <td>0.994041</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.999389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>0.832317</td>\n",
       "      <td>0.802941</td>\n",
       "      <td>0.817365</td>\n",
       "      <td>0.873525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NUM</td>\n",
       "      <td>0.961798</td>\n",
       "      <td>0.972727</td>\n",
       "      <td>0.967232</td>\n",
       "      <td>0.991866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0.850902</td>\n",
       "      <td>0.753686</td>\n",
       "      <td>0.799349</td>\n",
       "      <td>0.884637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>0.885135</td>\n",
       "      <td>0.803681</td>\n",
       "      <td>0.842444</td>\n",
       "      <td>0.885570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0.948633</td>\n",
       "      <td>0.923387</td>\n",
       "      <td>0.935840</td>\n",
       "      <td>0.979367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>_</td>\n",
       "      <td>0.843501</td>\n",
       "      <td>0.978462</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.952154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>PART</td>\n",
       "      <td>0.956604</td>\n",
       "      <td>0.976879</td>\n",
       "      <td>0.966635</td>\n",
       "      <td>0.992150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0.914748</td>\n",
       "      <td>0.906289</td>\n",
       "      <td>0.910499</td>\n",
       "      <td>0.964880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>ADV</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.898564</td>\n",
       "      <td>0.908761</td>\n",
       "      <td>0.969339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>SYM</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.790426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>DET</td>\n",
       "      <td>0.990939</td>\n",
       "      <td>0.984368</td>\n",
       "      <td>0.987643</td>\n",
       "      <td>0.999007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0.960816</td>\n",
       "      <td>0.968561</td>\n",
       "      <td>0.964673</td>\n",
       "      <td>0.989253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.887481</td>\n",
       "      <td>0.941496</td>\n",
       "      <td>0.913690</td>\n",
       "      <td>0.969050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>X</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.492185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>PRON</td>\n",
       "      <td>0.977879</td>\n",
       "      <td>0.987400</td>\n",
       "      <td>0.982616</td>\n",
       "      <td>0.998846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class Id Class Name  Precision    Recall        F1  Precision-Recall AUC\n",
       "0          0        AUX   0.981340  0.973087  0.977196              0.994956\n",
       "1          1      PUNCT   0.998678  0.998348  0.998513              0.999924\n",
       "2          2      CCONJ   0.991677  0.994041  0.992857              0.999389\n",
       "3          3      SCONJ   0.832317  0.802941  0.817365              0.873525\n",
       "4          4        NUM   0.961798  0.972727  0.967232              0.991866\n",
       "5          5      PROPN   0.850902  0.753686  0.799349              0.884637\n",
       "6          6       INTJ   0.885135  0.803681  0.842444              0.885570\n",
       "7          7       VERB   0.948633  0.923387  0.935840              0.979367\n",
       "8          8          _   0.843501  0.978462  0.905983              0.952154\n",
       "9          9       PART   0.956604  0.976879  0.966635              0.992150\n",
       "10        10        ADJ   0.914748  0.906289  0.910499              0.964880\n",
       "11        11        ADV   0.919192  0.898564  0.908761              0.969339\n",
       "12        12        SYM   0.848485  0.800000  0.823529              0.790426\n",
       "13        13        DET   0.990939  0.984368  0.987643              0.999007\n",
       "14        14        ADP   0.960816  0.968561  0.964673              0.989253\n",
       "15        15       NOUN   0.887481  0.941496  0.913690              0.969050\n",
       "16        16          X   0.846154  0.343750  0.488889              0.492185\n",
       "17        17       PRON   0.977879  0.987400  0.982616              0.998846"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classification_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "182574e1-0192-41e2-82da-d45d7705ceae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Macro Average Precision</th>\n",
       "      <th>Macro Average Recall</th>\n",
       "      <th>Macro Average F1</th>\n",
       "      <th>Macro Average Precision Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.922015</td>\n",
       "      <td>0.889315</td>\n",
       "      <td>0.899095</td>\n",
       "      <td>0.929251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Macro Average Precision  Macro Average Recall  Macro Average F1  \\\n",
       "0                 0.922015              0.889315          0.899095   \n",
       "\n",
       "   Macro Average Precision Recall AUC  \n",
       "0                            0.929251  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_macro_average_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
